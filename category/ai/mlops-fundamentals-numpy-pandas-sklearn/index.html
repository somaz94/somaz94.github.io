<!DOCTYPE html>
<html lang="en" class="no-js">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    

    
    

    
    

    
    

    <!-- ✅ Google Tag Manager 추가 -->
    <script>
        (function(w,d,s,l,i){
            w[l]=w[l]||[];
            w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});
            var f=d.getElementsByTagName(s)[0],
            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';
            j.async=true;
            j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;
            f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer','GTM-MBP83N4Q');
    </script>
      <!-- ✅ End Google Tag Manager -->

    <!-- Mermaid.js 직접 로드 -->
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true });
    </script>

    <title>Mastering MLOps Essential Libraries: NumPy, Pandas, and Scikit-Learn Complete Guide | somaz</title>
    <meta name="description" content="A comprehensive guide to NumPy, Pandas, and Scikit-Learn for building production-ready MLOps pipelines, covering data processing, model training, and deploym...">
    
        <meta name="keywords" content="mlops, numpy, pandas, scikit-learn, machine-learning, python, data-science">
    

    <!-- Social: Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Mastering MLOps Essential Libraries: NumPy, Pandas, and Scikit-Learn Complete Guide | somaz">
    <meta name="twitter:description" content="A comprehensive guide to NumPy, Pandas, and Scikit-Learn for building production-ready MLOps pipelines, covering data processing, model training, and deploym...">

    
        <meta property="twitter:image" content="https://res.cloudinary.com/dkcm26aem/image/upload/v1750904968/mlops-demo_znwpz1.png">
    
    
    
        <meta name="twitter:site" content="@twitter_username">
    

    <!-- Social: Facebook / Open Graph -->
    <meta property="og:url" content="https://somaz.blog/category/ai/mlops-fundamentals-numpy-pandas-sklearn/">
    <meta property="og:title" content="Mastering MLOps Essential Libraries: NumPy, Pandas, and Scikit-Learn Complete Guide | somaz">
    <meta property="og:image" content="https://res.cloudinary.com/dkcm26aem/image/upload/v1750904968/mlops-demo_znwpz1.png">
    <meta property="og:description" content="A comprehensive guide to NumPy, Pandas, and Scikit-Learn for building production-ready MLOps pipelines, covering data processing, model training, and deploym...">
    <meta property="og:site_name" content="Somaz Tech Blog">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/assets/img/icons/apple-touch-icon.png" />
    <link rel="apple-touch-icon" sizes="57x57" href="/assets/img/icons/apple-touch-icon-57x57.png" />
    <link rel="apple-touch-icon" sizes="72x72" href="/assets/img/icons/apple-touch-icon-72x72.png" />
    <link rel="apple-touch-icon" sizes="114x114" href="/assets/img/icons/apple-touch-icon-114x114.png" />
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/img/icons/apple-touch-icon-144x144.png" />
    <link rel="apple-touch-icon" sizes="60x60" href="/assets/img/icons/apple-touch-icon-60x60.png" />
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/img/icons/apple-touch-icon-120x120.png" />
    <link rel="apple-touch-icon" sizes="76x76" href="/assets/img/icons/apple-touch-icon-76x76.png" />
    <link rel="apple-touch-icon" sizes="152x152" href="/assets/img/icons/apple-touch-icon-152x152.png" />

    <!-- Windows 8 Tile Icons -->
    <meta name="application-name" content="somaz">
    <meta name="msapplication-TileColor" content="#141414">
    <meta name="msapplication-square70x70logo" content="smalltile.png" />
    <meta name="msapplication-square150x150logo" content="mediumtile.png" />
    <meta name="msapplication-wide310x150logo" content="widetile.png" />
    <meta name="msapplication-square310x310logo" content="largetile.png" />
    
    <!-- Android Lolipop Theme Color -->
    <meta name="theme-color" content="#141414">

    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Titillium+Web:300,400,700" rel="stylesheet">

    <link rel="stylesheet" href="/assets/css/styles.css">
    <link rel="canonical" href="https://somaz.blog/category/ai/mlops-fundamentals-numpy-pandas-sklearn/">
    <link rel="alternate" type="application/rss+xml" title="Somaz Tech Blog" href="https://somaz.blog/feed.xml" />

    <!-- Include extra styles -->
    

    <!-- JavaScript enabled/disabled -->
    <script>
        document.querySelector('html').classList.remove('no-js');
    </script>

    <!-- Google Adsense -->
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8725590811736154"
        crossorigin="anonymous"></script>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <!-- <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet"> -->
    <!-- <link href="https://cdn.jsdelivr.net/gh/sunn-us/SUIT/fonts/variable/woff2/SUIT-Variable.css" rel="stylesheet"> -->
    <link href="https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@400;500;700&display=swap" rel="stylesheet">
    <!-- <link href="https://fonts.googleapis.com/css2?family=Albert+Sans:wght@400;500;700&display=swap" rel="stylesheet"> -->

    <link rel="sitemap" type="application/xml" title="Sitemap" href="/sitemap.xml" />

</head>
<!-- ✅ Google Tag Manager (noscript) -->
<noscript>
    <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MBP83N4Q"
            height="0" width="0" style="display:none;visibility:hidden">
    </iframe>
</noscript>
<!-- ✅ End Google Tag Manager (noscript) -->
    <body class="has-push-menu">
        





        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" display="none" version="1.1"><defs><symbol id="icon-menu" viewBox="0 0 1024 1024"><path class="path1" d="M128 213.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 725.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 469.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5z"/></symbol><symbol id="icon-search" viewBox="0 0 951 1024"><path class="path1" d="M658.286 475.429q0-105.714-75.143-180.857t-180.857-75.143-180.857 75.143-75.143 180.857 75.143 180.857 180.857 75.143 180.857-75.143 75.143-180.857zM950.857 950.857q0 29.714-21.714 51.429t-51.429 21.714q-30.857 0-51.429-21.714l-196-195.429q-102.286 70.857-228 70.857-81.714 0-156.286-31.714t-128.571-85.714-85.714-128.571-31.714-156.286 31.714-156.286 85.714-128.571 128.571-85.714 156.286-31.714 156.286 31.714 128.571 85.714 85.714 128.571 31.714 156.286q0 125.714-70.857 228l196 196q21.143 21.143 21.143 51.429z"/></symbol><symbol id="icon-close" viewBox="0 0 1000 1000"><path d="M969.8,870.3c27,27.7,27,71.8,0,99.1C955.7,983,937.9,990,920,990c-17.9,0-35.7-7-49.7-20.7L500,599L129.6,969.4C115.6,983,97.8,990,79.9,990s-35.7-7-49.7-20.7c-27-27.3-27-71.4,0-99.1L400.9,500L30.3,129.3c-27-27.3-27-71.4,0-99.1c27.3-27,71.8-27,99.4,0L500,400.9L870.4,30.2c27.7-27,71.8-27,99.4,0c27,27.7,27,71.8,0,99.1L599.1,500L969.8,870.3z"/></symbol><symbol id="icon-twitter" viewBox="0 0 951 1024"><path class="path1" d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"/></symbol><symbol id="icon-facebook" viewBox="0 0 585 1024"><path class="path1" d="M548 6.857v150.857h-89.714q-49.143 0-66.286 20.571t-17.143 61.714v108h167.429l-22.286 169.143h-145.143v433.714h-174.857v-433.714h-145.714v-169.143h145.714v-124.571q0-106.286 59.429-164.857t158.286-58.571q84 0 130.286 6.857z"/></symbol><symbol id="icon-clock" viewBox="0 0 1000 1000"><path d="M500,10C229.8,10,10,229.8,10,500c0,270.2,219.8,490,490,490c270.2,0,490-219.8,490-490C990,229.8,770.2,10,500,10z M500,910.2c-226.2,0-410.2-184-410.2-410.2c0-226.2,184-410.2,410.2-410.2c226.2,0,410.2,184,410.2,410.2C910.2,726.1,726.2,910.2,500,910.2z M753.1,374c8.2,11.9,5.2,28.1-6.6,36.3L509.9,573.7c-4.4,3.1-9.6,4.6-14.8,4.6c-4.1,0-8.3-1-12.1-3c-8.6-4.5-14-13.4-14-23.1V202.5c0-14.4,11.7-26.1,26.1-26.1c14.4,0,26.1,11.7,26.1,26.1v300l195.6-135.1C728.7,359.2,744.9,362.1,753.1,374z"/></symbol><symbol id="icon-calendar" viewBox="0 0 1000 1000"><path d="M920,500v420H80V500H920 M990,430H10v490c0,38.7,31.3,70,70,70h840c38.7,0,70-31.3,70-70V430L990,430z"/><path d="M850,80v105c0,57.9-47.2,105-105,105c-58,0-105-47.1-105-105V80H360v105c0,57.9-47.2,105-105,105c-58,0-105-47.1-105-105V80C72.8,80,10,142.7,10,220v140h980V220C990,142.7,927.2,80,850,80z"/><path d="M255,10c-19.3,0-35,15.8-35,35v140c0,19.2,15.7,35,35,35c19.3,0,35-15.8,35-35V45C290,25.8,274.3,10,255,10z"/><path d="M745,10c-19.3,0-35,15.8-35,35v140c0,19.2,15.7,35,35,35c19.3,0,35-15.8,35-35V45C780,25.8,764.3,10,745,10z"/></symbol><symbol id="icon-github" viewBox="0 0 12 14"><path d="M6 1q1.633 0 3.012 0.805t2.184 2.184 0.805 3.012q0 1.961-1.145 3.527t-2.957 2.168q-0.211 0.039-0.312-0.055t-0.102-0.234q0-0.023 0.004-0.598t0.004-1.051q0-0.758-0.406-1.109 0.445-0.047 0.801-0.141t0.734-0.305 0.633-0.52 0.414-0.82 0.16-1.176q0-0.93-0.617-1.609 0.289-0.711-0.062-1.594-0.219-0.070-0.633 0.086t-0.719 0.344l-0.297 0.187q-0.727-0.203-1.5-0.203t-1.5 0.203q-0.125-0.086-0.332-0.211t-0.652-0.301-0.664-0.105q-0.352 0.883-0.062 1.594-0.617 0.68-0.617 1.609 0 0.664 0.16 1.172t0.41 0.82 0.629 0.523 0.734 0.305 0.801 0.141q-0.305 0.281-0.383 0.805-0.164 0.078-0.352 0.117t-0.445 0.039-0.512-0.168-0.434-0.488q-0.148-0.25-0.379-0.406t-0.387-0.187l-0.156-0.023q-0.164 0-0.227 0.035t-0.039 0.090 0.070 0.109 0.102 0.094l0.055 0.039q0.172 0.078 0.34 0.297t0.246 0.398l0.078 0.18q0.102 0.297 0.344 0.48t0.523 0.234 0.543 0.055 0.434-0.027l0.18-0.031q0 0.297 0.004 0.691t0.004 0.426q0 0.141-0.102 0.234t-0.312 0.055q-1.812-0.602-2.957-2.168t-1.145-3.527q0-1.633 0.805-3.012t2.184-2.184 3.012-0.805zM2.273 9.617q0.023-0.055-0.055-0.094-0.078-0.023-0.102 0.016-0.023 0.055 0.055 0.094 0.070 0.047 0.102-0.016zM2.516 9.883q0.055-0.039-0.016-0.125-0.078-0.070-0.125-0.023-0.055 0.039 0.016 0.125 0.078 0.078 0.125 0.023zM2.75 10.234q0.070-0.055 0-0.148-0.062-0.102-0.133-0.047-0.070 0.039 0 0.141t0.133 0.055zM3.078 10.562q0.062-0.062-0.031-0.148-0.094-0.094-0.156-0.023-0.070 0.062 0.031 0.148 0.094 0.094 0.156 0.023zM3.523 10.758q0.023-0.086-0.102-0.125-0.117-0.031-0.148 0.055t0.102 0.117q0.117 0.047 0.148-0.047zM4.016 10.797q0-0.102-0.133-0.086-0.125 0-0.125 0.086 0 0.102 0.133 0.086 0.125 0 0.125-0.086zM4.469 10.719q-0.016-0.086-0.141-0.070-0.125 0.023-0.109 0.117t0.141 0.062 0.109-0.109z"></path></symbol><symbol id="icon-medium" viewBox="0 0 1000 1000"><path d="M336.5,240.2v641.5c0,9.1-2.3,16.9-6.8,23.2s-11.2,9.6-20,9.6c-6.2,0-12.2-1.5-18-4.4L37.3,782.7c-7.7-3.6-14.1-9.8-19.4-18.3S10,747.4,10,739V115.5c0-7.3,1.8-13.5,5.5-18.6c3.6-5.1,8.9-7.7,15.9-7.7c5.1,0,13.1,2.7,24.1,8.2l279.5,140C335.9,238.6,336.5,239.5,336.5,240.2L336.5,240.2z M371.5,295.5l292,473.6l-292-145.5V295.5z M990,305.3v576.4c0,9.1-2.6,16.5-7.7,22.1c-5.1,5.7-12,8.5-20.8,8.5s-17.3-2.4-25.7-7.1L694.7,784.9L990,305.3z M988.4,239.7c0,1.1-46.8,77.6-140.3,229.4C754.6,621,699.8,709.8,683.8,735.7L470.5,389l177.2-288.2c6.2-10.2,15.7-15.3,28.4-15.3c5.1,0,9.8,1.1,14.2,3.3l295.9,147.7C987.6,237.1,988.4,238.2,988.4,239.7L988.4,239.7z"/></symbol><symbol id="icon-instagram" viewBox="0 0 489.84 489.84"><path d="M249.62,50.46c65.4,0,73.14.25,99,1.43C372.47,53,385.44,57,394.07,60.32a75.88,75.88,0,0,1,28.16,18.32,75.88,75.88,0,0,1,18.32,28.16c3.35,8.63,7.34,21.6,8.43,45.48,1.18,25.83,1.43,33.57,1.43,99s-0.25,73.14-1.43,99c-1.09,23.88-5.08,36.85-8.43,45.48a81.11,81.11,0,0,1-46.48,46.48c-8.63,3.35-21.6,7.34-45.48,8.43-25.82,1.18-33.57,1.43-99,1.43s-73.15-.25-99-1.43c-23.88-1.09-36.85-5.08-45.48-8.43A75.88,75.88,0,0,1,77,423.86,75.88,75.88,0,0,1,58.69,395.7c-3.35-8.63-7.34-21.6-8.43-45.48-1.18-25.83-1.43-33.57-1.43-99s0.25-73.14,1.43-99c1.09-23.88,5.08-36.85,8.43-45.48A75.88,75.88,0,0,1,77,78.64a75.88,75.88,0,0,1,28.16-18.32c8.63-3.35,21.6-7.34,45.48-8.43,25.83-1.18,33.57-1.43,99-1.43m0-44.13c-66.52,0-74.86.28-101,1.47s-43.87,5.33-59.45,11.38A120.06,120.06,0,0,0,45.81,47.44,120.06,120.06,0,0,0,17.56,90.82C11.5,106.4,7.36,124.2,6.17,150.27s-1.47,34.46-1.47,101,0.28,74.86,1.47,101,5.33,43.87,11.38,59.45a120.06,120.06,0,0,0,28.25,43.38,120.06,120.06,0,0,0,43.38,28.25c15.58,6.05,33.38,10.19,59.45,11.38s34.46,1.47,101,1.47,74.86-.28,101-1.47,43.87-5.33,59.45-11.38a125.24,125.24,0,0,0,71.63-71.63c6.05-15.58,10.19-33.38,11.38-59.45s1.47-34.46,1.47-101-0.28-74.86-1.47-101-5.33-43.87-11.38-59.45a120.06,120.06,0,0,0-28.25-43.38,120.06,120.06,0,0,0-43.38-28.25C394.47,13.13,376.67,9,350.6,7.8s-34.46-1.47-101-1.47h0Z" transform="translate(-4.7 -6.33)" /><path d="M249.62,125.48A125.77,125.77,0,1,0,375.39,251.25,125.77,125.77,0,0,0,249.62,125.48Zm0,207.41a81.64,81.64,0,1,1,81.64-81.64A81.64,81.64,0,0,1,249.62,332.89Z" transform="translate(-4.7 -6.33)"/><circle cx="375.66" cy="114.18" r="29.39" /></symbol><symbol id="icon-linkedin" viewBox="0 0 12 14"><path d="M2.727 4.883v7.742h-2.578v-7.742h2.578zM2.891 2.492q0.008 0.57-0.395 0.953t-1.059 0.383h-0.016q-0.641 0-1.031-0.383t-0.391-0.953q0-0.578 0.402-0.957t1.051-0.379 1.039 0.379 0.398 0.957zM12 8.187v4.437h-2.57v-4.141q0-0.82-0.316-1.285t-0.988-0.465q-0.492 0-0.824 0.27t-0.496 0.668q-0.086 0.234-0.086 0.633v4.32h-2.57q0.016-3.117 0.016-5.055t-0.008-2.313l-0.008-0.375h2.57v1.125h-0.016q0.156-0.25 0.32-0.438t0.441-0.406 0.68-0.34 0.895-0.121q1.336 0 2.148 0.887t0.813 2.598z"></path></symbol><symbol id="icon-heart" viewBox="0 0 34 30"><path d="M17,29.7 L16.4,29.2 C3.5,18.7 0,15 0,9 C0,4 4,0 9,0 C13.1,0 15.4,2.3 17,4.1 C18.6,2.3 20.9,0 25,0 C30,0 34,4 34,9 C34,15 30.5,18.7 17.6,29.2 L17,29.7 Z M9,2 C5.1,2 2,5.1 2,9 C2,14.1 5.2,17.5 17,27.1 C28.8,17.5 32,14.1 32,9 C32,5.1 28.9,2 25,2 C21.5,2 19.6,4.1 18.1,5.8 L17,7.1 L15.9,5.8 C14.4,4.1 12.5,2 9,2 Z" id="Shape"></path></symbol><symbol id="icon-arrow-right" viewBox="0 0 25.452 25.452"><path d="M4.471,24.929v-2.004l12.409-9.788c0.122-0.101,0.195-0.251,0.195-0.411c0-0.156-0.073-0.31-0.195-0.409L4.471,2.526V0.522c0-0.2,0.115-0.384,0.293-0.469c0.18-0.087,0.396-0.066,0.552,0.061l15.47,12.202c0.123,0.1,0.195,0.253,0.195,0.409c0,0.16-0.072,0.311-0.195,0.411L5.316,25.34c-0.155,0.125-0.372,0.147-0.552,0.061C4.586,25.315,4.471,25.13,4.471,24.929z"/></symbol><symbol id="icon-star" viewBox="0 0 48 48"><path fill="currentColor" d="M44,24c0,11.045-8.955,20-20,20S4,35.045,4,24S12.955,4,24,4S44,12.955,44,24z"/><path fill="#ffffff" d="M24,11l3.898,7.898l8.703,1.301l-6.301,6.102l1.5,8.699L24,30.898L16.199,35l1.5-8.699l-6.301-6.102  l8.703-1.301L24,11z"/></symbol><symbol id="icon-read" viewBox="0 0 32 32"><path fill="currentColor" d="M29,4H3C1.343,4,0,5.343,0,7v18c0,1.657,1.343,3,3,3h10c0,0.552,0.448,1,1,1h4c0.552,0,1-0.448,1-1h10  c1.657,0,3-1.343,3-3V7C32,5.343,30.657,4,29,4z M29,5v20H18.708c-0.618,0-1.236,0.146-1.789,0.422l-0.419,0.21V5H29z M15.5,5  v20.632l-0.419-0.21C14.528,25.146,13.91,25,13.292,25H3V5H15.5z M31,25c0,1.103-0.897,2-2,2H18v1h-4v-1H3c-1.103,0-2-0.897-2-2V7  c0-0.737,0.405-1.375,1-1.722V25c0,0.552,0.448,1,1,1h10.292c0.466,0,0.925,0.108,1.342,0.317l0.919,0.46  c0.141,0.07,0.294,0.106,0.447,0.106c0.153,0,0.306-0.035,0.447-0.106l0.919-0.46C17.783,26.108,18.242,26,18.708,26H29  c0.552,0,1-0.448,1-1V5.278C30.595,5.625,31,6.263,31,7V25z M6,12.5C6,12.224,6.224,12,6.5,12h5c0.276,0,0.5,0.224,0.5,0.5  S11.776,13,11.5,13h-5C6.224,13,6,12.776,6,12.5z M6,14.5C6,14.224,6.224,14,6.5,14h5c0.276,0,0.5,0.224,0.5,0.5S11.776,15,11.5,15  h-5C6.224,15,6,14.776,6,14.5z M6,16.5C6,16.224,6.224,16,6.5,16h5c0.276,0,0.5,0.224,0.5,0.5S11.776,17,11.5,17h-5  C6.224,17,6,16.776,6,16.5z M20,12.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,13,25.5,13h-5  C20.224,13,20,12.776,20,12.5z M20,14.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,15,25.5,15h-5  C20.224,15,20,14.776,20,14.5z M20,16.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,17,25.5,17h-5  C20.224,17,20,16.776,20,16.5z"></path></symbol><symbol id="icon-tistory" viewBox="0 0 24 24"><path d="M4 4h16v3h-6v13h-4V7H4V4z"/></symbol></defs></svg>

        <header class="bar-header">
    <a id="menu" role="button">
        <svg id="open" class="icon-menu"><use xlink:href="#icon-menu"></use></svg>
    </a>
    <h1 class="logo">
        <a href="/">
            
                somaz <span class="version">v3.1.2</span>
            
        </a>
    </h1>
    <a id="search" class="dosearch" role="button">
        <svg class="icon-search"><use xlink:href="#icon-search"></use></svg>
    </a>
    
        <a href="https://github.com/thiagorossener/jekflix-template" class="get-theme" role="button">
            Get this theme!
        </a>
    
</header>

<div id="mask" class="overlay"></div>

<aside class="sidebar" id="sidebar">
    <nav id="navigation">
      <h2>Menu</h2>
      <ul>
  
    
      <li>
        <a href="https://somaz.blog/">Home</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/about">About</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/category">Category</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/contact">Contact</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/feed.xml">Feed</a>
      </li>
    
  
</ul>

    </nav>
</aside>

<div class="search-wrapper">
    <div class="search-form">
        <input type="text" class="search-field" placeholder="Search">
        <svg class="icon-remove-sign"><use xlink:href="#icon-close"></use></svg>
        <ul class="search-results search-list"></ul>
    </div>
</div>



        <section class="post two-columns">
            <article role="article" class="post-content">
                <p class="post-info">
                    
                        <svg class="icon-calendar" id="date"><use xlink:href="#icon-calendar"></use></svg>
                        <time class="date" datetime="2025-10-02T00:00:00+00:00">
                            


October 2, 2025

                        </time>
                    
                    <svg id="clock" class="icon-clock"><use xlink:href="#icon-clock"></use></svg>
                    <span>62 min to read</span>
                </p>
                <h1 class="post-title">Mastering MLOps Essential Libraries: NumPy, Pandas, and Scikit-Learn Complete Guide</h1>
                <p class="post-subtitle">From data pipelines to model deployment - Essential tools for MLOps engineers</p>

                
                    <img src="https://res.cloudinary.com/dkcm26aem/image/upload/v1750904968/mlops-demo_znwpz1.png" alt="Featured image" class="post-cover">
                

                <!-- Pagination links -->



                <!-- Add your table of contents here -->


                <h2 id="table-of-contents">Table of Contents</h2>

<ol>
  <li><a href="#introduction-to-mlops-fundamentals">Introduction</a></li>
  <li><a href="#mlops-pipeline-architecture">MLOps Pipeline Architecture</a></li>
  <li><a href="#numpy-high-performance-foundation-for-ml-operations">NumPy: High-Performance Foundation</a></li>
  <li><a href="#pandas-data-pipeline-powerhouse">Pandas: Data Pipeline Powerhouse</a></li>
  <li><a href="#scikit-learn-complete-machine-learning-pipeline-framework">Scikit-Learn: Complete ML Pipeline</a></li>
  <li><a href="#running-locally">Hands-on: Local MLOps Pipeline</a></li>
  <li><a href="#production-deployment-fastapi--docker">Production Deployment (FastAPI + Docker + K8s)</a></li>
  <li><a href="#performance-monitoring-and-automation">Monitoring &amp; Automation</a></li>
  <li><a href="#key-points-and-conclusion">Key Points &amp; Conclusion</a></li>
  <li><a href="#references">References</a></li>
</ol>

<hr />

<h2 id="introduction-to-mlops-fundamentals">Introduction to MLOps Fundamentals</h2>

<blockquote>
  <p>“Data is as important as code.” As AI/ML becomes central to modern software development, traditional DevOps engineers must expand into MLOps territory. <br /><br />This comprehensive guide explores how NumPy, Pandas, and Scikit-Learn form the backbone of production MLOps workflows, enabling efficient data processing, model training, and deployment strategies.</p>
</blockquote>

<p><br /></p>

<h3 id="why-these-three-libraries-matter">Why These Three Libraries Matter</h3>

<p>NumPy, Pandas, and Scikit-Learn aren’t just data science tools—they’re the foundation of modern MLOps infrastructure:</p>

<ul>
  <li><strong>NumPy</strong>: High-performance numerical computing engine powering all ML frameworks</li>
  <li><strong>Pandas</strong>: Data manipulation and ETL backbone for feature engineering</li>
  <li><strong>Scikit-Learn</strong>: Complete machine learning pipeline from experimentation to production</li>
  <li><strong>Production Ready</strong>: Battle-tested libraries used by major tech companies worldwide</li>
  <li><strong>Ecosystem Integration</strong>: Seamless compatibility with Docker, Kubernetes, and cloud platforms</li>
  <li><strong>Community Support</strong>: Extensive documentation, tutorials, and community resources</li>
</ul>

<hr />

<h2 id="mlops-pipeline-architecture">MLOps Pipeline Architecture</h2>

<p>Understanding how these libraries fit into the MLOps workflow is crucial for building efficient, scalable machine learning systems. This section maps out where each library excels in the typical MLOps pipeline and how they work together to create robust data-driven applications.</p>

<p><br /></p>

<h3 id="library-roles-in-mlops-workflow">Library Roles in MLOps Workflow</h3>

<div style="width: 100%; margin: 20px auto;">
  <div class="mermaid">
    graph LR
      A[Data Collection] --&gt; B[Preprocessing/Cleaning]
      B --&gt; C[Training/Inference]
      C --&gt; D[Evaluation/Logging]
      D --&gt; E[Storage/Deployment]
      
      A -.-&gt; A1[Pandas<br />Data Sources]
      B -.-&gt; B1[NumPy<br />Transformations]
      C -.-&gt; C1[Scikit-Learn<br />Models]
      D -.-&gt; D1[Scikit/Pandas<br />Metrics]
      E -.-&gt; E1[joblib + API<br />Serving]
      
      style A fill:#a5d6a7,stroke:#333,stroke-width:1px
      style B fill:#64b5f6,stroke:#333,stroke-width:1px
      style C fill:#ffcc80,stroke:#333,stroke-width:1px
      style D fill:#ce93d8,stroke:#333,stroke-width:1px
      style E fill:#ef9a9a,stroke:#333,stroke-width:1px
  </div>
</div>

<p><br /></p>

<div class="table-container">
  <table class="table-beauty">
    <tr>
      <th style="width: 20%;">Pipeline Stage</th>
      <th style="width: 25%;">Primary Library</th>
      <th style="width: 55%;">Key Responsibilities</th>
    </tr>
    <tr>
      <td><strong>Data Collection</strong></td>
      <td>Pandas</td>
      <td>Reading from various sources (CSV, JSON, SQL, Parquet), data validation, initial exploration</td>
    </tr>
    <tr>
      <td><strong>Preprocessing</strong></td>
      <td>NumPy + Pandas</td>
      <td>Numerical transformations, feature engineering, data cleaning, normalization</td>
    </tr>
    <tr>
      <td><strong>Model Training</strong></td>
      <td>Scikit-Learn</td>
      <td>Algorithm selection, hyperparameter tuning, cross-validation, model fitting</td>
    </tr>
    <tr>
      <td><strong>Evaluation</strong></td>
      <td>All Three</td>
      <td>Performance metrics calculation, model comparison, result visualization</td>
    </tr>
    <tr>
      <td><strong>Deployment</strong></td>
      <td>joblib + FastAPI</td>
      <td>Model serialization, API serving, containerization, monitoring</td>
    </tr>
  </table>
</div>

<hr />

<h2 id="numpy-high-performance-foundation-for-ml-operations">NumPy: High-Performance Foundation for ML Operations</h2>

<p>NumPy serves as the numerical computing foundation for the entire Python data science ecosystem. Its efficient array operations and mathematical functions make it indispensable for high-performance machine learning workflows, providing the speed and reliability needed for production systems.</p>

<p><br /></p>

<h3 id="why-numpy-is-critical-for-mlops">Why NumPy is Critical for MLOps</h3>

<h4 id="the-performance-engine-of-ml">The Performance Engine of ML</h4>

<p>NumPy isn’t just a numerical library—it’s the performance engine behind modern machine learning operations:</p>

<ul>
  <li><strong>Speed</strong>: C-implemented vectorized operations are 10-100x faster than pure Python</li>
  <li><strong>Memory Efficiency</strong>: Homogeneous arrays with contiguous memory layout</li>
  <li><strong>Universal Compatibility</strong>: Foundation for TensorFlow, PyTorch, Scikit-Learn, and other ML libraries</li>
  <li><strong>Broadcasting</strong>: Efficient operations on arrays of different shapes</li>
  <li><strong>Mathematical Functions</strong>: Comprehensive collection of mathematical, statistical, and linear algebra operations</li>
</ul>

<p><br /></p>

<h3 id="core-numpy-capabilities">Core NumPy Capabilities</h3>

<div class="table-container">
  <table class="table-beauty">
    <tr>
      <th style="width: 25%;">Feature Category</th>
      <th style="width: 35%;">Key Functions</th>
      <th style="width: 40%;">MLOps Applications</th>
    </tr>
    <tr>
      <td><strong>Array Operations</strong></td>
      <td>reshape, concatenate, split, stack</td>
      <td>Data preprocessing, batch processing, feature transformation</td>
    </tr>
    <tr>
      <td><strong>Mathematical Functions</strong></td>
      <td>sin, cos, exp, log, sqrt</td>
      <td>Feature engineering, activation functions, transformations</td>
    </tr>
    <tr>
      <td><strong>Statistical Operations</strong></td>
      <td>mean, std, percentile, histogram</td>
      <td>Data analysis, normalization, outlier detection</td>
    </tr>
    <tr>
      <td><strong>Linear Algebra</strong></td>
      <td>dot, matmul, linalg.inv, svd</td>
      <td>Matrix operations, dimensionality reduction, optimization</td>
    </tr>
    <tr>
      <td><strong>Random Sampling</strong></td>
      <td>random.normal, random.choice, seed</td>
      <td>Data augmentation, train/test splits, reproducible experiments</td>
    </tr>
  </table>
</div>

<p><br /></p>

<h3 id="practical-implementation-examples">Practical Implementation Examples</h3>

<h4 id="real-time-log-data-normalization">Real-time Log Data Normalization</h4>

<p>Processing server latency logs for anomaly detection:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">normalize_latency_data</span><span class="p">(</span><span class="n">latencies</span><span class="p">):</span>
    <span class="s">"""Normalize server response time logs for outlier detection"""</span>
    <span class="n">latencies</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">latencies</span><span class="p">)</span>
    
    <span class="c1"># Z-score normalization
</span>    <span class="n">normalized</span> <span class="o">=</span> <span class="p">(</span><span class="n">latencies</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">latencies</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">latencies</span><span class="p">)</span>
    
    <span class="c1"># Apply 3-sigma rule for outlier clipping
</span>    <span class="n">clipped</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">clip</span><span class="p">(</span><span class="n">normalized</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">clipped</span>

<span class="c1"># Example: Microservice response times (ms)
</span><span class="n">response_times</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">19</span><span class="p">]</span>
<span class="n">cleaned_data</span> <span class="o">=</span> <span class="n">normalize_latency_data</span><span class="p">(</span><span class="n">response_times</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Normalized data: </span><span class="si">{</span><span class="n">cleaned_data</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h4 id="vectorized-operations-for-performance-optimization">Vectorized Operations for Performance Optimization</h4>

<p>Comparing vectorized vs traditional approaches:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Inefficient approach (pure Python)
</span><span class="k">def</span> <span class="nf">slow_distance_calculation</span><span class="p">(</span><span class="n">points1</span><span class="p">,</span> <span class="n">points2</span><span class="p">):</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">p1</span><span class="p">,</span> <span class="n">p2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">points1</span><span class="p">,</span> <span class="n">points2</span><span class="p">):</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="p">((</span><span class="n">p1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">p2</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">p1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">p2</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mf">0.5</span>
        <span class="n">distances</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">distances</span>

<span class="c1"># Efficient approach (NumPy vectorization)
</span><span class="k">def</span> <span class="nf">fast_distance_calculation</span><span class="p">(</span><span class="n">points1</span><span class="p">,</span> <span class="n">points2</span><span class="p">):</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">points1</span><span class="p">)</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">points2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">p1</span> <span class="o">-</span> <span class="n">p2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># Performance benchmark
</span><span class="kn">import</span> <span class="nn">time</span>
<span class="n">points1</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">)]</span>
<span class="n">points2</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">)]</span>

<span class="c1"># NumPy approach is 10-50x faster
</span></code></pre></div></div>

<p><br /></p>

<h3 id="mlops-production-tips">MLOps Production Tips</h3>

<div class="info-box info-box-default">
  <strong>Performance Optimization Strategies</strong>
  <ol>
    <li><strong>Memory Efficiency</strong>: Use np.memmap for processing datasets larger than available RAM</li>
    <li><strong>Type Optimization</strong>: Choose float32 vs float64 to reduce memory usage by 50%</li>
    <li><strong>GPU Acceleration</strong>: Leverage CuPy library to run NumPy code on GPU for massive datasets</li>
    <li><strong>Vectorization</strong>: Replace Python loops with NumPy operations for 10-100x speed improvements</li>
    <li><strong>Broadcasting</strong>: Use NumPy's broadcasting rules to avoid explicit loops and temporary arrays</li>
  </ol>
</div>

<hr />

<h2 id="pandas-data-pipeline-powerhouse">Pandas: Data Pipeline Powerhouse</h2>

<p>Pandas serves as the backbone of data manipulation and ETL processes in MLOps workflows. Its ability to handle diverse data formats and perform complex transformations makes it indispensable for feature engineering, data cleaning, and preparing datasets for machine learning models.</p>

<p><br /></p>

<h3 id="why-pandas-is-essential-for-mlops">Why Pandas is Essential for MLOps</h3>

<h4 id="the-data-manipulation-engine">The Data Manipulation Engine</h4>

<p>Pandas isn’t just a data analysis tool—it’s the data manipulation engine powering MLOps workflows:</p>

<ul>
  <li><strong>Format Versatility</strong>: Native support for CSV, JSON, Parquet, SQL, Excel, and more</li>
  <li><strong>Data Operations</strong>: Powerful grouping, joining, pivoting, and aggregation capabilities</li>
  <li><strong>Time Series Support</strong>: Specialized functionality for temporal data analysis</li>
  <li><strong>Missing Data Handling</strong>: Robust methods for dealing with incomplete datasets</li>
  <li><strong>Performance</strong>: Optimized operations using underlying NumPy arrays</li>
  <li><strong>Integration</strong>: Seamless compatibility with scikit-learn and other ML libraries</li>
</ul>

<p><br /></p>

<h3 id="core-pandas-capabilities">Core Pandas Capabilities</h3>

<div class="table-container">
  <table class="table-beauty">
    <tr>
      <th style="width: 25%;">Feature Category</th>
      <th style="width: 35%;">Key Functions</th>
      <th style="width: 40%;">MLOps Applications</th>
    </tr>
    <tr>
      <td><strong>Data I/O</strong></td>
      <td>read_csv, read_json, read_sql, to_parquet</td>
      <td>Data ingestion, feature store integration, model artifact storage</td>
    </tr>
    <tr>
      <td><strong>Data Cleaning</strong></td>
      <td>dropna, fillna, replace, duplicated</td>
      <td>Data quality assurance, preprocessing automation</td>
    </tr>
    <tr>
      <td><strong>Transformations</strong></td>
      <td>groupby, merge, pivot, apply</td>
      <td>Feature engineering, data aggregation, business logic implementation</td>
    </tr>
    <tr>
      <td><strong>Time Series</strong></td>
      <td>resample, rolling, shift, date_range</td>
      <td>Temporal feature extraction, trend analysis, forecasting preparation</td>
    </tr>
    <tr>
      <td><strong>Statistical Operations</strong></td>
      <td>describe, corr, value_counts, quantile</td>
      <td>Data profiling, exploratory data analysis, feature selection</td>
    </tr>
  </table>
</div>

<p><br /></p>

<h3 id="practical-implementation-examples-1">Practical Implementation Examples</h3>

<h4 id="feature-store-integration-pipeline">Feature Store Integration Pipeline</h4>

<p>Building a robust data pipeline that connects multiple data sources:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>
<span class="kn">import</span> <span class="nn">sqlalchemy</span>
<span class="kn">import</span> <span class="nn">boto3</span>

<span class="k">class</span> <span class="nc">FeaturePipeline</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">db_engine</span> <span class="o">=</span> <span class="n">sqlalchemy</span><span class="p">.</span><span class="n">create_engine</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s">'database_url'</span><span class="p">])</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">s3_client</span> <span class="o">=</span> <span class="n">boto3</span><span class="p">.</span><span class="n">client</span><span class="p">(</span><span class="s">'s3'</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">extract_user_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user_ids</span><span class="p">,</span> <span class="n">date_range</span><span class="p">):</span>
        <span class="s">"""Extract and combine user features from multiple data sources"""</span>
        
        <span class="c1"># 1. Extract user activity from S3 (Parquet files)
</span>        <span class="n">activity_df</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_extract_activity_data</span><span class="p">(</span><span class="n">date_range</span><span class="p">)</span>
        
        <span class="c1"># 2. Extract transaction data from PostgreSQL
</span>        <span class="n">transaction_df</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_extract_transaction_data</span><span class="p">(</span><span class="n">user_ids</span><span class="p">,</span> <span class="n">date_range</span><span class="p">)</span>
        
        <span class="c1"># 3. Extract product interaction from Redis/MongoDB
</span>        <span class="n">interaction_df</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_extract_interaction_data</span><span class="p">(</span><span class="n">user_ids</span><span class="p">,</span> <span class="n">date_range</span><span class="p">)</span>
        
        <span class="c1"># 4. Combine and engineer features
</span>        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_create_feature_matrix</span><span class="p">(</span><span class="n">activity_df</span><span class="p">,</span> <span class="n">transaction_df</span><span class="p">,</span> <span class="n">interaction_df</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_extract_activity_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">date_range</span><span class="p">):</span>
        <span class="s">"""Extract user activity logs from S3"""</span>
        <span class="n">start_date</span><span class="p">,</span> <span class="n">end_date</span> <span class="o">=</span> <span class="n">date_range</span>
        
        <span class="c1"># Read multiple Parquet files efficiently
</span>        <span class="n">file_pattern</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"s3://ml-datalake/user-activity/year=</span><span class="si">{</span><span class="n">start_date</span><span class="p">.</span><span class="n">year</span><span class="si">}</span><span class="s">/month=</span><span class="si">{</span><span class="n">start_date</span><span class="p">.</span><span class="n">month</span><span class="si">:</span><span class="mi">02</span><span class="n">d</span><span class="si">}</span><span class="s">/*.parquet"</span>
        
        <span class="n">activity_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">file_pattern</span><span class="p">,</span> 
                                    <span class="n">filters</span><span class="o">=</span><span class="p">[(</span><span class="s">'event_date'</span><span class="p">,</span> <span class="s">'&gt;='</span><span class="p">,</span> <span class="n">start_date</span><span class="p">),</span>
                                           <span class="p">(</span><span class="s">'event_date'</span><span class="p">,</span> <span class="s">'&lt;='</span><span class="p">,</span> <span class="n">end_date</span><span class="p">)])</span>
        
        <span class="c1"># Data quality checks
</span>        <span class="n">activity_df</span> <span class="o">=</span> <span class="n">activity_df</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s">'user_id'</span><span class="p">,</span> <span class="s">'event_type'</span><span class="p">])</span>
        <span class="n">activity_df</span><span class="p">[</span><span class="s">'session_duration'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">activity_df</span><span class="p">[</span><span class="s">'session_duration'</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s">'coerce'</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">activity_df</span>
    
    <span class="k">def</span> <span class="nf">_extract_transaction_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user_ids</span><span class="p">,</span> <span class="n">date_range</span><span class="p">):</span>
        <span class="s">"""Extract transaction data from PostgreSQL"""</span>
        <span class="n">start_date</span><span class="p">,</span> <span class="n">end_date</span> <span class="o">=</span> <span class="n">date_range</span>
        
        <span class="n">query</span> <span class="o">=</span> <span class="s">"""
        SELECT 
            user_id,
            transaction_date,
            amount,
            category,
            payment_method,
            is_successful
        FROM transactions 
        WHERE user_id = ANY(%(user_ids)s)
        AND transaction_date BETWEEN %(start_date)s AND %(end_date)s
        AND is_successful = true
        """</span>
        
        <span class="n">transaction_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_sql</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> 
                                   <span class="n">con</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">db_engine</span><span class="p">,</span>
                                   <span class="n">params</span><span class="o">=</span><span class="p">{</span>
                                       <span class="s">'user_ids'</span><span class="p">:</span> <span class="n">user_ids</span><span class="p">,</span>
                                       <span class="s">'start_date'</span><span class="p">:</span> <span class="n">start_date</span><span class="p">,</span>
                                       <span class="s">'end_date'</span><span class="p">:</span> <span class="n">end_date</span>
                                   <span class="p">})</span>
        
        <span class="c1"># Convert data types and handle missing values
</span>        <span class="n">transaction_df</span><span class="p">[</span><span class="s">'transaction_date'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">transaction_df</span><span class="p">[</span><span class="s">'transaction_date'</span><span class="p">])</span>
        <span class="n">transaction_df</span><span class="p">[</span><span class="s">'amount'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">transaction_df</span><span class="p">[</span><span class="s">'amount'</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s">'coerce'</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">transaction_df</span>
    
    <span class="k">def</span> <span class="nf">_create_feature_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">activity_df</span><span class="p">,</span> <span class="n">transaction_df</span><span class="p">,</span> <span class="n">interaction_df</span><span class="p">):</span>
        <span class="s">"""Engineer features from raw data"""</span>
        
        <span class="c1"># User activity features
</span>        <span class="n">activity_features</span> <span class="o">=</span> <span class="n">activity_df</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'user_id'</span><span class="p">).</span><span class="n">agg</span><span class="p">({</span>
            <span class="s">'session_duration'</span><span class="p">:</span> <span class="p">[</span><span class="s">'mean'</span><span class="p">,</span> <span class="s">'std'</span><span class="p">,</span> <span class="s">'count'</span><span class="p">,</span> <span class="s">'sum'</span><span class="p">],</span>
            <span class="s">'page_views'</span><span class="p">:</span> <span class="p">[</span><span class="s">'sum'</span><span class="p">,</span> <span class="s">'mean'</span><span class="p">],</span>
            <span class="s">'clicks'</span><span class="p">:</span> <span class="p">[</span><span class="s">'sum'</span><span class="p">,</span> <span class="s">'mean'</span><span class="p">],</span>
            <span class="s">'scroll_depth'</span><span class="p">:</span> <span class="p">[</span><span class="s">'mean'</span><span class="p">,</span> <span class="s">'max'</span><span class="p">]</span>
        <span class="p">}).</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        
        <span class="c1"># Flatten column names
</span>        <span class="n">activity_features</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'_'</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">col</span><span class="p">).</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">activity_features</span><span class="p">.</span><span class="n">columns</span><span class="p">]</span>
        
        <span class="c1"># Calculate engagement metrics
</span>        <span class="n">activity_features</span><span class="p">[</span><span class="s">'avg_ctr'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">activity_features</span><span class="p">[</span><span class="s">'clicks_sum'</span><span class="p">]</span> <span class="o">/</span> 
            <span class="p">(</span><span class="n">activity_features</span><span class="p">[</span><span class="s">'page_views_sum'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="n">activity_features</span><span class="p">[</span><span class="s">'engagement_score'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">activity_features</span><span class="p">[</span><span class="s">'session_duration_mean'</span><span class="p">]</span> <span class="o">*</span> 
            <span class="n">activity_features</span><span class="p">[</span><span class="s">'avg_ctr'</span><span class="p">]</span> <span class="o">*</span> 
            <span class="n">activity_features</span><span class="p">[</span><span class="s">'scroll_depth_mean'</span><span class="p">]</span>
        <span class="p">)</span>
        
        <span class="c1"># Transaction features
</span>        <span class="n">transaction_features</span> <span class="o">=</span> <span class="n">transaction_df</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'user_id'</span><span class="p">).</span><span class="n">agg</span><span class="p">({</span>
            <span class="s">'amount'</span><span class="p">:</span> <span class="p">[</span><span class="s">'sum'</span><span class="p">,</span> <span class="s">'mean'</span><span class="p">,</span> <span class="s">'count'</span><span class="p">,</span> <span class="s">'std'</span><span class="p">],</span>
            <span class="s">'category'</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="n">nunique</span><span class="p">(),</span>
            <span class="s">'payment_method'</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="n">mode</span><span class="p">().</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s">'unknown'</span>
        <span class="p">})</span>
        
        <span class="n">transaction_features</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'_'</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">col</span><span class="p">).</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">transaction_features</span><span class="p">.</span><span class="n">columns</span><span class="p">]</span>
        
        <span class="c1"># Time-based features
</span>        <span class="n">transaction_df</span><span class="p">[</span><span class="s">'hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">transaction_df</span><span class="p">[</span><span class="s">'transaction_date'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">hour</span>
        <span class="n">transaction_df</span><span class="p">[</span><span class="s">'day_of_week'</span><span class="p">]</span> <span class="o">=</span> <span class="n">transaction_df</span><span class="p">[</span><span class="s">'transaction_date'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">dayofweek</span>
        
        <span class="n">time_features</span> <span class="o">=</span> <span class="n">transaction_df</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'user_id'</span><span class="p">).</span><span class="n">agg</span><span class="p">({</span>
            <span class="s">'hour'</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="n">mode</span><span class="p">().</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">12</span><span class="p">,</span>  <span class="c1"># Preferred shopping hour
</span>            <span class="s">'day_of_week'</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="n">mode</span><span class="p">().</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>  <span class="c1"># Preferred shopping day
</span>        <span class="p">})</span>
        
        <span class="n">time_features</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'preferred_hour'</span><span class="p">,</span> <span class="s">'preferred_day'</span><span class="p">]</span>
        
        <span class="c1"># Combine all features
</span>        <span class="n">feature_matrix</span> <span class="o">=</span> <span class="n">activity_features</span><span class="p">.</span><span class="n">join</span><span class="p">([</span><span class="n">transaction_features</span><span class="p">,</span> <span class="n">time_features</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s">'outer'</span><span class="p">)</span>
        
        <span class="c1"># Handle missing values with business logic
</span>        <span class="n">feature_matrix</span> <span class="o">=</span> <span class="n">feature_matrix</span><span class="p">.</span><span class="n">fillna</span><span class="p">({</span>
            <span class="s">'session_duration_mean'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s">'clicks_sum'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s">'amount_sum'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s">'engagement_score'</span><span class="p">:</span> <span class="mi">0</span>
        <span class="p">})</span>
        
        <span class="c1"># Add derived features
</span>        <span class="n">feature_matrix</span><span class="p">[</span><span class="s">'is_high_value'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">feature_matrix</span><span class="p">[</span><span class="s">'amount_sum'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">feature_matrix</span><span class="p">[</span><span class="s">'amount_sum'</span><span class="p">].</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.8</span><span class="p">)).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">feature_matrix</span><span class="p">[</span><span class="s">'is_frequent_user'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">feature_matrix</span><span class="p">[</span><span class="s">'session_duration_count'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">feature_matrix</span>

<span class="c1"># Example usage
</span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'database_url'</span><span class="p">:</span> <span class="s">'postgresql://user:pass@localhost:5432/mlops'</span><span class="p">,</span>
    <span class="s">'s3_bucket'</span><span class="p">:</span> <span class="s">'ml-datalake'</span><span class="p">,</span>
    <span class="s">'redis_host'</span><span class="p">:</span> <span class="s">'localhost'</span>
<span class="p">}</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">FeaturePipeline</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">user_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1001</span><span class="p">,</span> <span class="mi">1002</span><span class="p">,</span> <span class="mi">1003</span><span class="p">,</span> <span class="mi">1004</span><span class="p">,</span> <span class="mi">1005</span><span class="p">]</span>
<span class="n">date_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">30</span><span class="p">),</span> <span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">())</span>

<span class="n">features</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">extract_user_features</span><span class="p">(</span><span class="n">user_list</span><span class="p">,</span> <span class="n">date_range</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Feature matrix shape: </span><span class="si">{</span><span class="n">features</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Features: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">features</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h4 id="real-time-data-stream-processing">Real-time Data Stream Processing</h4>
<p>Processing streaming data for real-time feature computation:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">kafka</span> <span class="kn">import</span> <span class="n">KafkaConsumer</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">redis</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>

<span class="k">class</span> <span class="nc">RealTimeFeatureProcessor</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kafka_config</span><span class="p">,</span> <span class="n">redis_client</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">consumer</span> <span class="o">=</span> <span class="n">KafkaConsumer</span><span class="p">(</span>
            <span class="s">'user-events'</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kafka_config</span><span class="p">,</span>
            <span class="n">value_deserializer</span><span class="o">=</span><span class="k">lambda</span> <span class="n">m</span><span class="p">:</span> <span class="n">json</span><span class="p">.</span><span class="n">loads</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">redis_client</span> <span class="o">=</span> <span class="n">redis_client</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">minutes</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">feature_buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>  <span class="c1"># Circular buffer for memory efficiency
</span>        
    <span class="k">def</span> <span class="nf">process_stream</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""Process real-time event stream and maintain feature windows"""</span>
        
        <span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">consumer</span><span class="p">:</span>
            <span class="n">event_data</span> <span class="o">=</span> <span class="n">message</span><span class="p">.</span><span class="n">value</span>
            
            <span class="c1"># Convert to DataFrame for consistent processing
</span>            <span class="n">event_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">event_data</span><span class="p">])</span>
            <span class="n">event_df</span><span class="p">[</span><span class="s">'timestamp'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">event_df</span><span class="p">[</span><span class="s">'timestamp'</span><span class="p">])</span>
            
            <span class="c1"># Add to buffer
</span>            <span class="bp">self</span><span class="p">.</span><span class="n">feature_buffer</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">event_data</span><span class="p">)</span>
            
            <span class="c1"># Calculate windowed features
</span>            <span class="n">current_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">()</span>
            <span class="n">window_start</span> <span class="o">=</span> <span class="n">current_time</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">window_size</span>
            
            <span class="c1"># Filter recent events
</span>            <span class="n">recent_events</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">event</span> <span class="k">for</span> <span class="n">event</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">feature_buffer</span> 
                <span class="k">if</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">event</span><span class="p">[</span><span class="s">'timestamp'</span><span class="p">])</span> <span class="o">&gt;</span> <span class="n">window_start</span>
            <span class="p">]</span>
            
            <span class="k">if</span> <span class="n">recent_events</span><span class="p">:</span>
                <span class="n">recent_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">recent_events</span><span class="p">)</span>
                <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_calculate_windowed_features</span><span class="p">(</span><span class="n">recent_df</span><span class="p">)</span>
                
                <span class="c1"># Store features in Redis for real-time serving
</span>                <span class="bp">self</span><span class="p">.</span><span class="n">_store_features_redis</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_calculate_windowed_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>
        <span class="s">"""Calculate features over a time window"""</span>
        
        <span class="c1"># Ensure proper data types
</span>        <span class="n">df</span><span class="p">[</span><span class="s">'timestamp'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'timestamp'</span><span class="p">])</span>
        <span class="n">df</span><span class="p">[</span><span class="s">'page_views'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'page_views'</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s">'coerce'</span><span class="p">).</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">df</span><span class="p">[</span><span class="s">'clicks'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'clicks'</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s">'coerce'</span><span class="p">).</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># Group by user and calculate features
</span>        <span class="n">user_features</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'user_id'</span><span class="p">).</span><span class="n">agg</span><span class="p">({</span>
            <span class="s">'page_views'</span><span class="p">:</span> <span class="p">[</span><span class="s">'sum'</span><span class="p">,</span> <span class="s">'count'</span><span class="p">],</span>
            <span class="s">'clicks'</span><span class="p">:</span> <span class="s">'sum'</span><span class="p">,</span>
            <span class="s">'session_duration'</span><span class="p">:</span> <span class="s">'mean'</span><span class="p">,</span>
            <span class="s">'timestamp'</span><span class="p">:</span> <span class="s">'count'</span>  <span class="c1"># Event frequency
</span>        <span class="p">})</span>
        
        <span class="c1"># Flatten columns
</span>        <span class="n">user_features</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'_'</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">col</span><span class="p">).</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">user_features</span><span class="p">.</span><span class="n">columns</span><span class="p">]</span>
        
        <span class="c1"># Add time-based features
</span>        <span class="n">current_hour</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">().</span><span class="n">hour</span>
        <span class="n">user_features</span><span class="p">[</span><span class="s">'current_hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_hour</span>
        <span class="n">user_features</span><span class="p">[</span><span class="s">'is_business_hours'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">9</span> <span class="o">&lt;=</span> <span class="n">current_hour</span> <span class="o">&lt;=</span> <span class="mi">17</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        
        <span class="c1"># Calculate rates
</span>        <span class="n">user_features</span><span class="p">[</span><span class="s">'click_rate'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">user_features</span><span class="p">[</span><span class="s">'clicks_sum'</span><span class="p">]</span> <span class="o">/</span> 
            <span class="p">(</span><span class="n">user_features</span><span class="p">[</span><span class="s">'page_views_sum'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="n">user_features</span><span class="p">[</span><span class="s">'events_per_minute'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">user_features</span><span class="p">[</span><span class="s">'timestamp_count'</span><span class="p">]</span> <span class="o">/</span> <span class="mi">5</span>  <span class="c1"># 5-minute window
</span>        <span class="p">)</span>
        
        <span class="k">return</span> <span class="n">user_features</span>
    
    <span class="k">def</span> <span class="nf">_store_features_redis</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
        <span class="s">"""Store computed features in Redis with TTL"""</span>
        
        <span class="k">for</span> <span class="n">user_id</span> <span class="ow">in</span> <span class="n">features</span><span class="p">.</span><span class="n">index</span><span class="p">:</span>
            <span class="n">feature_dict</span> <span class="o">=</span> <span class="n">features</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">user_id</span><span class="p">].</span><span class="n">to_dict</span><span class="p">()</span>
            
            <span class="c1"># Store with 10-minute TTL
</span>            <span class="n">key</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"user_features:</span><span class="si">{</span><span class="n">user_id</span><span class="si">}</span><span class="s">"</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">redis_client</span><span class="p">.</span><span class="n">hmset</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">feature_dict</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">redis_client</span><span class="p">.</span><span class="n">expire</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">600</span><span class="p">)</span>  <span class="c1"># 10 minutes
</span>
<span class="c1"># Production deployment example
</span><span class="k">def</span> <span class="nf">deploy_stream_processor</span><span class="p">():</span>
    <span class="n">kafka_config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'bootstrap_servers'</span><span class="p">:</span> <span class="p">[</span><span class="s">'kafka1:9092'</span><span class="p">,</span> <span class="s">'kafka2:9092'</span><span class="p">],</span>
        <span class="s">'group_id'</span><span class="p">:</span> <span class="s">'feature-processor'</span><span class="p">,</span>
        <span class="s">'auto_offset_reset'</span><span class="p">:</span> <span class="s">'latest'</span><span class="p">,</span>
        <span class="s">'enable_auto_commit'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
        <span class="s">'value_deserializer'</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">m</span><span class="p">:</span> <span class="n">json</span><span class="p">.</span><span class="n">loads</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
    <span class="p">}</span>
    
    <span class="n">redis_client</span> <span class="o">=</span> <span class="n">redis</span><span class="p">.</span><span class="n">Redis</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="s">'redis-cluster.example.com'</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="mi">6379</span><span class="p">,</span>
        <span class="n">decode_responses</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>
    
    <span class="n">processor</span> <span class="o">=</span> <span class="n">RealTimeFeatureProcessor</span><span class="p">(</span><span class="n">kafka_config</span><span class="p">,</span> <span class="n">redis_client</span><span class="p">)</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="n">processor</span><span class="p">.</span><span class="n">process_stream</span><span class="p">()</span>
    <span class="k">except</span> <span class="nb">KeyboardInterrupt</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Shutting down stream processor..."</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Error in stream processing: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="c1"># Add error handling and retry logic
</span>
<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">deploy_stream_processor</span><span class="p">()</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="mlops-production-tips-1">MLOps Production Tips</h3>

<p>Performance and scalability best practices for MLOps:</p>

<ul>
  <li><strong>Format Optimization</strong>: Use Parquet format for 5-10x faster I/O compared to CSV</li>
  <li><strong>Memory Management</strong>: Use categorical dtypes and optimize data types to reduce memory usage</li>
  <li><strong>Chunk Processing</strong>: Process large datasets in chunks to avoid memory overflow</li>
  <li><strong>Parallel Processing</strong>: Leverage Dask for distributed computing when datasets exceed single-machine capacity</li>
  <li><strong>Data Validation</strong>: Implement Great Expectations for automated data quality checks</li>
  <li><strong>Caching Strategy</strong>: Cache intermediate results and use efficient storage formats</li>
</ul>

<hr />

<h2 id="scikit-learn-complete-machine-learning-pipeline-framework">Scikit-Learn: Complete Machine Learning Pipeline Framework</h2>

<p>Scikit-Learn provides a unified, production-ready framework for building complete machine learning pipelines. Its consistent API design and powerful pipeline patterns enable seamless workflows from experimentation to deployment, making it the gold standard for traditional machine learning tasks.</p>

<p><br /></p>

<h3 id="why-scikit-learn-is-central-to-mlops">Why Scikit-Learn is Central to MLOps</h3>

<p>Scikit-Learn isn’t just a machine learning library—it’s the complete ML ecosystem for MLOps:</p>

<ul>
  <li><strong>Consistent API</strong>: Uniform fit(), predict(), transform() interface across all components</li>
  <li><strong>Pipeline Architecture</strong>: Combines preprocessing and modeling into single, deployable objects</li>
  <li><strong>Model Selection</strong>: Built-in cross-validation and hyperparameter tuning capabilities</li>
  <li><strong>Production Ready</strong>: Robust serialization with joblib for model persistence</li>
  <li><strong>Extensive Algorithms</strong>: Comprehensive collection of supervised and unsupervised learning algorithms</li>
  <li><strong>Integration Friendly</strong>: Seamless compatibility with NumPy, Pandas, and deployment frameworks</li>
</ul>

<p><br /></p>

<h3 id="core-scikit-learn-components">Core Scikit-Learn Components</h3>

<div class="table-container">
  <table class="table-beauty">
    <tr>
      <th style="width: 25%;">Component Category</th>
      <th style="width: 35%;">Key Classes</th>
      <th style="width: 40%;">MLOps Applications</th>
    </tr>
    <tr>
      <td><strong>Preprocessing</strong></td>
      <td>StandardScaler, OneHotEncoder, LabelEncoder</td>
      <td>Feature normalization, categorical encoding, data transformation</td>
    </tr>
    <tr>
      <td><strong>Models</strong></td>
      <td>RandomForest, SVM, LogisticRegression, XGBoost</td>
      <td>Classification, regression, prediction tasks</td>
    </tr>
    <tr>
      <td><strong>Pipeline</strong></td>
      <td>Pipeline, ColumnTransformer, FeatureUnion</td>
      <td>Workflow automation, reproducible preprocessing</td>
    </tr>
    <tr>
      <td><strong>Model Selection</strong></td>
      <td>GridSearchCV, RandomizedSearchCV, cross_val_score</td>
      <td>Hyperparameter tuning, model validation, performance estimation</td>
    </tr>
    <tr>
      <td><strong>Metrics</strong></td>
      <td>accuracy_score, precision_recall_curve, roc_auc_score</td>
      <td>Model evaluation, performance monitoring, A/B testing</td>
    </tr>
  </table>
</div>

<p><br /></p>

<h3 id="production-ready-implementation-examples">Production-Ready Implementation Examples</h3>

<h4 id="complete-ml-pipeline-with-best-practices">Complete ML Pipeline with Best Practices</h4>

<p>Building a robust, production-ready machine learning pipeline:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">joblib</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="nn">logging</span>

<span class="k">class</span> <span class="nc">ProductionMLPipeline</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span> <span class="ow">or</span> <span class="bp">self</span><span class="p">.</span><span class="n">_default_config</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">is_trained</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">training_metadata</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">logger</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_setup_logging</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">_default_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""Default configuration for the ML pipeline"""</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s">'model_type'</span><span class="p">:</span> <span class="s">'random_forest'</span><span class="p">,</span>
            <span class="s">'random_state'</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
            <span class="s">'test_size'</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span>
            <span class="s">'cv_folds'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
            <span class="s">'n_jobs'</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
            <span class="s">'hyperparameter_tuning'</span><span class="p">:</span> <span class="bp">True</span>
        <span class="p">}</span>
    
    <span class="k">def</span> <span class="nf">_setup_logging</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""Configure logging for the pipeline"""</span>
        <span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="p">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>
        <span class="n">logger</span><span class="p">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="p">.</span><span class="n">INFO</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="n">logger</span><span class="p">.</span><span class="n">handlers</span><span class="p">:</span>
            <span class="n">handler</span> <span class="o">=</span> <span class="n">logging</span><span class="p">.</span><span class="n">StreamHandler</span><span class="p">()</span>
            <span class="n">formatter</span> <span class="o">=</span> <span class="n">logging</span><span class="p">.</span><span class="n">Formatter</span><span class="p">(</span>
                <span class="s">'%(asctime)s - %(name)s - %(levelname)s - %(message)s'</span>
            <span class="p">)</span>
            <span class="n">handler</span><span class="p">.</span><span class="n">setFormatter</span><span class="p">(</span><span class="n">formatter</span><span class="p">)</span>
            <span class="n">logger</span><span class="p">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">handler</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">logger</span>
    
    <span class="k">def</span> <span class="nf">build_pipeline</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_config</span><span class="p">):</span>
        <span class="s">"""Build a complete ML pipeline with preprocessing and modeling"""</span>
        
        <span class="n">numeric_features</span> <span class="o">=</span> <span class="n">feature_config</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'numeric_features'</span><span class="p">,</span> <span class="p">[])</span>
        <span class="n">categorical_features</span> <span class="o">=</span> <span class="n">feature_config</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'categorical_features'</span><span class="p">,</span> <span class="p">[])</span>
        
        <span class="c1"># Create preprocessing pipeline
</span>        <span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
            <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
                <span class="p">(</span><span class="s">'num'</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">numeric_features</span><span class="p">),</span>
                <span class="p">(</span><span class="s">'cat'</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s">'first'</span><span class="p">,</span> <span class="n">sparse_output</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">),</span> 
                 <span class="n">categorical_features</span><span class="p">)</span>
            <span class="p">],</span>
            <span class="n">remainder</span><span class="o">=</span><span class="s">'passthrough'</span>  <span class="c1"># Keep other columns as-is
</span>        <span class="p">)</span>
        
        <span class="c1"># Select model based on configuration
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'model_type'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'random_forest'</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span>
                <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'random_state'</span><span class="p">],</span>
                <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'n_jobs'</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'model_type'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'logistic_regression'</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span>
                <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'random_state'</span><span class="p">],</span>
                <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'n_jobs'</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s">"Unsupported model type: </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'model_type'</span><span class="p">]</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        
        <span class="c1"># Create complete pipeline
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s">'preprocessor'</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
            <span class="p">(</span><span class="s">'classifier'</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="p">])</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Built pipeline with </span><span class="si">{</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'model_type'</span><span class="p">]</span><span class="si">}</span><span class="s"> model"</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">feature_config</span><span class="p">):</span>
        <span class="s">"""Train the model with comprehensive validation"""</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">build_pipeline</span><span class="p">(</span><span class="n">feature_config</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Starting model training..."</span><span class="p">)</span>
        <span class="n">training_start</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">()</span>
        
        <span class="c1"># Split data
</span>        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
            <span class="n">test_size</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'test_size'</span><span class="p">],</span> 
            <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'random_state'</span><span class="p">],</span>
            <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
        <span class="p">)</span>
        
        <span class="c1"># Hyperparameter tuning if enabled
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'hyperparameter_tuning'</span><span class="p">]:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_tune_hyperparameters</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        
        <span class="c1"># Train final model
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">is_trained</span> <span class="o">=</span> <span class="bp">True</span>
        
        <span class="c1"># Evaluate model
</span>        <span class="n">train_score</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">test_score</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
        
        <span class="c1"># Cross-validation
</span>        <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
            <span class="n">cv</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'cv_folds'</span><span class="p">],</span> 
            <span class="n">scoring</span><span class="o">=</span><span class="s">'accuracy'</span>
        <span class="p">)</span>
        
        <span class="c1"># Generate detailed evaluation
</span>        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">classification_rep</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">output_dict</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        
        <span class="c1"># Store training metadata
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">training_metadata</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">'training_time'</span><span class="p">:</span> <span class="p">(</span><span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">training_start</span><span class="p">).</span><span class="n">total_seconds</span><span class="p">(),</span>
            <span class="s">'train_accuracy'</span><span class="p">:</span> <span class="n">train_score</span><span class="p">,</span>
            <span class="s">'test_accuracy'</span><span class="p">:</span> <span class="n">test_score</span><span class="p">,</span>
            <span class="s">'cv_mean'</span><span class="p">:</span> <span class="n">cv_scores</span><span class="p">.</span><span class="n">mean</span><span class="p">(),</span>
            <span class="s">'cv_std'</span><span class="p">:</span> <span class="n">cv_scores</span><span class="p">.</span><span class="n">std</span><span class="p">(),</span>
            <span class="s">'train_samples'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span>
            <span class="s">'test_samples'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
            <span class="s">'feature_count'</span><span class="p">:</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="s">'classification_report'</span><span class="p">:</span> <span class="n">classification_rep</span><span class="p">,</span>
            <span class="s">'model_config'</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">,</span>
            <span class="s">'timestamp'</span><span class="p">:</span> <span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">().</span><span class="n">isoformat</span><span class="p">()</span>
        <span class="p">}</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Training completed. Test accuracy: </span><span class="si">{</span><span class="n">test_score</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">training_metadata</span>
    
    <span class="k">def</span> <span class="nf">_tune_hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
        <span class="s">"""Perform hyperparameter tuning"""</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Starting hyperparameter tuning..."</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'model_type'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'random_forest'</span><span class="p">:</span>
            <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s">'classifier__n_estimators'</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span>
                <span class="s">'classifier__max_depth'</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span>
                <span class="s">'classifier__min_samples_split'</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
                <span class="s">'classifier__min_samples_leaf'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
            <span class="p">}</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'model_type'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'logistic_regression'</span><span class="p">:</span>
            <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s">'classifier__C'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">],</span>
                <span class="s">'classifier__penalty'</span><span class="p">:</span> <span class="p">[</span><span class="s">'l1'</span><span class="p">,</span> <span class="s">'l2'</span><span class="p">],</span>
                <span class="s">'classifier__solver'</span><span class="p">:</span> <span class="p">[</span><span class="s">'liblinear'</span><span class="p">,</span> <span class="s">'saga'</span><span class="p">]</span>
            <span class="p">}</span>
        
        <span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span><span class="p">,</span> 
            <span class="n">param_grid</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>  <span class="c1"># Reduced for faster tuning
</span>            <span class="n">scoring</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'n_jobs'</span><span class="p">],</span>
            <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        
        <span class="n">grid_search</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Best parameters: </span><span class="si">{</span><span class="n">grid_search</span><span class="p">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Best CV score: </span><span class="si">{</span><span class="n">grid_search</span><span class="p">.</span><span class="n">best_score_</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">grid_search</span><span class="p">.</span><span class="n">best_estimator_</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="s">"""Make predictions with the trained model"""</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">is_trained</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">"Model must be trained before making predictions"</span><span class="p">)</span>
        
        <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">probabilities</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="s">'predict_proba'</span><span class="p">)</span> <span class="k">else</span> <span class="bp">None</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="s">'predictions'</span><span class="p">:</span> <span class="n">predictions</span><span class="p">.</span><span class="n">tolist</span><span class="p">(),</span>
            <span class="s">'probabilities'</span><span class="p">:</span> <span class="n">probabilities</span><span class="p">.</span><span class="n">tolist</span><span class="p">()</span> <span class="k">if</span> <span class="n">probabilities</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="k">else</span> <span class="bp">None</span>
        <span class="p">}</span>
    
    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">):</span>
        <span class="s">"""Save the trained model with metadata"""</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">is_trained</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">"Cannot save untrained model"</span><span class="p">)</span>
        
        <span class="n">model_data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">'pipeline'</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span><span class="p">,</span>
            <span class="s">'metadata'</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">training_metadata</span><span class="p">,</span>
            <span class="s">'config'</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">config</span>
        <span class="p">}</span>
        
        <span class="n">joblib</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model_data</span><span class="p">,</span> <span class="n">filepath</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s">"Model saved to </span><span class="si">{</span><span class="n">filepath</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="o">@</span><span class="nb">classmethod</span>
    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">filepath</span><span class="p">):</span>
        <span class="s">"""Load a saved model"""</span>
        
        <span class="n">model_data</span> <span class="o">=</span> <span class="n">joblib</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
        
        <span class="n">instance</span> <span class="o">=</span> <span class="n">cls</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">model_data</span><span class="p">[</span><span class="s">'config'</span><span class="p">])</span>
        <span class="n">instance</span><span class="p">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">model_data</span><span class="p">[</span><span class="s">'pipeline'</span><span class="p">]</span>
        <span class="n">instance</span><span class="p">.</span><span class="n">training_metadata</span> <span class="o">=</span> <span class="n">model_data</span><span class="p">[</span><span class="s">'metadata'</span><span class="p">]</span>
        <span class="n">instance</span><span class="p">.</span><span class="n">is_trained</span> <span class="o">=</span> <span class="bp">True</span>
        
        <span class="k">return</span> <span class="n">instance</span>
    
    <span class="k">def</span> <span class="nf">get_feature_importance</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""Get feature importance if available"""</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">.</span><span class="n">is_trained</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nb">ValueError</span><span class="p">(</span><span class="s">"Model must be trained first"</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span><span class="p">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s">'classifier'</span><span class="p">],</span> <span class="s">'feature_importances_'</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">pipeline</span><span class="p">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s">'classifier'</span><span class="p">].</span><span class="n">feature_importances_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">None</span>

<span class="c1"># Example usage with comprehensive validation
</span><span class="k">def</span> <span class="nf">train_production_model</span><span class="p">():</span>
    <span class="s">"""Example of training a production-ready model"""</span>
    
    <span class="c1"># Load data
</span>    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'user_behavior_dataset.csv'</span><span class="p">)</span>
    
    <span class="c1"># Define features
</span>    <span class="n">feature_config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'numeric_features'</span><span class="p">:</span> <span class="p">[</span><span class="s">'age'</span><span class="p">,</span> <span class="s">'income'</span><span class="p">,</span> <span class="s">'session_duration'</span><span class="p">,</span> <span class="s">'page_views'</span><span class="p">],</span>
        <span class="s">'categorical_features'</span><span class="p">:</span> <span class="p">[</span><span class="s">'gender'</span><span class="p">,</span> <span class="s">'device_type'</span><span class="p">,</span> <span class="s">'region'</span><span class="p">,</span> <span class="s">'subscription_type'</span><span class="p">]</span>
    <span class="p">}</span>
    
    <span class="c1"># Prepare data
</span>    <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">feature_config</span><span class="p">[</span><span class="s">'numeric_features'</span><span class="p">]</span> <span class="o">+</span> <span class="n">feature_config</span><span class="p">[</span><span class="s">'categorical_features'</span><span class="p">]]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'target'</span><span class="p">]</span>
    
    <span class="c1"># Initialize and train pipeline
</span>    <span class="n">ml_pipeline</span> <span class="o">=</span> <span class="n">ProductionMLPipeline</span><span class="p">({</span>
        <span class="s">'model_type'</span><span class="p">:</span> <span class="s">'random_forest'</span><span class="p">,</span>
        <span class="s">'hyperparameter_tuning'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
        <span class="s">'cv_folds'</span><span class="p">:</span> <span class="mi">5</span>
    <span class="p">})</span>
    
    <span class="c1"># Train model
</span>    <span class="n">results</span> <span class="o">=</span> <span class="n">ml_pipeline</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">feature_config</span><span class="p">)</span>
    
    <span class="c1"># Save model
</span>    <span class="n">ml_pipeline</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="s">'models/production_model.pkl'</span><span class="p">)</span>
    
    <span class="c1"># Print results
</span>    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Model Performance:"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Test Accuracy: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s">'test_accuracy'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  CV Score: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s">'cv_mean'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> ± </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s">'cv_std'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Training Time: </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s">'training_time'</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">ml_pipeline</span>

<span class="c1"># Load and use trained model
</span><span class="k">def</span> <span class="nf">use_trained_model</span><span class="p">():</span>
    <span class="s">"""Example of loading and using a trained model"""</span>
    
    <span class="c1"># Load model
</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">ProductionMLPipeline</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">'models/production_model.pkl'</span><span class="p">)</span>
    
    <span class="c1"># Make predictions on new data
</span>    <span class="n">new_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s">'age'</span><span class="p">:</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">45</span><span class="p">],</span>
        <span class="s">'income'</span><span class="p">:</span> <span class="p">[</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">75000</span><span class="p">,</span> <span class="mi">100000</span><span class="p">],</span>
        <span class="s">'session_duration'</span><span class="p">:</span> <span class="p">[</span><span class="mi">120</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">90</span><span class="p">],</span>
        <span class="s">'page_views'</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="s">'gender'</span><span class="p">:</span> <span class="p">[</span><span class="s">'M'</span><span class="p">,</span> <span class="s">'F'</span><span class="p">,</span> <span class="s">'M'</span><span class="p">],</span>
        <span class="s">'device_type'</span><span class="p">:</span> <span class="p">[</span><span class="s">'mobile'</span><span class="p">,</span> <span class="s">'desktop'</span><span class="p">,</span> <span class="s">'tablet'</span><span class="p">],</span>
        <span class="s">'region'</span><span class="p">:</span> <span class="p">[</span><span class="s">'US'</span><span class="p">,</span> <span class="s">'EU'</span><span class="p">,</span> <span class="s">'ASIA'</span><span class="p">],</span>
        <span class="s">'subscription_type'</span><span class="p">:</span> <span class="p">[</span><span class="s">'basic'</span><span class="p">,</span> <span class="s">'premium'</span><span class="p">,</span> <span class="s">'basic'</span><span class="p">]</span>
    <span class="p">})</span>
    
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new_data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">predictions</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="c1"># Train model
</span>    <span class="n">trained_model</span> <span class="o">=</span> <span class="n">train_production_model</span><span class="p">()</span>
    
    <span class="c1"># Use model for predictions
</span>    <span class="n">predictions</span> <span class="o">=</span> <span class="n">use_trained_model</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Predictions: </span><span class="si">{</span><span class="n">predictions</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h4 id="model-comparison-for-ab-testing">Model Comparison for A/B Testing</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="k">class</span> <span class="nc">ModelExperiment</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">experiment_name</span><span class="p">):</span>
        <span class="n">mlflow</span><span class="p">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="n">experiment_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">'random_forest'</span><span class="p">:</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
            <span class="s">'gradient_boosting'</span><span class="p">:</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
            <span class="s">'logistic_regression'</span><span class="p">:</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
        <span class="p">}</span>
    
    <span class="k">def</span> <span class="nf">run_experiment</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
        <span class="s">"""Run experiment comparing multiple models"""</span>
        
        <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">with</span> <span class="n">mlflow</span><span class="p">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">):</span>
                
                <span class="c1"># Train model
</span>                <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
                
                <span class="c1"># Make predictions
</span>                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
                <span class="n">y_prob</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s">'predict_proba'</span><span class="p">)</span> <span class="k">else</span> <span class="bp">None</span>
                
                <span class="c1"># Calculate performance metrics
</span>                <span class="n">accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
                
                <span class="c1"># Log to MLflow
</span>                <span class="n">mlflow</span><span class="p">.</span><span class="n">log_param</span><span class="p">(</span><span class="s">"model_type"</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
                <span class="n">mlflow</span><span class="p">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s">"accuracy"</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s">'feature_importances_'</span><span class="p">):</span>
                    <span class="c1"># Log feature importance
</span>                    <span class="n">feature_importance</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span>
                        <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> 
                        <span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span>
                    <span class="p">))</span>
                    <span class="n">mlflow</span><span class="p">.</span><span class="n">log_params</span><span class="p">(</span><span class="n">feature_importance</span><span class="p">)</span>
                
                <span class="c1"># Save model
</span>                <span class="n">mlflow</span><span class="p">.</span><span class="n">sklearn</span><span class="p">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s">_model"</span><span class="p">)</span>
                
                <span class="n">results</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s">'accuracy'</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">,</span>
                    <span class="s">'model'</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span>
                    <span class="s">'predictions'</span><span class="p">:</span> <span class="n">y_pred</span>
                <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">results</span>
</code></pre></div></div>

<h3 id="mlops-production-tips-2">MLOps Production Tips</h3>

<h4 id="1-model-version-management">1. Model Version Management:</h4>
<ul>
  <li>Manage model lifecycle with MLflow Model Registry</li>
  <li>Include metadata in models (training date, data version, etc.)</li>
</ul>

<h4 id="2-deployment-optimization">2. Deployment Optimization:</h4>
<ul>
  <li>Convert to ONNX format for improved inference performance</li>
  <li>Reduce model size with quantization</li>
</ul>

<h4 id="3-monitoring">3. Monitoring:</h4>
<ul>
  <li>Detect input data distribution changes (Data Drift)</li>
  <li>Automated alerts for model performance degradation</li>
</ul>

<hr />

<h2 id="running-locally">Running Locally</h2>

<p>Let’s build a complete MLOps pipeline using NumPy, Pandas, and Scikit-Learn as learned above. Theory alone is not enough—get hands-on and practice!</p>

<p><br /></p>

<h3 id="create-and-activate-virtual-environment">Create and Activate Virtual Environment</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Create virtual environment</span>
python3 <span class="nt">-m</span> venv venv
<span class="nb">source </span>venv/bin/activate  <span class="c"># Windows: venv\Scripts\activate</span>

<span class="c"># Result: (venv) prompt appears, indicating the environment is active</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="install-dependencies">Install Dependencies</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Install required packages</span>
pip3 <span class="nb">install </span>numpy pandas scikit-learn fastapi uvicorn

<span class="c"># Result: Required packages are installed and progress is shown</span>
<span class="c"># Collecting numpy&gt;=1.26.0</span>
<span class="c"># Collecting pandas&gt;=2.1.0  </span>
<span class="c"># Collecting scikit-learn&gt;=1.3.2</span>
<span class="c"># ...</span>
<span class="c"># Successfully installed numpy-1.26.0 pandas-2.1.0 scikit-learn-1.3.2 ...</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="data-preprocessing">Data Preprocessing</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># preprocess.py
</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">def</span> <span class="nf">preprocess_data</span><span class="p">():</span>
    <span class="s">"""Generate and preprocess sample data"""</span>
    
    <span class="c1"># Generate sample user behavior data
</span>    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>
    
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s">'age'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">65</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">),</span>
        <span class="s">'income'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">15000</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">),</span>
        <span class="s">'session_duration'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">),</span>
        <span class="s">'page_views'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">poisson</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">),</span>
        <span class="s">'purchases'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="p">})</span>
    
    <span class="c1"># Feature engineering
</span>    <span class="n">data</span><span class="p">[</span><span class="s">'income_age_ratio'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'income'</span><span class="p">]</span> <span class="o">/</span> <span class="n">data</span><span class="p">[</span><span class="s">'age'</span><span class="p">]</span>
    <span class="n">data</span><span class="p">[</span><span class="s">'engagement_score'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'session_duration'</span><span class="p">]</span> <span class="o">*</span> <span class="n">data</span><span class="p">[</span><span class="s">'page_views'</span><span class="p">])</span> <span class="o">/</span> <span class="mi">100</span>
    
    <span class="c1"># Prepare features and target
</span>    <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s">'age'</span><span class="p">,</span> <span class="s">'income'</span><span class="p">,</span> <span class="s">'session_duration'</span><span class="p">,</span> <span class="s">'page_views'</span><span class="p">,</span> <span class="s">'income_age_ratio'</span><span class="p">,</span> <span class="s">'engagement_score'</span><span class="p">]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'purchases'</span><span class="p">]</span>
    
    <span class="c1"># Feature scaling
</span>    <span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
    <span class="n">X_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>
    
    <span class="c1"># Save processed data
</span>    <span class="n">os</span><span class="p">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s">'data'</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">X_scaled</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">'data/X.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">y</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">'data/y.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    
    <span class="c1"># Save scaler for production use
</span>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'data/scaler.pkl'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"✅ Data preprocessing complete"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"📊 Dataset shape: </span><span class="si">{</span><span class="n">X_scaled</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"🎯 Target distribution: </span><span class="si">{</span><span class="n">y</span><span class="p">.</span><span class="n">value_counts</span><span class="p">().</span><span class="n">to_dict</span><span class="p">()</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">X_scaled</span><span class="p">,</span> <span class="n">y</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">preprocess_data</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Run data preprocessing</span>
python3 preprocess.py

<span class="c"># Result: Data preprocessing is complete and the following files are generated</span>
<span class="c"># ✅ Data preprocessing complete</span>
<span class="c"># 📊 Dataset shape: (1000, 6)</span>
<span class="c"># 🎯 Target distribution: {0: 700, 1: 300}</span>
<span class="c"># data/X.csv  # Preprocessed input data</span>
<span class="c"># data/y.csv  # Preprocessed target data  </span>
<span class="c"># data/scaler.pkl  # Scaler parameters</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="model-training">Model Training</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># train_model.py
</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">def</span> <span class="nf">train_model</span><span class="p">():</span>
    <span class="s">"""Train and evaluate ML model"""</span>
    
    <span class="c1"># Load processed data
</span>    <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/X.csv'</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/y.csv'</span><span class="p">).</span><span class="n">squeeze</span><span class="p">()</span>
    
    <span class="c1"># Split data
</span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
    <span class="p">)</span>
    
    <span class="c1"># Train model
</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Evaluate model
</span>    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">cv_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"🎯 Model training results:"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"   Test accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"   Cross-validation score: </span><span class="si">{</span><span class="n">cv_scores</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> ± </span><span class="si">{</span><span class="n">cv_scores</span><span class="p">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">📈 Classification report:"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
    
    <span class="c1"># Save model
</span>    <span class="n">os</span><span class="p">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s">'model'</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'model/model.pkl'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"💾 Model saved to model/model.pkl"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">train_model</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Run model training</span>
python3 train_model.py

<span class="c"># Result: Model training is complete and the following output is shown</span>
<span class="c"># 🎯 Model training results:</span>
<span class="c">#    Test accuracy: 0.8500</span>
<span class="c">#    Cross-validation score: 0.8400 ± 0.0200</span>
<span class="c"># 📈 Classification report:</span>
<span class="c"># ...</span>
<span class="c"># 💾 Model saved to model/model.pkl</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="run-api-server">Run API Server</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># predict_api.py  
</span><span class="kn">from</span> <span class="nn">fastapi</span> <span class="kn">import</span> <span class="n">FastAPI</span><span class="p">,</span> <span class="n">HTTPException</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">import</span> <span class="nn">uvicorn</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">FastAPI</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s">"MLOps Prediction API"</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s">"Production-grade ML API for hands-on MLOps practice"</span><span class="p">,</span>
    <span class="n">version</span><span class="o">=</span><span class="s">"1.0.0"</span>
<span class="p">)</span>

<span class="c1"># Load model and scaler at startup
</span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'model/model.pkl'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'data/scaler.pkl'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">PredictionRequest</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">age</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">income</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">session_duration</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">page_views</span><span class="p">:</span> <span class="nb">int</span>

<span class="o">@</span><span class="n">app</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"/"</span><span class="p">)</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">root</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">{</span><span class="s">"message"</span><span class="p">:</span> <span class="s">"MLOps Prediction API is running!"</span><span class="p">,</span> <span class="s">"status"</span><span class="p">:</span> <span class="s">"healthy"</span><span class="p">}</span>

<span class="o">@</span><span class="n">app</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"/health"</span><span class="p">)</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">health_check</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">{</span><span class="s">"status"</span><span class="p">:</span> <span class="s">"healthy"</span><span class="p">,</span> <span class="s">"model_loaded"</span><span class="p">:</span> <span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">}</span>

<span class="o">@</span><span class="n">app</span><span class="p">.</span><span class="n">post</span><span class="p">(</span><span class="s">"/predict"</span><span class="p">)</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">request</span><span class="p">:</span> <span class="n">PredictionRequest</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Feature engineering
</span>        <span class="n">income_age_ratio</span> <span class="o">=</span> <span class="n">request</span><span class="p">.</span><span class="n">income</span> <span class="o">/</span> <span class="n">request</span><span class="p">.</span><span class="n">age</span>
        <span class="n">engagement_score</span> <span class="o">=</span> <span class="p">(</span><span class="n">request</span><span class="p">.</span><span class="n">session_duration</span> <span class="o">*</span> <span class="n">request</span><span class="p">.</span><span class="n">page_views</span><span class="p">)</span> <span class="o">/</span> <span class="mi">100</span>
        
        <span class="c1"># Prepare and scale features
</span>        <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span>
            <span class="n">request</span><span class="p">.</span><span class="n">age</span><span class="p">,</span> <span class="n">request</span><span class="p">.</span><span class="n">income</span><span class="p">,</span> <span class="n">request</span><span class="p">.</span><span class="n">session_duration</span><span class="p">,</span>
            <span class="n">request</span><span class="p">.</span><span class="n">page_views</span><span class="p">,</span> <span class="n">income_age_ratio</span><span class="p">,</span> <span class="n">engagement_score</span>
        <span class="p">]])</span>
        <span class="n">features_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        
        <span class="c1"># Make prediction
</span>        <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">features_scaled</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">probability</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">features_scaled</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="s">"prediction"</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">prediction</span><span class="p">),</span>
            <span class="s">"probability"</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">probability</span><span class="p">),</span>
            <span class="s">"confidence"</span><span class="p">:</span> <span class="s">"High"</span> <span class="k">if</span> <span class="n">probability</span> <span class="o">&gt;</span> <span class="mf">0.8</span> <span class="k">else</span> <span class="s">"Medium"</span> <span class="k">if</span> <span class="n">probability</span> <span class="o">&gt;</span> <span class="mf">0.6</span> <span class="k">else</span> <span class="s">"Low"</span><span class="p">,</span>
            <span class="s">"input_features"</span><span class="p">:</span> <span class="n">request</span><span class="p">.</span><span class="nb">dict</span><span class="p">()</span>
        <span class="p">}</span>
        
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="sa">f</span><span class="s">"Prediction error: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">uvicorn</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="n">host</span><span class="o">=</span><span class="s">"0.0.0.0"</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">8000</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Run API server</span>
python3 predict_api.py

<span class="c"># Result: FastAPI server starts and the following message is shown</span>
<span class="c"># INFO:     Started server process [xxxxx]</span>
<span class="c"># INFO:     Waiting for application startup.</span>
<span class="c"># INFO:     Application startup complete.</span>
<span class="c"># INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="api-test-and-verification">API Test and Verification</h3>

<p>Once the server is running, you can test the API as follows:</p>

<p><img src="https://res.cloudinary.com/dkcm26aem/image/upload/v1750906667/mlops-demo2_qcauhd.png" alt="MLOps Demo Server" /></p>

<p><br /></p>

<script src="https://gist.github.com/somaz94/403371d13564510056746c0dfcc756f2.js"></script>

<p><br /></p>

<h3 id="deactivate-virtual-environment">Deactivate Virtual Environment</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Deactivate virtual environment</span>
deactivate

<span class="c"># Result: (venv) prompt disappears, indicating the environment is deactivated</span>
</code></pre></div></div>

<div class="info-box info-box-success-not-check">
  <strong>🎉 Congratulations!</strong>
  <p>You have successfully built a complete MLOps pipeline using NumPy, Pandas, and Scikit-Learn:</p>
  <ul>
    <li>✅ Data preprocessing including feature engineering</li>
    <li>✅ Model training with proper evaluation</li>
    <li>✅ Production-grade API with comprehensive error handling</li>
    <li>✅ Health check and monitoring endpoints</li>
    <li>✅ Scalable architecture ready for containerization</li>
  </ul>
</div>

<hr />

<h2 id="production-deployment-fastapi--docker">Production Deployment: FastAPI + Docker</h2>

<p>Let’s examine a complete example of deploying ML models in a real service environment.</p>

<p><br /></p>

<h3 id="1-fastapi-based-inference-server">1. FastAPI-based Inference Server</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># app.py
</span><span class="kn">from</span> <span class="nn">fastapi</span> <span class="kn">import</span> <span class="n">FastAPI</span><span class="p">,</span> <span class="n">HTTPException</span><span class="p">,</span> <span class="n">UploadFile</span><span class="p">,</span> <span class="n">File</span>
<span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">joblib</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">io</span>

<span class="n">app</span> <span class="o">=</span> <span class="n">FastAPI</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s">"ML Model API"</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="s">"1.0.0"</span><span class="p">)</span>

<span class="c1"># Global variable for model loading
</span><span class="n">model</span> <span class="o">=</span> <span class="bp">None</span>

<span class="o">@</span><span class="n">app</span><span class="p">.</span><span class="n">on_event</span><span class="p">(</span><span class="s">"startup"</span><span class="p">)</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">load_model</span><span class="p">():</span>
    <span class="s">"""Load model when application starts"""</span>
    <span class="k">global</span> <span class="n">model</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">joblib</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'model/production_model.pkl'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Model loaded successfully."</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Model loading failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">PredictionRequest</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="s">"""Single prediction request schema"""</span>
    <span class="n">age</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">income</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">session_duration</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">gender</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">device_type</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">region</span><span class="p">:</span> <span class="nb">str</span>

<span class="k">class</span> <span class="nc">BatchPredictionRequest</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="s">"""Batch prediction request schema"""</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">PredictionRequest</span><span class="p">]</span>

<span class="o">@</span><span class="n">app</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"/"</span><span class="p">)</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">health_check</span><span class="p">():</span>
    <span class="s">"""Health check endpoint"""</span>
    <span class="k">return</span> <span class="p">{</span><span class="s">"status"</span><span class="p">:</span> <span class="s">"healthy"</span><span class="p">,</span> <span class="s">"model_loaded"</span><span class="p">:</span> <span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">}</span>

<span class="o">@</span><span class="n">app</span><span class="p">.</span><span class="n">post</span><span class="p">(</span><span class="s">"/predict"</span><span class="p">)</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">predict_single</span><span class="p">(</span><span class="n">request</span><span class="p">:</span> <span class="n">PredictionRequest</span><span class="p">):</span>
    <span class="s">"""Single data prediction"""</span>
    <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">503</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="s">"Model is not loaded."</span><span class="p">)</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Convert input data to DataFrame
</span>        <span class="n">input_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">request</span><span class="p">.</span><span class="nb">dict</span><span class="p">()])</span>
        
        <span class="c1"># Perform prediction
</span>        <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_data</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">probability</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">input_data</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="s">"prediction"</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">prediction</span><span class="p">),</span>
            <span class="s">"probability"</span><span class="p">:</span> <span class="n">probability</span><span class="p">,</span>
            <span class="s">"input_data"</span><span class="p">:</span> <span class="n">request</span><span class="p">.</span><span class="nb">dict</span><span class="p">()</span>
        <span class="p">}</span>
        
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="sa">f</span><span class="s">"Prediction failed: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="o">@</span><span class="n">app</span><span class="p">.</span><span class="n">post</span><span class="p">(</span><span class="s">"/predict_batch"</span><span class="p">)</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">predict_batch</span><span class="p">(</span><span class="n">request</span><span class="p">:</span> <span class="n">BatchPredictionRequest</span><span class="p">):</span>
    <span class="s">"""Batch data prediction"""</span>
    <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">503</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="s">"Model is not loaded."</span><span class="p">)</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Convert batch data to DataFrame
</span>        <span class="n">input_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">item</span><span class="p">.</span><span class="nb">dict</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">request</span><span class="p">.</span><span class="n">data</span><span class="p">])</span>
        
        <span class="c1"># Perform batch prediction
</span>        <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_data</span><span class="p">).</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">probabilities</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">input_data</span><span class="p">).</span><span class="n">tolist</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="s">"predictions"</span><span class="p">:</span> <span class="n">predictions</span><span class="p">,</span>
            <span class="s">"probabilities"</span><span class="p">:</span> <span class="n">probabilities</span><span class="p">,</span>
            <span class="s">"batch_size"</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">request</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
        <span class="p">}</span>
        
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="sa">f</span><span class="s">"Batch prediction failed: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="o">@</span><span class="n">app</span><span class="p">.</span><span class="n">post</span><span class="p">(</span><span class="s">"/predict_csv"</span><span class="p">)</span>
<span class="k">async</span> <span class="k">def</span> <span class="nf">predict_csv</span><span class="p">(</span><span class="nb">file</span><span class="p">:</span> <span class="n">UploadFile</span> <span class="o">=</span> <span class="n">File</span><span class="p">(...)):</span>
    <span class="s">"""Prediction via CSV file upload"""</span>
    <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">503</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="s">"Model is not loaded."</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">file</span><span class="p">.</span><span class="n">filename</span><span class="p">.</span><span class="n">endswith</span><span class="p">(</span><span class="s">'.csv'</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="s">"Only CSV files can be uploaded."</span><span class="p">)</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Read CSV file
</span>        <span class="n">contents</span> <span class="o">=</span> <span class="k">await</span> <span class="nb">file</span><span class="p">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">io</span><span class="p">.</span><span class="n">StringIO</span><span class="p">(</span><span class="n">contents</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)))</span>
        
        <span class="c1"># Perform prediction
</span>        <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">probabilities</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">tolist</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="p">{</span>
            <span class="s">"predictions"</span><span class="p">:</span> <span class="n">predictions</span><span class="p">,</span>
            <span class="s">"probabilities"</span><span class="p">:</span> <span class="n">probabilities</span><span class="p">,</span>
            <span class="s">"rows_processed"</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        <span class="p">}</span>
        
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">HTTPException</span><span class="p">(</span><span class="n">status_code</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">detail</span><span class="o">=</span><span class="sa">f</span><span class="s">"CSV prediction failed: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">uvicorn</span>
    <span class="n">uvicorn</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="n">host</span><span class="o">=</span><span class="s">"0.0.0.0"</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">8000</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="2-docker-containerization">2. Docker Containerization</h3>

<p><br /></p>

<script src="https://gist.github.com/somaz94/df0ef19731aca9595bca20682bd74095.js"></script>

<p><br /></p>

<h3 id="3-kubernetes-deployment">3. Kubernetes Deployment</h3>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># k8s-deployment.yaml</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">ml-model-api</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">ml-model-api</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">ml-model-api</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">ml-model-api</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">ml-api</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">your-registry/ml-model-api:latest</span>
        <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">8000</span>
        <span class="na">resources</span><span class="pi">:</span>
          <span class="na">requests</span><span class="pi">:</span>
            <span class="na">memory</span><span class="pi">:</span> <span class="s2">"</span><span class="s">512Mi"</span>
            <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">250m"</span>
          <span class="na">limits</span><span class="pi">:</span>
            <span class="na">memory</span><span class="pi">:</span> <span class="s2">"</span><span class="s">1Gi"</span>
            <span class="na">cpu</span><span class="pi">:</span> <span class="s2">"</span><span class="s">500m"</span>
        <span class="na">livenessProbe</span><span class="pi">:</span>
          <span class="na">httpGet</span><span class="pi">:</span>
            <span class="na">path</span><span class="pi">:</span> <span class="s">/</span>
            <span class="na">port</span><span class="pi">:</span> <span class="m">8000</span>
          <span class="na">initialDelaySeconds</span><span class="pi">:</span> <span class="m">30</span>
          <span class="na">periodSeconds</span><span class="pi">:</span> <span class="m">10</span>
        <span class="na">readinessProbe</span><span class="pi">:</span>
          <span class="na">httpGet</span><span class="pi">:</span>
            <span class="na">path</span><span class="pi">:</span> <span class="s">/</span>
            <span class="na">port</span><span class="pi">:</span> <span class="m">8000</span>
          <span class="na">initialDelaySeconds</span><span class="pi">:</span> <span class="m">5</span>
          <span class="na">periodSeconds</span><span class="pi">:</span> <span class="m">5</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">ml-model-service</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">ml-model-api</span>
  <span class="na">ports</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
      <span class="na">port</span><span class="pi">:</span> <span class="m">80</span>
      <span class="na">targetPort</span><span class="pi">:</span> <span class="m">8000</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">LoadBalancer</span>
</code></pre></div></div>

<hr />

<h2 id="performance-monitoring-and-automation">Performance Monitoring and Automation</h2>

<p><br /></p>

<h3 id="1-data-drift-detection">1. Data Drift Detection</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="k">class</span> <span class="nc">DataDriftMonitor</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reference_data</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
        <span class="s">"""
        Data drift monitoring class
        
        Args:
            reference_data: Reference training data
            threshold: p-value threshold (default: 0.05)
        """</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">reference_data</span> <span class="o">=</span> <span class="n">reference_data</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">baseline_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_calculate_baseline_stats</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">_calculate_baseline_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""Calculate baseline statistics from reference data"""</span>
        <span class="n">stats_dict</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">reference_data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">reference_data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'int64'</span><span class="p">,</span> <span class="s">'float64'</span><span class="p">]:</span>
                <span class="n">stats_dict</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s">'mean'</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">reference_data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span>
                    <span class="s">'std'</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">reference_data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">std</span><span class="p">(),</span>
                    <span class="s">'distribution'</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">reference_data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">values</span>
                <span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">stats_dict</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s">'value_counts'</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">reference_data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">to_dict</span><span class="p">()</span>
                <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">stats_dict</span>
    
    <span class="k">def</span> <span class="nf">detect_drift</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_data</span><span class="p">):</span>
        <span class="s">"""Detect drift in new data"""</span>
        <span class="n">drift_results</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">new_data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">column</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">baseline_stats</span><span class="p">:</span>
                <span class="k">continue</span>
                
            <span class="k">if</span> <span class="n">new_data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'int64'</span><span class="p">,</span> <span class="s">'float64'</span><span class="p">]:</span>
                <span class="c1"># Numerical data: Kolmogorov-Smirnov test
</span>                <span class="n">ks_statistic</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">ks_2samp</span><span class="p">(</span>
                    <span class="bp">self</span><span class="p">.</span><span class="n">baseline_stats</span><span class="p">[</span><span class="n">column</span><span class="p">][</span><span class="s">'distribution'</span><span class="p">],</span>
                    <span class="n">new_data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">values</span>
                <span class="p">)</span>
                
                <span class="n">drift_results</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s">'drift_detected'</span><span class="p">:</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">threshold</span><span class="p">,</span>
                    <span class="s">'p_value'</span><span class="p">:</span> <span class="n">p_value</span><span class="p">,</span>
                    <span class="s">'ks_statistic'</span><span class="p">:</span> <span class="n">ks_statistic</span><span class="p">,</span>
                    <span class="s">'mean_shift'</span><span class="p">:</span> <span class="nb">abs</span><span class="p">(</span><span class="n">new_data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">baseline_stats</span><span class="p">[</span><span class="n">column</span><span class="p">][</span><span class="s">'mean'</span><span class="p">])</span>
                <span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Categorical data: Chi-square test
</span>                <span class="n">new_counts</span> <span class="o">=</span> <span class="n">new_data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">to_dict</span><span class="p">()</span>
                <span class="n">baseline_counts</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">baseline_stats</span><span class="p">[</span><span class="n">column</span><span class="p">][</span><span class="s">'value_counts'</span><span class="p">]</span>
                
                <span class="c1"># Compare only common categories
</span>                <span class="n">common_categories</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">new_counts</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">baseline_counts</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
                
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">common_categories</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">observed</span> <span class="o">=</span> <span class="p">[</span><span class="n">new_counts</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">cat</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">cat</span> <span class="ow">in</span> <span class="n">common_categories</span><span class="p">]</span>
                    <span class="n">expected</span> <span class="o">=</span> <span class="p">[</span><span class="n">baseline_counts</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">cat</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">cat</span> <span class="ow">in</span> <span class="n">common_categories</span><span class="p">]</span>
                    
                    <span class="n">chi2_stat</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">chisquare</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="n">expected</span><span class="p">)</span>
                    
                    <span class="n">drift_results</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="s">'drift_detected'</span><span class="p">:</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">threshold</span><span class="p">,</span>
                        <span class="s">'p_value'</span><span class="p">:</span> <span class="n">p_value</span><span class="p">,</span>
                        <span class="s">'chi2_statistic'</span><span class="p">:</span> <span class="n">chi2_stat</span>
                    <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">drift_results</span>
    
    <span class="k">def</span> <span class="nf">generate_drift_report</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">drift_results</span><span class="p">):</span>
        <span class="s">"""Generate drift detection result report"""</span>
        <span class="n">drifted_features</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">drift_results</span><span class="p">.</span><span class="n">items</span><span class="p">()</span> 
                           <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="s">'drift_detected'</span><span class="p">]]</span>
        
        <span class="n">report</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">'timestamp'</span><span class="p">:</span> <span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">().</span><span class="n">isoformat</span><span class="p">(),</span>
            <span class="s">'total_features_checked'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">drift_results</span><span class="p">),</span>
            <span class="s">'drifted_features_count'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">drifted_features</span><span class="p">),</span>
            <span class="s">'drifted_features'</span><span class="p">:</span> <span class="n">drifted_features</span><span class="p">,</span>
            <span class="s">'drift_severity'</span><span class="p">:</span> <span class="s">'HIGH'</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">drifted_features</span><span class="p">)</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">drift_results</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.3</span> <span class="k">else</span> <span class="s">'LOW'</span><span class="p">,</span>
            <span class="s">'detailed_results'</span><span class="p">:</span> <span class="n">drift_results</span>
        <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">report</span>

<span class="c1"># Usage Example
</span><span class="n">monitor</span> <span class="o">=</span> <span class="n">DataDriftMonitor</span><span class="p">(</span><span class="n">reference_data</span><span class="o">=</span><span class="n">training_data</span><span class="p">)</span>
<span class="n">new_batch</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'latest_production_data.csv'</span><span class="p">)</span>
<span class="n">drift_results</span> <span class="o">=</span> <span class="n">monitor</span><span class="p">.</span><span class="n">detect_drift</span><span class="p">(</span><span class="n">new_batch</span><span class="p">)</span>
<span class="n">report</span> <span class="o">=</span> <span class="n">monitor</span><span class="p">.</span><span class="n">generate_drift_report</span><span class="p">(</span><span class="n">drift_results</span><span class="p">)</span>

<span class="k">if</span> <span class="n">report</span><span class="p">[</span><span class="s">'drift_severity'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'HIGH'</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"⚠️ High level of data drift detected!"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Affected features: </span><span class="si">{</span><span class="n">report</span><span class="p">[</span><span class="s">'drifted_features'</span><span class="p">]</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="2-automated-retraining-pipeline">2. Automated Retraining Pipeline</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">schedule</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">timedelta</span>
<span class="kn">import</span> <span class="nn">logging</span>

<span class="k">class</span> <span class="nc">AutoMLPipeline</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">logger</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_setup_logging</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">drift_monitor</span> <span class="o">=</span> <span class="n">DataDriftMonitor</span><span class="p">(</span><span class="n">reference_data</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">_setup_logging</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""Logging configuration"""</span>
        <span class="n">logging</span><span class="p">.</span><span class="n">basicConfig</span><span class="p">(</span>
            <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="p">.</span><span class="n">INFO</span><span class="p">,</span>
            <span class="nb">format</span><span class="o">=</span><span class="s">'%(asctime)s - %(levelname)s - %(message)s'</span><span class="p">,</span>
            <span class="n">handlers</span><span class="o">=</span><span class="p">[</span>
                <span class="n">logging</span><span class="p">.</span><span class="n">FileHandler</span><span class="p">(</span><span class="s">'ml_pipeline.log'</span><span class="p">),</span>
                <span class="n">logging</span><span class="p">.</span><span class="n">StreamHandler</span><span class="p">()</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">logging</span><span class="p">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">check_and_retrain</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""Check data drift and retrain if necessary"""</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Starting data drift check"</span><span class="p">)</span>
        
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># 1. Collect latest production data
</span>            <span class="n">new_data</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_collect_production_data</span><span class="p">()</span>
            
            <span class="c1"># 2. Detect drift
</span>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s">'reference_data'</span><span class="p">):</span>
                <span class="n">drift_results</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">drift_monitor</span><span class="p">.</span><span class="n">detect_drift</span><span class="p">(</span><span class="n">new_data</span><span class="p">)</span>
                <span class="n">report</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">drift_monitor</span><span class="p">.</span><span class="n">generate_drift_report</span><span class="p">(</span><span class="n">drift_results</span><span class="p">)</span>
                
                <span class="c1"># 3. Determine retraining necessity
</span>                <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">_should_retrain</span><span class="p">(</span><span class="n">report</span><span class="p">):</span>
                    <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Retraining is needed. Starting retraining."</span><span class="p">)</span>
                    <span class="bp">self</span><span class="p">.</span><span class="n">_retrain_model</span><span class="p">(</span><span class="n">new_data</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Model is stable. No retraining needed."</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"No reference data available. Proceeding with initial training."</span><span class="p">)</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">_train_initial_model</span><span class="p">(</span><span class="n">new_data</span><span class="p">)</span>
                
        <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s">"Error during pipeline execution: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_collect_production_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""Collect data from production environment"""</span>
        <span class="c1"># In actual implementation, collect data from database, S3, Kafka, etc.
</span>        <span class="n">end_date</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">()</span>
        <span class="n">start_date</span> <span class="o">=</span> <span class="n">end_date</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
        
        <span class="c1"># Example: Collect data from PostgreSQL
</span>        <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"""
        SELECT * FROM user_features 
        WHERE created_at BETWEEN '</span><span class="si">{</span><span class="n">start_date</span><span class="si">}</span><span class="s">' AND '</span><span class="si">{</span><span class="n">end_date</span><span class="si">}</span><span class="s">'
        """</span>
        
        <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_sql</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">con</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">'database_connection'</span><span class="p">])</span>
    
    <span class="k">def</span> <span class="nf">_should_retrain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">drift_report</span><span class="p">):</span>
        <span class="s">"""Determine retraining necessity"""</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">drift_report</span><span class="p">[</span><span class="s">'drift_severity'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'HIGH'</span> <span class="ow">or</span>
            <span class="n">drift_report</span><span class="p">[</span><span class="s">'drifted_features_count'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">3</span>
        <span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_retrain_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_data</span><span class="p">):</span>
        <span class="s">"""Model retraining"""</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># 1. Data preprocessing
</span>            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_preprocess_data</span><span class="p">(</span><span class="n">new_data</span><span class="p">)</span>
            
            <span class="c1"># 2. Train new model
</span>            <span class="n">new_pipeline</span> <span class="o">=</span> <span class="n">MLPipeline</span><span class="p">()</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">new_pipeline</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            
            <span class="c1"># 3. Validate model performance
</span>            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">_validate_new_model</span><span class="p">(</span><span class="n">new_pipeline</span><span class="p">,</span> <span class="n">results</span><span class="p">):</span>
                <span class="c1"># 4. Deploy model
</span>                <span class="bp">self</span><span class="p">.</span><span class="n">_deploy_model</span><span class="p">(</span><span class="n">new_pipeline</span><span class="p">)</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="s">"New model deployed successfully."</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span><span class="s">"New model performance below standards."</span><span class="p">)</span>
                
        <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">logger</span><span class="p">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s">"Error during retraining: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_validate_new_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_model</span><span class="p">,</span> <span class="n">results</span><span class="p">):</span>
        <span class="s">"""Validate new model performance"""</span>
        <span class="c1"># Compare with baseline performance
</span>        <span class="n">min_accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">'min_accuracy'</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">results</span><span class="p">[</span><span class="s">'test_accuracy'</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">min_accuracy</span>
    
    <span class="k">def</span> <span class="nf">_deploy_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="s">"""Model deployment"""</span>
        <span class="c1"># Timestamp for version management
</span>        <span class="n">timestamp</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">().</span><span class="n">strftime</span><span class="p">(</span><span class="s">"%Y%m%d_%H%M%S"</span><span class="p">)</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"models/model_</span><span class="si">{</span><span class="n">timestamp</span><span class="si">}</span><span class="s">.pkl"</span>
        
        <span class="c1"># Save model
</span>        <span class="n">model</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
        
        <span class="c1"># Update production model symbolic link
</span>        <span class="kn">import</span> <span class="nn">os</span>
        <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="s">"models/production_model.pkl"</span><span class="p">):</span>
            <span class="n">os</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="s">"models/production_model.pkl"</span><span class="p">)</span>
        <span class="n">os</span><span class="p">.</span><span class="n">symlink</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="s">"models/production_model.pkl"</span><span class="p">)</span>
        
        <span class="c1"># Trigger rolling update in Kubernetes (optional)
</span>        <span class="c1"># kubectl patch deployment ml-model-api -p '{"spec":{"template":{"metadata":{"labels":{"date":"' + timestamp + '"}}}}}'
</span>
<span class="c1"># Scheduling configuration
</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">AutoMLPipeline</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

<span class="c1"># Run daily at 2 AM
</span><span class="n">schedule</span><span class="p">.</span><span class="n">every</span><span class="p">().</span><span class="n">day</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="s">"02:00"</span><span class="p">).</span><span class="n">do</span><span class="p">(</span><span class="n">pipeline</span><span class="p">.</span><span class="n">check_and_retrain</span><span class="p">)</span>

<span class="c1"># Run every Monday at 1 AM
</span><span class="n">schedule</span><span class="p">.</span><span class="n">every</span><span class="p">().</span><span class="n">monday</span><span class="p">.</span><span class="n">at</span><span class="p">(</span><span class="s">"01:00"</span><span class="p">).</span><span class="n">do</span><span class="p">(</span><span class="n">pipeline</span><span class="p">.</span><span class="n">check_and_retrain</span><span class="p">)</span>

<span class="c1"># Run scheduler
</span><span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">schedule</span><span class="p">.</span><span class="n">run_pending</span><span class="p">()</span>
    <span class="n">time</span><span class="p">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">60</span><span class="p">)</span>  <span class="c1"># Check every minute
</span></code></pre></div></div>

<hr />

<h2 id="key-points-and-conclusion">Key Points and Conclusion</h2>

<p><br /></p>

<div class="info-box info-box-success-not-check">
  <strong>💡 MLOps Essentials Summary</strong>
  <ul>
    <li>
      <strong>Foundation Libraries</strong><br />
      - NumPy: High-performance numerical computing foundation for all ML frameworks<br />
      - Pandas: Data manipulation and ETL backbone for feature engineering pipelines<br />
      - Scikit-Learn: Complete ML lifecycle from experimentation to production deployment
    </li>
    <li>
      <strong>Production Capabilities</strong><br />
      - Real-time data processing and feature engineering at scale<br />
      - Automated model training with hyperparameter optimization<br />
      - Containerized deployment with Docker and Kubernetes<br />
      - Comprehensive monitoring and automated retraining workflows
    </li>
    <li>
      <strong>Best Practices</strong><br />
      - Use vectorized operations for 10-100x performance improvements<br />
      - Implement proper data validation and quality checks<br />
      - Design pipelines for reproducibility and version control<br />
      - Monitor data drift and model performance in production
    </li>
  </ul>
</div>

<blockquote>
  <p>The transition from DevOps to MLOps is no longer optional—it’s essential for modern infrastructure teams. NumPy, Pandas, and Scikit-Learn aren’t just data science tools; they’re the foundational components of modern AI service infrastructure that enable data-driven applications at scale.</p>
</blockquote>

<p><br /></p>

<h3 id="core-takeaways">Core Takeaways</h3>

<ol>
  <li><strong>NumPy</strong>: Provides the high-performance numerical foundation that makes real-time data processing feasible</li>
  <li><strong>Pandas</strong>: Serves as the central hub for data pipelines and feature stores in production systems</li>
  <li><strong>Scikit-Learn</strong>: Delivers complete ML workflows from experimentation to production deployment</li>
</ol>

<p><br /></p>

<h3 id="next-steps-for-expansion">Next Steps for Expansion</h3>

<p>With these fundamentals mastered, consider expanding into advanced MLOps technologies:</p>

<p><br /></p>

<div class="table-container">
  <table class="table-beauty">
    <tr>
      <th style="width: 30%;">Technology Category</th>
      <th style="width: 70%;">Recommended Tools and Platforms</th>
    </tr>
    <tr>
      <td><strong>Experiment Management</strong></td>
      <td>MLflow, Weights &amp; Biases, Neptune.ai for tracking experiments and model versioning</td>
    </tr>
    <tr>
      <td><strong>Workflow Orchestration</strong></td>
      <td>Kubeflow, Argo Workflows, Apache Airflow for automating ML pipelines</td>
    </tr>
    <tr>
      <td><strong>Real-time Processing</strong></td>
      <td>Apache Kafka, Apache Spark, Apache Flink for streaming data processing</td>
    </tr>
    <tr>
      <td><strong>Model Serving</strong></td>
      <td>KServe, Seldon Core, TorchServe, TensorFlow Serving for production model deployment</td>
    </tr>
    <tr>
      <td><strong>Monitoring &amp; Observability</strong></td>
      <td>Prometheus + Grafana, Evidently AI, WhyLabs for model and data monitoring</td>
    </tr>
  </table>
</div>

<p>MLOps represents more than an extension of DevOps—it’s a fundamental shift toward data-centric thinking that enables entirely new dimensions of service operation and intelligence. The skills you’ve learned here provide the foundation for building AI-native applications that can adapt, learn, and improve over time.</p>

<p>Start implementing these concepts today to prepare for the AI-driven future of software infrastructure!</p>

<hr />

<h2 id="references">References</h2>

<ul>
  <li><a href="https://numpy.org/doc/">NumPy Official Documentation</a></li>
  <li><a href="https://pandas.pydata.org/docs/">Pandas Official Documentation</a></li>
  <li><a href="https://scikit-learn.org/stable/">Scikit-Learn Official Documentation</a></li>
  <li><a href="https://fastapi.tiangolo.com/">FastAPI Official Documentation</a></li>
  <li><a href="https://ml-ops.org/">MLOps Best Practices</a></li>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/">Kubernetes ML Workloads</a></li>
  <li><a href="https://docs.docker.com/get-started/">Docker for Machine Learning</a></li>
</ul>



                <!-- Pagination links -->


            </article>

            
                <aside class="see-also">
                    <h2>See also</h2>
                    <ul>
                        
                        
                        
                            <li>
                                <a href="/category/container/docker-compose/">
                                    
                                        <img src="https://res.cloudinary.com/dkcm26aem/image/upload/c_scale,w_380/v1755654072/docker-compose_l2hvau.png">
                                    
                                    <h3>Docker Compose - Complete Guide to Multi-Container Application Orchestration</h3>
                                </a>
                            </li>
                        
                            <li>
                                <a href="/category/ai/claude-gemini/">
                                    
                                        <img src="https://res.cloudinary.com/dkcm26aem/image/upload/c_scale,w_380/v1767603840/claude-gemini-1_q0lkop.png">
                                    
                                    <h3>Claude 4.5 Sonnet vs Gemini 3 Pro: The Ultimate 2026 AI Model Showdown</h3>
                                </a>
                            </li>
                        
                            <li>
                                <a href="/category/iac/ansible/">
                                    
                                        <img src="https://res.cloudinary.com/dkcm26aem/image/upload/c_scale,w_380/v1755657938/ansible-1_qtomxt.png">
                                    
                                    <h3>Ansible - Complete Guide to Infrastructure Automation and Galaxy Platform</h3>
                                </a>
                            </li>
                        
                    </ul>
                </aside>
            

        </section>

        <!-- Add time bar only for pages without pagination -->
        
            <div class="time-bar" data-minutes="62">
    <span class="time-completed"></span>
    <span class="time-remaining"></span>
    <div class="bar">
        <span class="completed" style="width:0%;"></span>
        <span class="remaining" style="width:100%;"></span>
    </div>
</div>

            <button class="toggle-preview" onclick="togglePreview()">
    <span>Hide Preview ▼</span>
</button>

<div id="recommendationSection" class="recommendation">
    <div class="message">
        <strong>Why don't you read something next?</strong>
        <div>
            <button>
                <svg><use xlink:href="#icon-arrow-right"></use></svg>
                <span>Go back to top</span>
            </button>
        </div>
    </div>
    <div id="previewSection" class="preview-section">
        
        <a href="/category/troubleshooting/gitlab-vm-nbd-recovery/" class="post-preview">
            <div class="image">
                
                    <img src="https://res.cloudinary.com/dkcm26aem/image/upload/c_scale,w_380/v1754460145/gitlab-recovery_q9gwuz.png">
                
            </div>
            <h3 class="title">GitLab VM Disaster Recovery: Service Restoration with NBD Mount and Backup Restore</h3>
        </a>
    </div>
</div>

<style>
.toggle-preview {
    position: fixed;
    bottom: 20px;
    right: 20px;
    background: #333;
    color: white;
    border: none;
    padding: 8px 15px;
    border-radius: 4px;
    cursor: pointer;
    z-index: 1000;
    opacity: 0;
    transition: opacity 0.3s ease;
}

.toggle-preview:hover {
    background: #444;
}

.toggle-preview.visible {
    opacity: 1;
}

.recommendation {
    margin-top: 1000px;
    display: block;
    transition: all 0.3s ease;
}

.recommendation.hidden {
    display: none;
}

.hide-preview {
    margin-left: 10px;
    background: none;
    border: 1px solid #666;
    color: #666;
    padding: 5px 10px;
    border-radius: 4px;
    cursor: pointer;
}

.hide-preview:hover {
    background: #f0f0f0;
}

.preview-section {
    max-height: 1000px;
    overflow: hidden;
    transition: max-height 0.3s ease-out;
}

.preview-section.hidden {
    max-height: 0;
}
</style>

<script>
function togglePreview() {
    const recommendation = document.getElementById('recommendationSection');
    const button = document.querySelector('.toggle-preview span');
    
    if (recommendation.classList.contains('hidden')) {
        recommendation.classList.remove('hidden');
        button.textContent = 'Hide Preview ▼';
    } else {
        recommendation.classList.add('hidden');
        button.textContent = 'Show Preview ▲';
    }
}

window.addEventListener('scroll', function() {
    const toggleButton = document.querySelector('.toggle-preview');
    const recommendation = document.getElementById('recommendationSection');
    const rect = recommendation.getBoundingClientRect();
    
    if (rect.top <= window.innerHeight) {
        toggleButton.classList.add('visible');
    } else {
        toggleButton.classList.remove('visible');
    }
});
</script>

        

        <!-- Show modal if the post is the last one -->
        

        <!-- Show modal before user leaves the page -->
        

        <!-- Add your newsletter subscription form here -->

        <section class="share">
    <h3>Share</h3>
    <a aria-label="Share on Twitter" href="https://twitter.com/intent/tweet?text=&quot;A comprehensive guide to NumPy, Pandas, and Scikit-Learn for building production-ready MLOps pipelines, covering data processing, model training, and deployment strategies&quot;%20https://somaz.blog/category/ai/mlops-fundamentals-numpy-pandas-sklearn/%20via%20&#64;twitter_username&hashtags=mlops,numpy,pandas,scikit-learn,machine-learning,python,data-science"
    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" title="Share on Twitter">
        <svg class="icon icon-twitter"><use xlink:href="#icon-twitter"></use></svg>
    </a>
    <a aria-label="Share on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://somaz.blog/category/ai/mlops-fundamentals-numpy-pandas-sklearn/"
    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;" title="Share on Facebook">
        <svg class="icon icon-facebook"><use xlink:href="#icon-facebook"></use></svg>
    </a>
</section>

        

  <section class="author">
    <div class="details">
      
        <img class="img-rounded" src="/assets/img/uploads/profile.png" alt="Somaz">
      
      <p class="def">Author</p>
      <h3 class="name">
        <a href="/authors/somaz/">Somaz</a>
      </h3>
      <p class="desc">DevOps engineer focused on cloud infrastructure and automation</p>
      <p>
        
          <a href="https://github.com/somaz94" title="Github">
            <svg><use xlink:href="#icon-github"></use></svg>
          </a>
        
        
        
        
        
        
          <a href="https://www.linkedin.com/in/somaz" title="LinkedIn">
            <svg><use xlink:href="#icon-linkedin"></use></svg>
          </a>
        
        
          <a href="https://somaz.tistory.com" title="Tistory">
            <svg><use xlink:href="#icon-tistory"></use></svg>
          </a>
        
      </p>
    </div>
  </section>

  
  
  
  
  
  
  
  

  <script type="application/ld+json">
  {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Somaz",
      
      "image": "/assets/img/uploads/profile.png",
      
      "jobTitle": "DevOps Engineer",
      "url": "https://somaz.blog/authors/somaz/",
      "sameAs": [
        "https://github.com/somaz94","https://www.linkedin.com/in/somaz","https://{{ author.tistory_username }}.tistory.com"
      ]
  }
  </script>


        

<section class="comments">
    <h3>Comments</h3>
    <div id="disqus_thread"></div>
</section>
<script type="text/javascript">
    var disqus_loaded = false;

    function load_disqus()
    {
        disqus_loaded = true;
        var disqus_shortname = 'https-somaz94-github-io';
        var disqus_title = '';
        var disqus_url = '/category/ai/mlops-fundamentals-numpy-pandas-sklearn/';
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        var ldr = document.getElementById('disqus_loader');
    };
    window.onscroll = function(e) {
        if ((window.innerHeight + window.scrollY) >= (document.body.offsetHeight - 800)) {
            //hit bottom of page
            if (disqus_loaded==false)
                load_disqus()
        }
    };
</script>



        <footer>
    <p>
      
        <a href="https://github.com/somaz94" title="Github">
          <svg><use xlink:href="#icon-github"></use></svg>
        </a>
      
      
        <a href="https://www.facebook.com/facebook_username" title="Facebook">
          <svg><use xlink:href="#icon-facebook"></use></svg>
        </a>
      
      
        <a href="https://twitter.com/twitter_username" title="Twitter">
          <svg><use xlink:href="#icon-twitter"></use></svg>
        </a>
      
      
        <a href="https://medium.com/@medium_username" title="Medium">
          <svg><use xlink:href="#icon-medium"></use></svg>
        </a>
      
      
        <a href="https://www.instagram.com/instagram_username" title="Instagram">
          <svg><use xlink:href="#icon-instagram"></use></svg>
        </a>
      
      
        <a href="https://www.linkedin.com/in/somaz" title="LinkedIn">
          <svg><use xlink:href="#icon-linkedin"></use></svg>
        </a>
      
      
        <a href="https://somaz.tistory.com" title="Tistory">
          <svg><use xlink:href="#icon-tistory"></use></svg>
        </a>
      
    </p>

    <ul>
  
    
      <li>
        <a href="https://somaz.blog/">Home</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/about">About</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/category">Category</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/contact">Contact</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/feed.xml">Feed</a>
      </li>
    
  
</ul>


    <p>
      <a href="https://somaz.blog/sitemap.xml" title="sitemap">Sitemap</a> |
      <a href="https://somaz.blog/privacy-policy" title="Privacy Policy">Privacy Policy</a>
    </p>

    <p>
      <span>Somaz Tech Blog</span> <svg class="love"><use xlink:href="#icon-heart"></use></svg>
    </p>
</footer>










<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "somaz",
  "description": "DevOps engineer's tech blog.",
  "url": "https://somaz.blog/",
  "logo": {
      "@type": "ImageObject",
      "url": "https://somaz.blog/assets/img/icons/mediumtile.png",
      "width": "600",
      "height": "315"
  },
  "sameAs": [
    "https://github.com/somaz94","https://www.facebook.com/facebook_username","https://twitter.com/twitter_username","https://medium.com/@medium_username","https://www.instagram.com/instagram_username","https://www.linkedin.com/in/somaz","https://{{ site.tistory_username }}.tistory.com"
  ]
}
</script>

<!-- Include the script that allows Netlify CMS login -->
<script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script>

<!-- Include the website scripts -->
<script src="/assets/js/scripts.min.js"></script>

<!-- Include Google Analytics script -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXX-X"></script>
<script>
  var host = window.location.hostname;
  if (host != 'localhost') {
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-XXXXXXXX-X');
  }
</script>
  


<!-- Include extra scripts -->



        

        
        
        
        
        
        
        
        
        <script type="application/ld+json">
        {
            "@context": "http://schema.org",
            "@type": "BlogPosting",
            "name": "Mastering MLOps Essential Libraries: NumPy, Pandas, and Scikit-Learn Complete Guide",
            "headline": "From data pipelines to model deployment - Essential tools for MLOps engineers",
            "description": "A comprehensive guide to NumPy, Pandas, and Scikit-Learn for building production-ready MLOps pipelines, covering data processing, model training, and deployment strategies",
            "image": "https://res.cloudinary.com/dkcm26aem/image/upload/v1750904968/mlops-demo_znwpz1.png",
            "url": "https://somaz.blog/category/ai/mlops-fundamentals-numpy-pandas-sklearn/",
            "articleBody": "Table of Contents


  Introduction
  MLOps Pipeline Architecture
  NumPy: High-Performance Foundation
  Pandas: Data Pipeline Powerhouse
  Scikit-Learn: Complete ML Pipeline
  Hands-on: Local MLOps Pipeline
  Production Deployment (FastAPI + Docker + K8s)
  Monitoring &amp;amp; Automation
  Key Points &amp;amp; Conclusion
  References




Introduction to MLOps Fundamentals


  “Data is as important as code.” As AI/ML becomes central to modern software development, traditional DevOps engineers must expand into MLOps territory. This comprehensive guide explores how NumPy, Pandas, and Scikit-Learn form the backbone of production MLOps workflows, enabling efficient data processing, model training, and deployment strategies.




Why These Three Libraries Matter

NumPy, Pandas, and Scikit-Learn aren’t just data science tools—they’re the foundation of modern MLOps infrastructure:


  NumPy: High-performance numerical computing engine powering all ML frameworks
  Pandas: Data manipulation and ETL backbone for feature engineering
  Scikit-Learn: Complete machine learning pipeline from experimentation to production
  Production Ready: Battle-tested libraries used by major tech companies worldwide
  Ecosystem Integration: Seamless compatibility with Docker, Kubernetes, and cloud platforms
  Community Support: Extensive documentation, tutorials, and community resources




MLOps Pipeline Architecture

Understanding how these libraries fit into the MLOps workflow is crucial for building efficient, scalable machine learning systems. This section maps out where each library excels in the typical MLOps pipeline and how they work together to create robust data-driven applications.



Library Roles in MLOps Workflow


  
    graph LR
      A[Data Collection] --&amp;gt; B[Preprocessing/Cleaning]
      B --&amp;gt; C[Training/Inference]
      C --&amp;gt; D[Evaluation/Logging]
      D --&amp;gt; E[Storage/Deployment]
      
      A -.-&amp;gt; A1[PandasData Sources]
      B -.-&amp;gt; B1[NumPyTransformations]
      C -.-&amp;gt; C1[Scikit-LearnModels]
      D -.-&amp;gt; D1[Scikit/PandasMetrics]
      E -.-&amp;gt; E1[joblib + APIServing]
      
      style A fill:#a5d6a7,stroke:#333,stroke-width:1px
      style B fill:#64b5f6,stroke:#333,stroke-width:1px
      style C fill:#ffcc80,stroke:#333,stroke-width:1px
      style D fill:#ce93d8,stroke:#333,stroke-width:1px
      style E fill:#ef9a9a,stroke:#333,stroke-width:1px
  





  
    
      Pipeline Stage
      Primary Library
      Key Responsibilities
    
    
      Data Collection
      Pandas
      Reading from various sources (CSV, JSON, SQL, Parquet), data validation, initial exploration
    
    
      Preprocessing
      NumPy + Pandas
      Numerical transformations, feature engineering, data cleaning, normalization
    
    
      Model Training
      Scikit-Learn
      Algorithm selection, hyperparameter tuning, cross-validation, model fitting
    
    
      Evaluation
      All Three
      Performance metrics calculation, model comparison, result visualization
    
    
      Deployment
      joblib + FastAPI
      Model serialization, API serving, containerization, monitoring
    
  




NumPy: High-Performance Foundation for ML Operations

NumPy serves as the numerical computing foundation for the entire Python data science ecosystem. Its efficient array operations and mathematical functions make it indispensable for high-performance machine learning workflows, providing the speed and reliability needed for production systems.



Why NumPy is Critical for MLOps

The Performance Engine of ML

NumPy isn’t just a numerical library—it’s the performance engine behind modern machine learning operations:


  Speed: C-implemented vectorized operations are 10-100x faster than pure Python
  Memory Efficiency: Homogeneous arrays with contiguous memory layout
  Universal Compatibility: Foundation for TensorFlow, PyTorch, Scikit-Learn, and other ML libraries
  Broadcasting: Efficient operations on arrays of different shapes
  Mathematical Functions: Comprehensive collection of mathematical, statistical, and linear algebra operations




Core NumPy Capabilities


  
    
      Feature Category
      Key Functions
      MLOps Applications
    
    
      Array Operations
      reshape, concatenate, split, stack
      Data preprocessing, batch processing, feature transformation
    
    
      Mathematical Functions
      sin, cos, exp, log, sqrt
      Feature engineering, activation functions, transformations
    
    
      Statistical Operations
      mean, std, percentile, histogram
      Data analysis, normalization, outlier detection
    
    
      Linear Algebra
      dot, matmul, linalg.inv, svd
      Matrix operations, dimensionality reduction, optimization
    
    
      Random Sampling
      random.normal, random.choice, seed
      Data augmentation, train/test splits, reproducible experiments
    
  




Practical Implementation Examples

Real-time Log Data Normalization

Processing server latency logs for anomaly detection:

import numpy as np

def normalize_latency_data(latencies):
    &quot;&quot;&quot;Normalize server response time logs for outlier detection&quot;&quot;&quot;
    latencies = np.array(latencies)
    
    # Z-score normalization
    normalized = (latencies - np.mean(latencies)) / np.std(latencies)
    
    # Apply 3-sigma rule for outlier clipping
    clipped = np.clip(normalized, -3, 3)
    
    return clipped

# Example: Microservice response times (ms)
response_times = [15, 20, 500, 30, 22, 18, 25, 1000, 19]
cleaned_data = normalize_latency_data(response_times)
print(f&quot;Normalized data: {cleaned_data}&quot;)




Vectorized Operations for Performance Optimization

Comparing vectorized vs traditional approaches:

# Inefficient approach (pure Python)
def slow_distance_calculation(points1, points2):
    distances = []
    for p1, p2 in zip(points1, points2):
        dist = ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)**0.5
        distances.append(dist)
    return distances

# Efficient approach (NumPy vectorization)
def fast_distance_calculation(points1, points2):
    p1 = np.array(points1)
    p2 = np.array(points2)
    return np.sqrt(np.sum((p1 - p2)**2, axis=1))

# Performance benchmark
import time
points1 = [(i, i) for i in range(100000)]
points2 = [(i+1, i+1) for i in range(100000)]

# NumPy approach is 10-50x faster




MLOps Production Tips


  Performance Optimization Strategies
  
    Memory Efficiency: Use np.memmap for processing datasets larger than available RAM
    Type Optimization: Choose float32 vs float64 to reduce memory usage by 50%
    GPU Acceleration: Leverage CuPy library to run NumPy code on GPU for massive datasets
    Vectorization: Replace Python loops with NumPy operations for 10-100x speed improvements
    Broadcasting: Use NumPy&apos;s broadcasting rules to avoid explicit loops and temporary arrays
  




Pandas: Data Pipeline Powerhouse

Pandas serves as the backbone of data manipulation and ETL processes in MLOps workflows. Its ability to handle diverse data formats and perform complex transformations makes it indispensable for feature engineering, data cleaning, and preparing datasets for machine learning models.



Why Pandas is Essential for MLOps

The Data Manipulation Engine

Pandas isn’t just a data analysis tool—it’s the data manipulation engine powering MLOps workflows:


  Format Versatility: Native support for CSV, JSON, Parquet, SQL, Excel, and more
  Data Operations: Powerful grouping, joining, pivoting, and aggregation capabilities
  Time Series Support: Specialized functionality for temporal data analysis
  Missing Data Handling: Robust methods for dealing with incomplete datasets
  Performance: Optimized operations using underlying NumPy arrays
  Integration: Seamless compatibility with scikit-learn and other ML libraries




Core Pandas Capabilities


  
    
      Feature Category
      Key Functions
      MLOps Applications
    
    
      Data I/O
      read_csv, read_json, read_sql, to_parquet
      Data ingestion, feature store integration, model artifact storage
    
    
      Data Cleaning
      dropna, fillna, replace, duplicated
      Data quality assurance, preprocessing automation
    
    
      Transformations
      groupby, merge, pivot, apply
      Feature engineering, data aggregation, business logic implementation
    
    
      Time Series
      resample, rolling, shift, date_range
      Temporal feature extraction, trend analysis, forecasting preparation
    
    
      Statistical Operations
      describe, corr, value_counts, quantile
      Data profiling, exploratory data analysis, feature selection
    
  




Practical Implementation Examples

Feature Store Integration Pipeline

Building a robust data pipeline that connects multiple data sources:

import pandas as pd
from datetime import datetime, timedelta
import sqlalchemy
import boto3

class FeaturePipeline:
    def __init__(self, config):
        self.config = config
        self.db_engine = sqlalchemy.create_engine(config[&apos;database_url&apos;])
        self.s3_client = boto3.client(&apos;s3&apos;)
        
    def extract_user_features(self, user_ids, date_range):
        &quot;&quot;&quot;Extract and combine user features from multiple data sources&quot;&quot;&quot;
        
        # 1. Extract user activity from S3 (Parquet files)
        activity_df = self._extract_activity_data(date_range)
        
        # 2. Extract transaction data from PostgreSQL
        transaction_df = self._extract_transaction_data(user_ids, date_range)
        
        # 3. Extract product interaction from Redis/MongoDB
        interaction_df = self._extract_interaction_data(user_ids, date_range)
        
        # 4. Combine and engineer features
        return self._create_feature_matrix(activity_df, transaction_df, interaction_df)
    
    def _extract_activity_data(self, date_range):
        &quot;&quot;&quot;Extract user activity logs from S3&quot;&quot;&quot;
        start_date, end_date = date_range
        
        # Read multiple Parquet files efficiently
        file_pattern = f&quot;s3://ml-datalake/user-activity/year={start_date.year}/month={start_date.month:02d}/*.parquet&quot;
        
        activity_df = pd.read_parquet(file_pattern, 
                                    filters=[(&apos;event_date&apos;, &apos;&amp;gt;=&apos;, start_date),
                                           (&apos;event_date&apos;, &apos;&amp;lt;=&apos;, end_date)])
        
        # Data quality checks
        activity_df = activity_df.dropna(subset=[&apos;user_id&apos;, &apos;event_type&apos;])
        activity_df[&apos;session_duration&apos;] = pd.to_numeric(activity_df[&apos;session_duration&apos;], errors=&apos;coerce&apos;)
        
        return activity_df
    
    def _extract_transaction_data(self, user_ids, date_range):
        &quot;&quot;&quot;Extract transaction data from PostgreSQL&quot;&quot;&quot;
        start_date, end_date = date_range
        
        query = &quot;&quot;&quot;
        SELECT 
            user_id,
            transaction_date,
            amount,
            category,
            payment_method,
            is_successful
        FROM transactions 
        WHERE user_id = ANY(%(user_ids)s)
        AND transaction_date BETWEEN %(start_date)s AND %(end_date)s
        AND is_successful = true
        &quot;&quot;&quot;
        
        transaction_df = pd.read_sql(query, 
                                   con=self.db_engine,
                                   params={
                                       &apos;user_ids&apos;: user_ids,
                                       &apos;start_date&apos;: start_date,
                                       &apos;end_date&apos;: end_date
                                   })
        
        # Convert data types and handle missing values
        transaction_df[&apos;transaction_date&apos;] = pd.to_datetime(transaction_df[&apos;transaction_date&apos;])
        transaction_df[&apos;amount&apos;] = pd.to_numeric(transaction_df[&apos;amount&apos;], errors=&apos;coerce&apos;)
        
        return transaction_df
    
    def _create_feature_matrix(self, activity_df, transaction_df, interaction_df):
        &quot;&quot;&quot;Engineer features from raw data&quot;&quot;&quot;
        
        # User activity features
        activity_features = activity_df.groupby(&apos;user_id&apos;).agg({
            &apos;session_duration&apos;: [&apos;mean&apos;, &apos;std&apos;, &apos;count&apos;, &apos;sum&apos;],
            &apos;page_views&apos;: [&apos;sum&apos;, &apos;mean&apos;],
            &apos;clicks&apos;: [&apos;sum&apos;, &apos;mean&apos;],
            &apos;scroll_depth&apos;: [&apos;mean&apos;, &apos;max&apos;]
        }).round(2)
        
        # Flatten column names
        activity_features.columns = [&apos;_&apos;.join(col).strip() for col in activity_features.columns]
        
        # Calculate engagement metrics
        activity_features[&apos;avg_ctr&apos;] = (
            activity_features[&apos;clicks_sum&apos;] / 
            (activity_features[&apos;page_views_sum&apos;] + 1)
        )
        
        activity_features[&apos;engagement_score&apos;] = (
            activity_features[&apos;session_duration_mean&apos;] * 
            activity_features[&apos;avg_ctr&apos;] * 
            activity_features[&apos;scroll_depth_mean&apos;]
        )
        
        # Transaction features
        transaction_features = transaction_df.groupby(&apos;user_id&apos;).agg({
            &apos;amount&apos;: [&apos;sum&apos;, &apos;mean&apos;, &apos;count&apos;, &apos;std&apos;],
            &apos;category&apos;: lambda x: x.nunique(),
            &apos;payment_method&apos;: lambda x: x.mode().iloc[0] if len(x) &amp;gt; 0 else &apos;unknown&apos;
        })
        
        transaction_features.columns = [&apos;_&apos;.join(col).strip() for col in transaction_features.columns]
        
        # Time-based features
        transaction_df[&apos;hour&apos;] = transaction_df[&apos;transaction_date&apos;].dt.hour
        transaction_df[&apos;day_of_week&apos;] = transaction_df[&apos;transaction_date&apos;].dt.dayofweek
        
        time_features = transaction_df.groupby(&apos;user_id&apos;).agg({
            &apos;hour&apos;: lambda x: x.mode().iloc[0] if len(x) &amp;gt; 0 else 12,  # Preferred shopping hour
            &apos;day_of_week&apos;: lambda x: x.mode().iloc[0] if len(x) &amp;gt; 0 else 0  # Preferred shopping day
        })
        
        time_features.columns = [&apos;preferred_hour&apos;, &apos;preferred_day&apos;]
        
        # Combine all features
        feature_matrix = activity_features.join([transaction_features, time_features], how=&apos;outer&apos;)
        
        # Handle missing values with business logic
        feature_matrix = feature_matrix.fillna({
            &apos;session_duration_mean&apos;: 0,
            &apos;clicks_sum&apos;: 0,
            &apos;amount_sum&apos;: 0,
            &apos;engagement_score&apos;: 0
        })
        
        # Add derived features
        feature_matrix[&apos;is_high_value&apos;] = (feature_matrix[&apos;amount_sum&apos;] &amp;gt; feature_matrix[&apos;amount_sum&apos;].quantile(0.8)).astype(int)
        feature_matrix[&apos;is_frequent_user&apos;] = (feature_matrix[&apos;session_duration_count&apos;] &amp;gt; 10).astype(int)
        
        return feature_matrix

# Example usage
config = {
    &apos;database_url&apos;: &apos;postgresql://user:pass@localhost:5432/mlops&apos;,
    &apos;s3_bucket&apos;: &apos;ml-datalake&apos;,
    &apos;redis_host&apos;: &apos;localhost&apos;
}

pipeline = FeaturePipeline(config)
user_list = [1001, 1002, 1003, 1004, 1005]
date_range = (datetime.now() - timedelta(days=30), datetime.now())

features = pipeline.extract_user_features(user_list, date_range)
print(f&quot;Feature matrix shape: {features.shape}&quot;)
print(f&quot;Features: {list(features.columns)}&quot;)




Real-time Data Stream Processing
Processing streaming data for real-time feature computation:

import pandas as pd
from kafka import KafkaConsumer
import json
import redis
from collections import deque
from datetime import datetime, timedelta

class RealTimeFeatureProcessor:
    def __init__(self, kafka_config, redis_client):
        self.consumer = KafkaConsumer(
            &apos;user-events&apos;,
            **kafka_config,
            value_deserializer=lambda m: json.loads(m.decode(&apos;utf-8&apos;))
        )
        self.redis_client = redis_client
        self.window_size = timedelta(minutes=5)
        self.feature_buffer = deque(maxlen=10000)  # Circular buffer for memory efficiency
        
    def process_stream(self):
        &quot;&quot;&quot;Process real-time event stream and maintain feature windows&quot;&quot;&quot;
        
        for message in self.consumer:
            event_data = message.value
            
            # Convert to DataFrame for consistent processing
            event_df = pd.DataFrame([event_data])
            event_df[&apos;timestamp&apos;] = pd.to_datetime(event_df[&apos;timestamp&apos;])
            
            # Add to buffer
            self.feature_buffer.append(event_data)
            
            # Calculate windowed features
            current_time = datetime.now()
            window_start = current_time - self.window_size
            
            # Filter recent events
            recent_events = [
                event for event in self.feature_buffer 
                if pd.to_datetime(event[&apos;timestamp&apos;]) &amp;gt; window_start
            ]
            
            if recent_events:
                recent_df = pd.DataFrame(recent_events)
                features = self._calculate_windowed_features(recent_df)
                
                # Store features in Redis for real-time serving
                self._store_features_redis(features)
    
    def _calculate_windowed_features(self, df):
        &quot;&quot;&quot;Calculate features over a time window&quot;&quot;&quot;
        
        # Ensure proper data types
        df[&apos;timestamp&apos;] = pd.to_datetime(df[&apos;timestamp&apos;])
        df[&apos;page_views&apos;] = pd.to_numeric(df[&apos;page_views&apos;], errors=&apos;coerce&apos;).fillna(0)
        df[&apos;clicks&apos;] = pd.to_numeric(df[&apos;clicks&apos;], errors=&apos;coerce&apos;).fillna(0)
        
        # Group by user and calculate features
        user_features = df.groupby(&apos;user_id&apos;).agg({
            &apos;page_views&apos;: [&apos;sum&apos;, &apos;count&apos;],
            &apos;clicks&apos;: &apos;sum&apos;,
            &apos;session_duration&apos;: &apos;mean&apos;,
            &apos;timestamp&apos;: &apos;count&apos;  # Event frequency
        })
        
        # Flatten columns
        user_features.columns = [&apos;_&apos;.join(col).strip() for col in user_features.columns]
        
        # Add time-based features
        current_hour = datetime.now().hour
        user_features[&apos;current_hour&apos;] = current_hour
        user_features[&apos;is_business_hours&apos;] = (9 &amp;lt;= current_hour &amp;lt;= 17).astype(int)
        
        # Calculate rates
        user_features[&apos;click_rate&apos;] = (
            user_features[&apos;clicks_sum&apos;] / 
            (user_features[&apos;page_views_sum&apos;] + 1)
        )
        
        user_features[&apos;events_per_minute&apos;] = (
            user_features[&apos;timestamp_count&apos;] / 5  # 5-minute window
        )
        
        return user_features
    
    def _store_features_redis(self, features):
        &quot;&quot;&quot;Store computed features in Redis with TTL&quot;&quot;&quot;
        
        for user_id in features.index:
            feature_dict = features.loc[user_id].to_dict()
            
            # Store with 10-minute TTL
            key = f&quot;user_features:{user_id}&quot;
            self.redis_client.hmset(key, feature_dict)
            self.redis_client.expire(key, 600)  # 10 minutes

# Production deployment example
def deploy_stream_processor():
    kafka_config = {
        &apos;bootstrap_servers&apos;: [&apos;kafka1:9092&apos;, &apos;kafka2:9092&apos;],
        &apos;group_id&apos;: &apos;feature-processor&apos;,
        &apos;auto_offset_reset&apos;: &apos;latest&apos;,
        &apos;enable_auto_commit&apos;: True,
        &apos;value_deserializer&apos;: lambda m: json.loads(m.decode(&apos;utf-8&apos;))
    }
    
    redis_client = redis.Redis(
        host=&apos;redis-cluster.example.com&apos;,
        port=6379,
        decode_responses=True
    )
    
    processor = RealTimeFeatureProcessor(kafka_config, redis_client)
    
    try:
        processor.process_stream()
    except KeyboardInterrupt:
        print(&quot;Shutting down stream processor...&quot;)
    except Exception as e:
        print(f&quot;Error in stream processing: {e}&quot;)
        # Add error handling and retry logic

if __name__ == &quot;__main__&quot;:
    deploy_stream_processor()




MLOps Production Tips

Performance and scalability best practices for MLOps:


  Format Optimization: Use Parquet format for 5-10x faster I/O compared to CSV
  Memory Management: Use categorical dtypes and optimize data types to reduce memory usage
  Chunk Processing: Process large datasets in chunks to avoid memory overflow
  Parallel Processing: Leverage Dask for distributed computing when datasets exceed single-machine capacity
  Data Validation: Implement Great Expectations for automated data quality checks
  Caching Strategy: Cache intermediate results and use efficient storage formats




Scikit-Learn: Complete Machine Learning Pipeline Framework

Scikit-Learn provides a unified, production-ready framework for building complete machine learning pipelines. Its consistent API design and powerful pipeline patterns enable seamless workflows from experimentation to deployment, making it the gold standard for traditional machine learning tasks.



Why Scikit-Learn is Central to MLOps

Scikit-Learn isn’t just a machine learning library—it’s the complete ML ecosystem for MLOps:


  Consistent API: Uniform fit(), predict(), transform() interface across all components
  Pipeline Architecture: Combines preprocessing and modeling into single, deployable objects
  Model Selection: Built-in cross-validation and hyperparameter tuning capabilities
  Production Ready: Robust serialization with joblib for model persistence
  Extensive Algorithms: Comprehensive collection of supervised and unsupervised learning algorithms
  Integration Friendly: Seamless compatibility with NumPy, Pandas, and deployment frameworks




Core Scikit-Learn Components


  
    
      Component Category
      Key Classes
      MLOps Applications
    
    
      Preprocessing
      StandardScaler, OneHotEncoder, LabelEncoder
      Feature normalization, categorical encoding, data transformation
    
    
      Models
      RandomForest, SVM, LogisticRegression, XGBoost
      Classification, regression, prediction tasks
    
    
      Pipeline
      Pipeline, ColumnTransformer, FeatureUnion
      Workflow automation, reproducible preprocessing
    
    
      Model Selection
      GridSearchCV, RandomizedSearchCV, cross_val_score
      Hyperparameter tuning, model validation, performance estimation
    
    
      Metrics
      accuracy_score, precision_recall_curve, roc_auc_score
      Model evaluation, performance monitoring, A/B testing
    
  




Production-Ready Implementation Examples

Complete ML Pipeline with Best Practices

Building a robust, production-ready machine learning pipeline:

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix
import joblib
import pandas as pd
import numpy as np
from datetime import datetime
import logging

class ProductionMLPipeline:
    def __init__(self, config=None):
        self.config = config or self._default_config()
        self.pipeline = None
        self.is_trained = False
        self.training_metadata = {}
        self.logger = self._setup_logging()
    
    def _default_config(self):
        &quot;&quot;&quot;Default configuration for the ML pipeline&quot;&quot;&quot;
        return {
            &apos;model_type&apos;: &apos;random_forest&apos;,
            &apos;random_state&apos;: 42,
            &apos;test_size&apos;: 0.2,
            &apos;cv_folds&apos;: 5,
            &apos;n_jobs&apos;: -1,
            &apos;hyperparameter_tuning&apos;: True
        }
    
    def _setup_logging(self):
        &quot;&quot;&quot;Configure logging for the pipeline&quot;&quot;&quot;
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                &apos;%(asctime)s - %(name)s - %(levelname)s - %(message)s&apos;
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def build_pipeline(self, feature_config):
        &quot;&quot;&quot;Build a complete ML pipeline with preprocessing and modeling&quot;&quot;&quot;
        
        numeric_features = feature_config.get(&apos;numeric_features&apos;, [])
        categorical_features = feature_config.get(&apos;categorical_features&apos;, [])
        
        # Create preprocessing pipeline
        preprocessor = ColumnTransformer(
            transformers=[
                (&apos;num&apos;, StandardScaler(), numeric_features),
                (&apos;cat&apos;, OneHotEncoder(drop=&apos;first&apos;, sparse_output=False, handle_unknown=&apos;ignore&apos;), 
                 categorical_features)
            ],
            remainder=&apos;passthrough&apos;  # Keep other columns as-is
        )
        
        # Select model based on configuration
        if self.config[&apos;model_type&apos;] == &apos;random_forest&apos;:
            model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=self.config[&apos;random_state&apos;],
                n_jobs=self.config[&apos;n_jobs&apos;]
            )
        elif self.config[&apos;model_type&apos;] == &apos;logistic_regression&apos;:
            from sklearn.linear_model import LogisticRegression
            model = LogisticRegression(
                random_state=self.config[&apos;random_state&apos;],
                max_iter=1000,
                n_jobs=self.config[&apos;n_jobs&apos;]
            )
        else:
            raise ValueError(f&quot;Unsupported model type: {self.config[&apos;model_type&apos;]}&quot;)
        
        # Create complete pipeline
        self.pipeline = Pipeline([
            (&apos;preprocessor&apos;, preprocessor),
            (&apos;classifier&apos;, model)
        ])
        
        self.logger.info(f&quot;Built pipeline with {self.config[&apos;model_type&apos;]} model&quot;)
        return self.pipeline
    
    def train(self, X, y, feature_config):
        &quot;&quot;&quot;Train the model with comprehensive validation&quot;&quot;&quot;
        
        if self.pipeline is None:
            self.build_pipeline(feature_config)
        
        self.logger.info(&quot;Starting model training...&quot;)
        training_start = datetime.now()
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, 
            test_size=self.config[&apos;test_size&apos;], 
            random_state=self.config[&apos;random_state&apos;],
            stratify=y
        )
        
        # Hyperparameter tuning if enabled
        if self.config[&apos;hyperparameter_tuning&apos;]:
            self.pipeline = self._tune_hyperparameters(X_train, y_train)
        
        # Train final model
        self.pipeline.fit(X_train, y_train)
        self.is_trained = True
        
        # Evaluate model
        train_score = self.pipeline.score(X_train, y_train)
        test_score = self.pipeline.score(X_test, y_test)
        
        # Cross-validation
        cv_scores = cross_val_score(
            self.pipeline, X, y, 
            cv=self.config[&apos;cv_folds&apos;], 
            scoring=&apos;accuracy&apos;
        )
        
        # Generate detailed evaluation
        y_pred = self.pipeline.predict(X_test)
        classification_rep = classification_report(y_test, y_pred, output_dict=True)
        
        # Store training metadata
        self.training_metadata = {
            &apos;training_time&apos;: (datetime.now() - training_start).total_seconds(),
            &apos;train_accuracy&apos;: train_score,
            &apos;test_accuracy&apos;: test_score,
            &apos;cv_mean&apos;: cv_scores.mean(),
            &apos;cv_std&apos;: cv_scores.std(),
            &apos;train_samples&apos;: len(X_train),
            &apos;test_samples&apos;: len(X_test),
            &apos;feature_count&apos;: X.shape[1],
            &apos;classification_report&apos;: classification_rep,
            &apos;model_config&apos;: self.config,
            &apos;timestamp&apos;: datetime.now().isoformat()
        }
        
        self.logger.info(f&quot;Training completed. Test accuracy: {test_score:.4f}&quot;)
        return self.training_metadata
    
    def _tune_hyperparameters(self, X_train, y_train):
        &quot;&quot;&quot;Perform hyperparameter tuning&quot;&quot;&quot;
        
        self.logger.info(&quot;Starting hyperparameter tuning...&quot;)
        
        if self.config[&apos;model_type&apos;] == &apos;random_forest&apos;:
            param_grid = {
                &apos;classifier__n_estimators&apos;: [50, 100, 200],
                &apos;classifier__max_depth&apos;: [5, 10, 15, None],
                &apos;classifier__min_samples_split&apos;: [2, 5, 10],
                &apos;classifier__min_samples_leaf&apos;: [1, 2, 4]
            }
        elif self.config[&apos;model_type&apos;] == &apos;logistic_regression&apos;:
            param_grid = {
                &apos;classifier__C&apos;: [0.1, 1.0, 10.0, 100.0],
                &apos;classifier__penalty&apos;: [&apos;l1&apos;, &apos;l2&apos;],
                &apos;classifier__solver&apos;: [&apos;liblinear&apos;, &apos;saga&apos;]
            }
        
        grid_search = GridSearchCV(
            self.pipeline, 
            param_grid,
            cv=3,  # Reduced for faster tuning
            scoring=&apos;accuracy&apos;,
            n_jobs=self.config[&apos;n_jobs&apos;],
            verbose=1
        )
        
        grid_search.fit(X_train, y_train)
        
        self.logger.info(f&quot;Best parameters: {grid_search.best_params_}&quot;)
        self.logger.info(f&quot;Best CV score: {grid_search.best_score_:.4f}&quot;)
        
        return grid_search.best_estimator_
    
    def predict(self, X):
        &quot;&quot;&quot;Make predictions with the trained model&quot;&quot;&quot;
        
        if not self.is_trained:
            raise ValueError(&quot;Model must be trained before making predictions&quot;)
        
        predictions = self.pipeline.predict(X)
        probabilities = self.pipeline.predict_proba(X) if hasattr(self.pipeline, &apos;predict_proba&apos;) else None
        
        return {
            &apos;predictions&apos;: predictions.tolist(),
            &apos;probabilities&apos;: probabilities.tolist() if probabilities is not None else None
        }
    
    def save_model(self, filepath):
        &quot;&quot;&quot;Save the trained model with metadata&quot;&quot;&quot;
        
        if not self.is_trained:
            raise ValueError(&quot;Cannot save untrained model&quot;)
        
        model_data = {
            &apos;pipeline&apos;: self.pipeline,
            &apos;metadata&apos;: self.training_metadata,
            &apos;config&apos;: self.config
        }
        
        joblib.dump(model_data, filepath)
        self.logger.info(f&quot;Model saved to {filepath}&quot;)
    
    @classmethod
    def load_model(cls, filepath):
        &quot;&quot;&quot;Load a saved model&quot;&quot;&quot;
        
        model_data = joblib.load(filepath)
        
        instance = cls(config=model_data[&apos;config&apos;])
        instance.pipeline = model_data[&apos;pipeline&apos;]
        instance.training_metadata = model_data[&apos;metadata&apos;]
        instance.is_trained = True
        
        return instance
    
    def get_feature_importance(self):
        &quot;&quot;&quot;Get feature importance if available&quot;&quot;&quot;
        
        if not self.is_trained:
            raise ValueError(&quot;Model must be trained first&quot;)
        
        if hasattr(self.pipeline.named_steps[&apos;classifier&apos;], &apos;feature_importances_&apos;):
            return self.pipeline.named_steps[&apos;classifier&apos;].feature_importances_
        else:
            return None

# Example usage with comprehensive validation
def train_production_model():
    &quot;&quot;&quot;Example of training a production-ready model&quot;&quot;&quot;
    
    # Load data
    data = pd.read_csv(&apos;user_behavior_dataset.csv&apos;)
    
    # Define features
    feature_config = {
        &apos;numeric_features&apos;: [&apos;age&apos;, &apos;income&apos;, &apos;session_duration&apos;, &apos;page_views&apos;],
        &apos;categorical_features&apos;: [&apos;gender&apos;, &apos;device_type&apos;, &apos;region&apos;, &apos;subscription_type&apos;]
    }
    
    # Prepare data
    X = data[feature_config[&apos;numeric_features&apos;] + feature_config[&apos;categorical_features&apos;]]
    y = data[&apos;target&apos;]
    
    # Initialize and train pipeline
    ml_pipeline = ProductionMLPipeline({
        &apos;model_type&apos;: &apos;random_forest&apos;,
        &apos;hyperparameter_tuning&apos;: True,
        &apos;cv_folds&apos;: 5
    })
    
    # Train model
    results = ml_pipeline.train(X, y, feature_config)
    
    # Save model
    ml_pipeline.save_model(&apos;models/production_model.pkl&apos;)
    
    # Print results
    print(f&quot;Model Performance:&quot;)
    print(f&quot;  Test Accuracy: {results[&apos;test_accuracy&apos;]:.4f}&quot;)
    print(f&quot;  CV Score: {results[&apos;cv_mean&apos;]:.4f} ± {results[&apos;cv_std&apos;]:.4f}&quot;)
    print(f&quot;  Training Time: {results[&apos;training_time&apos;]:.2f} seconds&quot;)
    
    return ml_pipeline

# Load and use trained model
def use_trained_model():
    &quot;&quot;&quot;Example of loading and using a trained model&quot;&quot;&quot;
    
    # Load model
    model = ProductionMLPipeline.load_model(&apos;models/production_model.pkl&apos;)
    
    # Make predictions on new data
    new_data = pd.DataFrame({
        &apos;age&apos;: [25, 35, 45],
        &apos;income&apos;: [50000, 75000, 100000],
        &apos;session_duration&apos;: [120, 180, 90],
        &apos;page_views&apos;: [5, 8, 3],
        &apos;gender&apos;: [&apos;M&apos;, &apos;F&apos;, &apos;M&apos;],
        &apos;device_type&apos;: [&apos;mobile&apos;, &apos;desktop&apos;, &apos;tablet&apos;],
        &apos;region&apos;: [&apos;US&apos;, &apos;EU&apos;, &apos;ASIA&apos;],
        &apos;subscription_type&apos;: [&apos;basic&apos;, &apos;premium&apos;, &apos;basic&apos;]
    })
    
    predictions = model.predict(new_data)
    return predictions

if __name__ == &quot;__main__&quot;:
    # Train model
    trained_model = train_production_model()
    
    # Use model for predictions
    predictions = use_trained_model()
    print(f&quot;Predictions: {predictions}&quot;)




Model Comparison for A/B Testing

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
import mlflow
import mlflow.sklearn

class ModelExperiment:
    def __init__(self, experiment_name):
        mlflow.set_experiment(experiment_name)
        self.models = {
            &apos;random_forest&apos;: RandomForestClassifier(n_estimators=100, random_state=42),
            &apos;gradient_boosting&apos;: GradientBoostingClassifier(n_estimators=100, random_state=42),
            &apos;logistic_regression&apos;: LogisticRegression(random_state=42, max_iter=1000)
        }
    
    def run_experiment(self, X_train, X_test, y_train, y_test):
        &quot;&quot;&quot;Run experiment comparing multiple models&quot;&quot;&quot;
        
        results = {}
        
        for model_name, model in self.models.items():
            with mlflow.start_run(run_name=model_name):
                
                # Train model
                model.fit(X_train, y_train)
                
                # Make predictions
                y_pred = model.predict(X_test)
                y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, &apos;predict_proba&apos;) else None
                
                # Calculate performance metrics
                accuracy = model.score(X_test, y_test)
                
                # Log to MLflow
                mlflow.log_param(&quot;model_type&quot;, model_name)
                mlflow.log_metric(&quot;accuracy&quot;, accuracy)
                
                if hasattr(model, &apos;feature_importances_&apos;):
                    # Log feature importance
                    feature_importance = dict(zip(
                        X_train.columns, 
                        model.feature_importances_
                    ))
                    mlflow.log_params(feature_importance)
                
                # Save model
                mlflow.sklearn.log_model(model, f&quot;{model_name}_model&quot;)
                
                results[model_name] = {
                    &apos;accuracy&apos;: accuracy,
                    &apos;model&apos;: model,
                    &apos;predictions&apos;: y_pred
                }
        
        return results


MLOps Production Tips

1. Model Version Management:

  Manage model lifecycle with MLflow Model Registry
  Include metadata in models (training date, data version, etc.)


2. Deployment Optimization:

  Convert to ONNX format for improved inference performance
  Reduce model size with quantization


3. Monitoring:

  Detect input data distribution changes (Data Drift)
  Automated alerts for model performance degradation




Running Locally

Let’s build a complete MLOps pipeline using NumPy, Pandas, and Scikit-Learn as learned above. Theory alone is not enough—get hands-on and practice!



Create and Activate Virtual Environment

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Result: (venv) prompt appears, indicating the environment is active




Install Dependencies

# Install required packages
pip3 install numpy pandas scikit-learn fastapi uvicorn

# Result: Required packages are installed and progress is shown
# Collecting numpy&amp;gt;=1.26.0
# Collecting pandas&amp;gt;=2.1.0  
# Collecting scikit-learn&amp;gt;=1.3.2
# ...
# Successfully installed numpy-1.26.0 pandas-2.1.0 scikit-learn-1.3.2 ...




Data Preprocessing

# preprocess.py
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import pickle
import os

def preprocess_data():
    &quot;&quot;&quot;Generate and preprocess sample data&quot;&quot;&quot;
    
    # Generate sample user behavior data
    np.random.seed(42)
    n_samples = 1000
    
    data = pd.DataFrame({
        &apos;age&apos;: np.random.randint(18, 65, n_samples),
        &apos;income&apos;: np.random.normal(50000, 15000, n_samples),
        &apos;session_duration&apos;: np.random.exponential(120, n_samples),
        &apos;page_views&apos;: np.random.poisson(5, n_samples),
        &apos;purchases&apos;: np.random.binomial(1, 0.3, n_samples)
    })
    
    # Feature engineering
    data[&apos;income_age_ratio&apos;] = data[&apos;income&apos;] / data[&apos;age&apos;]
    data[&apos;engagement_score&apos;] = (data[&apos;session_duration&apos;] * data[&apos;page_views&apos;]) / 100
    
    # Prepare features and target
    features = [&apos;age&apos;, &apos;income&apos;, &apos;session_duration&apos;, &apos;page_views&apos;, &apos;income_age_ratio&apos;, &apos;engagement_score&apos;]
    X = data[features]
    y = data[&apos;purchases&apos;]
    
    # Feature scaling
    scaler = StandardScaler()
    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=features)
    
    # Save processed data
    os.makedirs(&apos;data&apos;, exist_ok=True)
    X_scaled.to_csv(&apos;data/X.csv&apos;, index=False)
    y.to_csv(&apos;data/y.csv&apos;, index=False)
    
    # Save scaler for production use
    with open(&apos;data/scaler.pkl&apos;, &apos;wb&apos;) as f:
        pickle.dump(scaler, f)
    
    print(&quot;✅ Data preprocessing complete&quot;)
    print(f&quot;📊 Dataset shape: {X_scaled.shape}&quot;)
    print(f&quot;🎯 Target distribution: {y.value_counts().to_dict()}&quot;)
    
    return X_scaled, y

if __name__ == &quot;__main__&quot;:
    preprocess_data()


# Run data preprocessing
python3 preprocess.py

# Result: Data preprocessing is complete and the following files are generated
# ✅ Data preprocessing complete
# 📊 Dataset shape: (1000, 6)
# 🎯 Target distribution: {0: 700, 1: 300}
# data/X.csv  # Preprocessed input data
# data/y.csv  # Preprocessed target data  
# data/scaler.pkl  # Scaler parameters




Model Training

# train_model.py
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report
import pickle
import os

def train_model():
    &quot;&quot;&quot;Train and evaluate ML model&quot;&quot;&quot;
    
    # Load processed data
    X = pd.read_csv(&apos;data/X.csv&apos;)
    y = pd.read_csv(&apos;data/y.csv&apos;).squeeze()
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Train model
    model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
    model.fit(X_train, y_train)
    
    # Evaluate model
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    cv_scores = cross_val_score(model, X_train, y_train, cv=5)
    
    print(&quot;🎯 Model training results:&quot;)
    print(f&quot;   Test accuracy: {accuracy:.4f}&quot;)
    print(f&quot;   Cross-validation score: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}&quot;)
    print(&quot;\n📈 Classification report:&quot;)
    print(classification_report(y_test, y_pred))
    
    # Save model
    os.makedirs(&apos;model&apos;, exist_ok=True)
    with open(&apos;model/model.pkl&apos;, &apos;wb&apos;) as f:
        pickle.dump(model, f)
    
    print(&quot;💾 Model saved to model/model.pkl&quot;)
    return model

if __name__ == &quot;__main__&quot;:
    train_model()


# Run model training
python3 train_model.py

# Result: Model training is complete and the following output is shown
# 🎯 Model training results:
#    Test accuracy: 0.8500
#    Cross-validation score: 0.8400 ± 0.0200
# 📈 Classification report:
# ...
# 💾 Model saved to model/model.pkl




Run API Server

# predict_api.py  
from fastapi import FastAPI, HTTPException
import pandas as pd
import numpy as np
import pickle
from pydantic import BaseModel
import uvicorn

app = FastAPI(
    title=&quot;MLOps Prediction API&quot;,
    description=&quot;Production-grade ML API for hands-on MLOps practice&quot;,
    version=&quot;1.0.0&quot;
)

# Load model and scaler at startup
with open(&apos;model/model.pkl&apos;, &apos;rb&apos;) as f:
    model = pickle.load(f)

with open(&apos;data/scaler.pkl&apos;, &apos;rb&apos;) as f:
    scaler = pickle.load(f)

class PredictionRequest(BaseModel):
    age: float
    income: float
    session_duration: float
    page_views: int

@app.get(&quot;/&quot;)
async def root():
    return {&quot;message&quot;: &quot;MLOps Prediction API is running!&quot;, &quot;status&quot;: &quot;healthy&quot;}

@app.get(&quot;/health&quot;)
async def health_check():
    return {&quot;status&quot;: &quot;healthy&quot;, &quot;model_loaded&quot;: model is not None}

@app.post(&quot;/predict&quot;)
async def predict(request: PredictionRequest):
    try:
        # Feature engineering
        income_age_ratio = request.income / request.age
        engagement_score = (request.session_duration * request.page_views) / 100
        
        # Prepare and scale features
        features = np.array([[
            request.age, request.income, request.session_duration,
            request.page_views, income_age_ratio, engagement_score
        ]])
        features_scaled = scaler.transform(features)
        
        # Make prediction
        prediction = model.predict(features_scaled)[0]
        probability = model.predict_proba(features_scaled)[0][1]
        
        return {
            &quot;prediction&quot;: int(prediction),
            &quot;probability&quot;: float(probability),
            &quot;confidence&quot;: &quot;High&quot; if probability &amp;gt; 0.8 else &quot;Medium&quot; if probability &amp;gt; 0.6 else &quot;Low&quot;,
            &quot;input_features&quot;: request.dict()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f&quot;Prediction error: {str(e)}&quot;)

if __name__ == &quot;__main__&quot;:
    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8000)


# Run API server
python3 predict_api.py

# Result: FastAPI server starts and the following message is shown
# INFO:     Started server process [xxxxx]
# INFO:     Waiting for application startup.
# INFO:     Application startup complete.
# INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)




API Test and Verification

Once the server is running, you can test the API as follows:









Deactivate Virtual Environment

# Deactivate virtual environment
deactivate

# Result: (venv) prompt disappears, indicating the environment is deactivated



  🎉 Congratulations!
  You have successfully built a complete MLOps pipeline using NumPy, Pandas, and Scikit-Learn:
  
    ✅ Data preprocessing including feature engineering
    ✅ Model training with proper evaluation
    ✅ Production-grade API with comprehensive error handling
    ✅ Health check and monitoring endpoints
    ✅ Scalable architecture ready for containerization
  




Production Deployment: FastAPI + Docker

Let’s examine a complete example of deploying ML models in a real service environment.



1. FastAPI-based Inference Server

# app.py
from fastapi import FastAPI, HTTPException, UploadFile, File
from pydantic import BaseModel
import pandas as pd
import joblib
import numpy as np
from typing import List
import io

app = FastAPI(title=&quot;ML Model API&quot;, version=&quot;1.0.0&quot;)

# Global variable for model loading
model = None

@app.on_event(&quot;startup&quot;)
async def load_model():
    &quot;&quot;&quot;Load model when application starts&quot;&quot;&quot;
    global model
    try:
        model = joblib.load(&apos;model/production_model.pkl&apos;)
        print(&quot;Model loaded successfully.&quot;)
    except Exception as e:
        print(f&quot;Model loading failed: {e}&quot;)

class PredictionRequest(BaseModel):
    &quot;&quot;&quot;Single prediction request schema&quot;&quot;&quot;
    age: int
    income: float
    session_duration: float
    gender: str
    device_type: str
    region: str

class BatchPredictionRequest(BaseModel):
    &quot;&quot;&quot;Batch prediction request schema&quot;&quot;&quot;
    data: List[PredictionRequest]

@app.get(&quot;/&quot;)
async def health_check():
    &quot;&quot;&quot;Health check endpoint&quot;&quot;&quot;
    return {&quot;status&quot;: &quot;healthy&quot;, &quot;model_loaded&quot;: model is not None}

@app.post(&quot;/predict&quot;)
async def predict_single(request: PredictionRequest):
    &quot;&quot;&quot;Single data prediction&quot;&quot;&quot;
    if model is None:
        raise HTTPException(status_code=503, detail=&quot;Model is not loaded.&quot;)
    
    try:
        # Convert input data to DataFrame
        input_data = pd.DataFrame([request.dict()])
        
        # Perform prediction
        prediction = model.predict(input_data)[0]
        probability = model.predict_proba(input_data)[0].tolist()
        
        return {
            &quot;prediction&quot;: int(prediction),
            &quot;probability&quot;: probability,
            &quot;input_data&quot;: request.dict()
        }
        
    except Exception as e:
        raise HTTPException(status_code=400, detail=f&quot;Prediction failed: {str(e)}&quot;)

@app.post(&quot;/predict_batch&quot;)
async def predict_batch(request: BatchPredictionRequest):
    &quot;&quot;&quot;Batch data prediction&quot;&quot;&quot;
    if model is None:
        raise HTTPException(status_code=503, detail=&quot;Model is not loaded.&quot;)
    
    try:
        # Convert batch data to DataFrame
        input_data = pd.DataFrame([item.dict() for item in request.data])
        
        # Perform batch prediction
        predictions = model.predict(input_data).tolist()
        probabilities = model.predict_proba(input_data).tolist()
        
        return {
            &quot;predictions&quot;: predictions,
            &quot;probabilities&quot;: probabilities,
            &quot;batch_size&quot;: len(request.data)
        }
        
    except Exception as e:
        raise HTTPException(status_code=400, detail=f&quot;Batch prediction failed: {str(e)}&quot;)

@app.post(&quot;/predict_csv&quot;)
async def predict_csv(file: UploadFile = File(...)):
    &quot;&quot;&quot;Prediction via CSV file upload&quot;&quot;&quot;
    if model is None:
        raise HTTPException(status_code=503, detail=&quot;Model is not loaded.&quot;)
    
    if not file.filename.endswith(&apos;.csv&apos;):
        raise HTTPException(status_code=400, detail=&quot;Only CSV files can be uploaded.&quot;)
    
    try:
        # Read CSV file
        contents = await file.read()
        df = pd.read_csv(io.StringIO(contents.decode(&apos;utf-8&apos;)))
        
        # Perform prediction
        predictions = model.predict(df).tolist()
        probabilities = model.predict_proba(df).tolist()
        
        return {
            &quot;predictions&quot;: predictions,
            &quot;probabilities&quot;: probabilities,
            &quot;rows_processed&quot;: len(df)
        }
        
    except Exception as e:
        raise HTTPException(status_code=400, detail=f&quot;CSV prediction failed: {str(e)}&quot;)

if __name__ == &quot;__main__&quot;:
    import uvicorn
    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8000)




2. Docker Containerization







3. Kubernetes Deployment

# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-model-api
  labels:
    app: ml-model-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ml-model-api
  template:
    metadata:
      labels:
        app: ml-model-api
    spec:
      containers:
      - name: ml-api
        image: your-registry/ml-model-api:latest
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: &quot;512Mi&quot;
            cpu: &quot;250m&quot;
          limits:
            memory: &quot;1Gi&quot;
            cpu: &quot;500m&quot;
        livenessProbe:
          httpGet:
            path: /
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: ml-model-service
spec:
  selector:
    app: ml-model-api
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: LoadBalancer




Performance Monitoring and Automation



1. Data Drift Detection

import pandas as pd
from scipy import stats
import numpy as np
from datetime import datetime
import warnings

class DataDriftMonitor:
    def __init__(self, reference_data, threshold=0.05):
        &quot;&quot;&quot;
        Data drift monitoring class
        
        Args:
            reference_data: Reference training data
            threshold: p-value threshold (default: 0.05)
        &quot;&quot;&quot;
        self.reference_data = reference_data
        self.threshold = threshold
        self.baseline_stats = self._calculate_baseline_stats()
    
    def _calculate_baseline_stats(self):
        &quot;&quot;&quot;Calculate baseline statistics from reference data&quot;&quot;&quot;
        stats_dict = {}
        
        for column in self.reference_data.columns:
            if self.reference_data[column].dtype in [&apos;int64&apos;, &apos;float64&apos;]:
                stats_dict[column] = {
                    &apos;mean&apos;: self.reference_data[column].mean(),
                    &apos;std&apos;: self.reference_data[column].std(),
                    &apos;distribution&apos;: self.reference_data[column].values
                }
            else:
                stats_dict[column] = {
                    &apos;value_counts&apos;: self.reference_data[column].value_counts().to_dict()
                }
        
        return stats_dict
    
    def detect_drift(self, new_data):
        &quot;&quot;&quot;Detect drift in new data&quot;&quot;&quot;
        drift_results = {}
        
        for column in new_data.columns:
            if column not in self.baseline_stats:
                continue
                
            if new_data[column].dtype in [&apos;int64&apos;, &apos;float64&apos;]:
                # Numerical data: Kolmogorov-Smirnov test
                ks_statistic, p_value = stats.ks_2samp(
                    self.baseline_stats[column][&apos;distribution&apos;],
                    new_data[column].values
                )
                
                drift_results[column] = {
                    &apos;drift_detected&apos;: p_value &amp;lt; self.threshold,
                    &apos;p_value&apos;: p_value,
                    &apos;ks_statistic&apos;: ks_statistic,
                    &apos;mean_shift&apos;: abs(new_data[column].mean() - self.baseline_stats[column][&apos;mean&apos;])
                }
            else:
                # Categorical data: Chi-square test
                new_counts = new_data[column].value_counts().to_dict()
                baseline_counts = self.baseline_stats[column][&apos;value_counts&apos;]
                
                # Compare only common categories
                common_categories = set(new_counts.keys()) &amp;amp; set(baseline_counts.keys())
                
                if len(common_categories) &amp;gt; 1:
                    observed = [new_counts.get(cat, 0) for cat in common_categories]
                    expected = [baseline_counts.get(cat, 0) for cat in common_categories]
                    
                    chi2_stat, p_value = stats.chisquare(observed, expected)
                    
                    drift_results[column] = {
                        &apos;drift_detected&apos;: p_value &amp;lt; self.threshold,
                        &apos;p_value&apos;: p_value,
                        &apos;chi2_statistic&apos;: chi2_stat
                    }
        
        return drift_results
    
    def generate_drift_report(self, drift_results):
        &quot;&quot;&quot;Generate drift detection result report&quot;&quot;&quot;
        drifted_features = [col for col, result in drift_results.items() 
                           if result[&apos;drift_detected&apos;]]
        
        report = {
            &apos;timestamp&apos;: datetime.now().isoformat(),
            &apos;total_features_checked&apos;: len(drift_results),
            &apos;drifted_features_count&apos;: len(drifted_features),
            &apos;drifted_features&apos;: drifted_features,
            &apos;drift_severity&apos;: &apos;HIGH&apos; if len(drifted_features) &amp;gt; len(drift_results) * 0.3 else &apos;LOW&apos;,
            &apos;detailed_results&apos;: drift_results
        }
        
        return report

# Usage Example
monitor = DataDriftMonitor(reference_data=training_data)
new_batch = pd.read_csv(&apos;latest_production_data.csv&apos;)
drift_results = monitor.detect_drift(new_batch)
report = monitor.generate_drift_report(drift_results)

if report[&apos;drift_severity&apos;] == &apos;HIGH&apos;:
    print(&quot;⚠️ High level of data drift detected!&quot;)
    print(f&quot;Affected features: {report[&apos;drifted_features&apos;]}&quot;)




2. Automated Retraining Pipeline

import schedule
import time
from datetime import datetime, timedelta
import logging

class AutoMLPipeline:
    def __init__(self, config):
        self.config = config
        self.logger = self._setup_logging()
        self.drift_monitor = DataDriftMonitor(reference_data=None)
        
    def _setup_logging(self):
        &quot;&quot;&quot;Logging configuration&quot;&quot;&quot;
        logging.basicConfig(
            level=logging.INFO,
            format=&apos;%(asctime)s - %(levelname)s - %(message)s&apos;,
            handlers=[
                logging.FileHandler(&apos;ml_pipeline.log&apos;),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger(__name__)
    
    def check_and_retrain(self):
        &quot;&quot;&quot;Check data drift and retrain if necessary&quot;&quot;&quot;
        self.logger.info(&quot;Starting data drift check&quot;)
        
        try:
            # 1. Collect latest production data
            new_data = self._collect_production_data()
            
            # 2. Detect drift
            if hasattr(self, &apos;reference_data&apos;):
                drift_results = self.drift_monitor.detect_drift(new_data)
                report = self.drift_monitor.generate_drift_report(drift_results)
                
                # 3. Determine retraining necessity
                if self._should_retrain(report):
                    self.logger.info(&quot;Retraining is needed. Starting retraining.&quot;)
                    self._retrain_model(new_data)
                else:
                    self.logger.info(&quot;Model is stable. No retraining needed.&quot;)
            else:
                self.logger.info(&quot;No reference data available. Proceeding with initial training.&quot;)
                self._train_initial_model(new_data)
                
        except Exception as e:
            self.logger.error(f&quot;Error during pipeline execution: {e}&quot;)
    
    def _collect_production_data(self):
        &quot;&quot;&quot;Collect data from production environment&quot;&quot;&quot;
        # In actual implementation, collect data from database, S3, Kafka, etc.
        end_date = datetime.now()
        start_date = end_date - timedelta(days=7)
        
        # Example: Collect data from PostgreSQL
        query = f&quot;&quot;&quot;
        SELECT * FROM user_features 
        WHERE created_at BETWEEN &apos;{start_date}&apos; AND &apos;{end_date}&apos;
        &quot;&quot;&quot;
        
        return pd.read_sql(query, con=self.config[&apos;database_connection&apos;])
    
    def _should_retrain(self, drift_report):
        &quot;&quot;&quot;Determine retraining necessity&quot;&quot;&quot;
        return (
            drift_report[&apos;drift_severity&apos;] == &apos;HIGH&apos; or
            drift_report[&apos;drifted_features_count&apos;] &amp;gt; 3
        )
    
    def _retrain_model(self, new_data):
        &quot;&quot;&quot;Model retraining&quot;&quot;&quot;
        try:
            # 1. Data preprocessing
            X, y = self._preprocess_data(new_data)
            
            # 2. Train new model
            new_pipeline = MLPipeline()
            results = new_pipeline.train(X, y)
            
            # 3. Validate model performance
            if self._validate_new_model(new_pipeline, results):
                # 4. Deploy model
                self._deploy_model(new_pipeline)
                self.logger.info(&quot;New model deployed successfully.&quot;)
            else:
                self.logger.warning(&quot;New model performance below standards.&quot;)
                
        except Exception as e:
            self.logger.error(f&quot;Error during retraining: {e}&quot;)
    
    def _validate_new_model(self, new_model, results):
        &quot;&quot;&quot;Validate new model performance&quot;&quot;&quot;
        # Compare with baseline performance
        min_accuracy = self.config.get(&apos;min_accuracy&apos;, 0.8)
        return results[&apos;test_accuracy&apos;] &amp;gt;= min_accuracy
    
    def _deploy_model(self, model):
        &quot;&quot;&quot;Model deployment&quot;&quot;&quot;
        # Timestamp for version management
        timestamp = datetime.now().strftime(&quot;%Y%m%d_%H%M%S&quot;)
        model_path = f&quot;models/model_{timestamp}.pkl&quot;
        
        # Save model
        model.save_model(model_path)
        
        # Update production model symbolic link
        import os
        if os.path.exists(&quot;models/production_model.pkl&quot;):
            os.remove(&quot;models/production_model.pkl&quot;)
        os.symlink(model_path, &quot;models/production_model.pkl&quot;)
        
        # Trigger rolling update in Kubernetes (optional)
        # kubectl patch deployment ml-model-api -p &apos;{&quot;spec&quot;:{&quot;template&quot;:{&quot;metadata&quot;:{&quot;labels&quot;:{&quot;date&quot;:&quot;&apos; + timestamp + &apos;&quot;}}}}}&apos;

# Scheduling configuration
pipeline = AutoMLPipeline(config)

# Run daily at 2 AM
schedule.every().day.at(&quot;02:00&quot;).do(pipeline.check_and_retrain)

# Run every Monday at 1 AM
schedule.every().monday.at(&quot;01:00&quot;).do(pipeline.check_and_retrain)

# Run scheduler
while True:
    schedule.run_pending()
    time.sleep(60)  # Check every minute




Key Points and Conclusion




  💡 MLOps Essentials Summary
  
    
      Foundation Libraries
      - NumPy: High-performance numerical computing foundation for all ML frameworks
      - Pandas: Data manipulation and ETL backbone for feature engineering pipelines
      - Scikit-Learn: Complete ML lifecycle from experimentation to production deployment
    
    
      Production Capabilities
      - Real-time data processing and feature engineering at scale
      - Automated model training with hyperparameter optimization
      - Containerized deployment with Docker and Kubernetes
      - Comprehensive monitoring and automated retraining workflows
    
    
      Best Practices
      - Use vectorized operations for 10-100x performance improvements
      - Implement proper data validation and quality checks
      - Design pipelines for reproducibility and version control
      - Monitor data drift and model performance in production
    
  



  The transition from DevOps to MLOps is no longer optional—it’s essential for modern infrastructure teams. NumPy, Pandas, and Scikit-Learn aren’t just data science tools; they’re the foundational components of modern AI service infrastructure that enable data-driven applications at scale.




Core Takeaways


  NumPy: Provides the high-performance numerical foundation that makes real-time data processing feasible
  Pandas: Serves as the central hub for data pipelines and feature stores in production systems
  Scikit-Learn: Delivers complete ML workflows from experimentation to production deployment




Next Steps for Expansion

With these fundamentals mastered, consider expanding into advanced MLOps technologies:




  
    
      Technology Category
      Recommended Tools and Platforms
    
    
      Experiment Management
      MLflow, Weights &amp;amp; Biases, Neptune.ai for tracking experiments and model versioning
    
    
      Workflow Orchestration
      Kubeflow, Argo Workflows, Apache Airflow for automating ML pipelines
    
    
      Real-time Processing
      Apache Kafka, Apache Spark, Apache Flink for streaming data processing
    
    
      Model Serving
      KServe, Seldon Core, TorchServe, TensorFlow Serving for production model deployment
    
    
      Monitoring &amp;amp; Observability
      Prometheus + Grafana, Evidently AI, WhyLabs for model and data monitoring
    
  


MLOps represents more than an extension of DevOps—it’s a fundamental shift toward data-centric thinking that enables entirely new dimensions of service operation and intelligence. The skills you’ve learned here provide the foundation for building AI-native applications that can adapt, learn, and improve over time.

Start implementing these concepts today to prepare for the AI-driven future of software infrastructure!



References


  NumPy Official Documentation
  Pandas Official Documentation
  Scikit-Learn Official Documentation
  FastAPI Official Documentation
  MLOps Best Practices
  Kubernetes ML Workloads
  Docker for Machine Learning


",
            "wordcount": "11337",
            "inLanguage": "en",
            "dateCreated": "2025-10-02/",
            "datePublished": "2025-10-02/",
            "dateModified": "2025-10-02/",
            "author": {
                "@type": "Person",
                "name": "Somaz",
                
                "image": "/assets/img/uploads/profile.png",
                
                "jobTitle": "DevOps Engineer",
                "url": "https://somaz.blog/authors/somaz/",
                "sameAs": [
                    "https://github.com/somaz94","https://www.linkedin.com/in/somaz"
                ]
            },
            "publisher": {
                "@type": "Organization",
                "name": "somaz",
                "url": "https://somaz.blog/",
                "logo": {
                    "@type": "ImageObject",
                    "url": "https://somaz.blog/assets/img/blog-image.png",
                    "width": "600",
                    "height": "315"
                }
            },
            "mainEntityOfPage": "True",
            "genre": "AI",
            "articleSection": "AI",
            "keywords": ["mlops","numpy","pandas","scikit-learn","machine-learning","python","data-science"]
        }
        </script>
    </body>
</html>
