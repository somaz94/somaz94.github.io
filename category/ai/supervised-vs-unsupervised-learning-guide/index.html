<!DOCTYPE html>
<html lang="en" class="no-js">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    

    
    

    
    

    
    

    <!-- ✅ Google Tag Manager 추가 -->
    <script>
        (function(w,d,s,l,i){
            w[l]=w[l]||[];
            w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});
            var f=d.getElementsByTagName(s)[0],
            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';
            j.async=true;
            j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;
            f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer','GTM-MBP83N4Q');
    </script>
      <!-- ✅ End Google Tag Manager -->

    <!-- Mermaid.js 직접 로드 -->
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true });
    </script>

    <title>Supervised vs Unsupervised Learning: Understanding ML Fundamentals with Fruit Classification | somaz</title>
    <meta name="description" content="Master the core concepts of supervised and unsupervised learning through intuitive fruit classification examples, practical Python implementations, and real-...">
    
        <meta name="keywords" content="machine-learning, supervised-learning, unsupervised-learning, classification, clustering, python, scikit-learn">
    

    <!-- Social: Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Supervised vs Unsupervised Learning: Understanding ML Fundamentals with Fruit Classification | somaz">
    <meta name="twitter:description" content="Master the core concepts of supervised and unsupervised learning through intuitive fruit classification examples, practical Python implementations, and real-...">

    
        <meta property="twitter:image" content="https://res.cloudinary.com/dkcm26aem/image/upload/v1750915895/supervised-vs-unsupervised_jktylx.png">
    
    
    
        <meta name="twitter:site" content="@twitter_username">
    

    <!-- Social: Facebook / Open Graph -->
    <meta property="og:url" content="https://somaz.blog/category/ai/supervised-vs-unsupervised-learning-guide/">
    <meta property="og:title" content="Supervised vs Unsupervised Learning: Understanding ML Fundamentals with Fruit Classification | somaz">
    <meta property="og:image" content="https://res.cloudinary.com/dkcm26aem/image/upload/v1750915895/supervised-vs-unsupervised_jktylx.png">
    <meta property="og:description" content="Master the core concepts of supervised and unsupervised learning through intuitive fruit classification examples, practical Python implementations, and real-...">
    <meta property="og:site_name" content="Somaz Tech Blog">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/assets/img/icons/apple-touch-icon.png" />
    <link rel="apple-touch-icon" sizes="57x57" href="/assets/img/icons/apple-touch-icon-57x57.png" />
    <link rel="apple-touch-icon" sizes="72x72" href="/assets/img/icons/apple-touch-icon-72x72.png" />
    <link rel="apple-touch-icon" sizes="114x114" href="/assets/img/icons/apple-touch-icon-114x114.png" />
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/img/icons/apple-touch-icon-144x144.png" />
    <link rel="apple-touch-icon" sizes="60x60" href="/assets/img/icons/apple-touch-icon-60x60.png" />
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/img/icons/apple-touch-icon-120x120.png" />
    <link rel="apple-touch-icon" sizes="76x76" href="/assets/img/icons/apple-touch-icon-76x76.png" />
    <link rel="apple-touch-icon" sizes="152x152" href="/assets/img/icons/apple-touch-icon-152x152.png" />

    <!-- Windows 8 Tile Icons -->
    <meta name="application-name" content="somaz">
    <meta name="msapplication-TileColor" content="#141414">
    <meta name="msapplication-square70x70logo" content="smalltile.png" />
    <meta name="msapplication-square150x150logo" content="mediumtile.png" />
    <meta name="msapplication-wide310x150logo" content="widetile.png" />
    <meta name="msapplication-square310x310logo" content="largetile.png" />
    
    <!-- Android Lolipop Theme Color -->
    <meta name="theme-color" content="#141414">

    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Titillium+Web:300,400,700" rel="stylesheet">

    <link rel="stylesheet" href="/assets/css/styles.css">
    <link rel="canonical" href="https://somaz.blog/category/ai/supervised-vs-unsupervised-learning-guide/">
    <link rel="alternate" type="application/rss+xml" title="Somaz Tech Blog" href="https://somaz.blog/feed.xml" />

    <!-- Include extra styles -->
    

    <!-- JavaScript enabled/disabled -->
    <script>
        document.querySelector('html').classList.remove('no-js');
    </script>

    <!-- Google Adsense -->
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8725590811736154"
        crossorigin="anonymous"></script>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <!-- <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet"> -->
    <!-- <link href="https://cdn.jsdelivr.net/gh/sunn-us/SUIT/fonts/variable/woff2/SUIT-Variable.css" rel="stylesheet"> -->
    <link href="https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@400;500;700&display=swap" rel="stylesheet">
    <!-- <link href="https://fonts.googleapis.com/css2?family=Albert+Sans:wght@400;500;700&display=swap" rel="stylesheet"> -->

    <link rel="sitemap" type="application/xml" title="Sitemap" href="/sitemap.xml" />

</head>
<!-- ✅ Google Tag Manager (noscript) -->
<noscript>
    <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MBP83N4Q"
            height="0" width="0" style="display:none;visibility:hidden">
    </iframe>
</noscript>
<!-- ✅ End Google Tag Manager (noscript) -->
    <body class="has-push-menu">
        





        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" display="none" version="1.1"><defs><symbol id="icon-menu" viewBox="0 0 1024 1024"><path class="path1" d="M128 213.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 725.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 469.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5z"/></symbol><symbol id="icon-search" viewBox="0 0 951 1024"><path class="path1" d="M658.286 475.429q0-105.714-75.143-180.857t-180.857-75.143-180.857 75.143-75.143 180.857 75.143 180.857 180.857 75.143 180.857-75.143 75.143-180.857zM950.857 950.857q0 29.714-21.714 51.429t-51.429 21.714q-30.857 0-51.429-21.714l-196-195.429q-102.286 70.857-228 70.857-81.714 0-156.286-31.714t-128.571-85.714-85.714-128.571-31.714-156.286 31.714-156.286 85.714-128.571 128.571-85.714 156.286-31.714 156.286 31.714 128.571 85.714 85.714 128.571 31.714 156.286q0 125.714-70.857 228l196 196q21.143 21.143 21.143 51.429z"/></symbol><symbol id="icon-close" viewBox="0 0 1000 1000"><path d="M969.8,870.3c27,27.7,27,71.8,0,99.1C955.7,983,937.9,990,920,990c-17.9,0-35.7-7-49.7-20.7L500,599L129.6,969.4C115.6,983,97.8,990,79.9,990s-35.7-7-49.7-20.7c-27-27.3-27-71.4,0-99.1L400.9,500L30.3,129.3c-27-27.3-27-71.4,0-99.1c27.3-27,71.8-27,99.4,0L500,400.9L870.4,30.2c27.7-27,71.8-27,99.4,0c27,27.7,27,71.8,0,99.1L599.1,500L969.8,870.3z"/></symbol><symbol id="icon-twitter" viewBox="0 0 951 1024"><path class="path1" d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"/></symbol><symbol id="icon-facebook" viewBox="0 0 585 1024"><path class="path1" d="M548 6.857v150.857h-89.714q-49.143 0-66.286 20.571t-17.143 61.714v108h167.429l-22.286 169.143h-145.143v433.714h-174.857v-433.714h-145.714v-169.143h145.714v-124.571q0-106.286 59.429-164.857t158.286-58.571q84 0 130.286 6.857z"/></symbol><symbol id="icon-clock" viewBox="0 0 1000 1000"><path d="M500,10C229.8,10,10,229.8,10,500c0,270.2,219.8,490,490,490c270.2,0,490-219.8,490-490C990,229.8,770.2,10,500,10z M500,910.2c-226.2,0-410.2-184-410.2-410.2c0-226.2,184-410.2,410.2-410.2c226.2,0,410.2,184,410.2,410.2C910.2,726.1,726.2,910.2,500,910.2z M753.1,374c8.2,11.9,5.2,28.1-6.6,36.3L509.9,573.7c-4.4,3.1-9.6,4.6-14.8,4.6c-4.1,0-8.3-1-12.1-3c-8.6-4.5-14-13.4-14-23.1V202.5c0-14.4,11.7-26.1,26.1-26.1c14.4,0,26.1,11.7,26.1,26.1v300l195.6-135.1C728.7,359.2,744.9,362.1,753.1,374z"/></symbol><symbol id="icon-calendar" viewBox="0 0 1000 1000"><path d="M920,500v420H80V500H920 M990,430H10v490c0,38.7,31.3,70,70,70h840c38.7,0,70-31.3,70-70V430L990,430z"/><path d="M850,80v105c0,57.9-47.2,105-105,105c-58,0-105-47.1-105-105V80H360v105c0,57.9-47.2,105-105,105c-58,0-105-47.1-105-105V80C72.8,80,10,142.7,10,220v140h980V220C990,142.7,927.2,80,850,80z"/><path d="M255,10c-19.3,0-35,15.8-35,35v140c0,19.2,15.7,35,35,35c19.3,0,35-15.8,35-35V45C290,25.8,274.3,10,255,10z"/><path d="M745,10c-19.3,0-35,15.8-35,35v140c0,19.2,15.7,35,35,35c19.3,0,35-15.8,35-35V45C780,25.8,764.3,10,745,10z"/></symbol><symbol id="icon-github" viewBox="0 0 12 14"><path d="M6 1q1.633 0 3.012 0.805t2.184 2.184 0.805 3.012q0 1.961-1.145 3.527t-2.957 2.168q-0.211 0.039-0.312-0.055t-0.102-0.234q0-0.023 0.004-0.598t0.004-1.051q0-0.758-0.406-1.109 0.445-0.047 0.801-0.141t0.734-0.305 0.633-0.52 0.414-0.82 0.16-1.176q0-0.93-0.617-1.609 0.289-0.711-0.062-1.594-0.219-0.070-0.633 0.086t-0.719 0.344l-0.297 0.187q-0.727-0.203-1.5-0.203t-1.5 0.203q-0.125-0.086-0.332-0.211t-0.652-0.301-0.664-0.105q-0.352 0.883-0.062 1.594-0.617 0.68-0.617 1.609 0 0.664 0.16 1.172t0.41 0.82 0.629 0.523 0.734 0.305 0.801 0.141q-0.305 0.281-0.383 0.805-0.164 0.078-0.352 0.117t-0.445 0.039-0.512-0.168-0.434-0.488q-0.148-0.25-0.379-0.406t-0.387-0.187l-0.156-0.023q-0.164 0-0.227 0.035t-0.039 0.090 0.070 0.109 0.102 0.094l0.055 0.039q0.172 0.078 0.34 0.297t0.246 0.398l0.078 0.18q0.102 0.297 0.344 0.48t0.523 0.234 0.543 0.055 0.434-0.027l0.18-0.031q0 0.297 0.004 0.691t0.004 0.426q0 0.141-0.102 0.234t-0.312 0.055q-1.812-0.602-2.957-2.168t-1.145-3.527q0-1.633 0.805-3.012t2.184-2.184 3.012-0.805zM2.273 9.617q0.023-0.055-0.055-0.094-0.078-0.023-0.102 0.016-0.023 0.055 0.055 0.094 0.070 0.047 0.102-0.016zM2.516 9.883q0.055-0.039-0.016-0.125-0.078-0.070-0.125-0.023-0.055 0.039 0.016 0.125 0.078 0.078 0.125 0.023zM2.75 10.234q0.070-0.055 0-0.148-0.062-0.102-0.133-0.047-0.070 0.039 0 0.141t0.133 0.055zM3.078 10.562q0.062-0.062-0.031-0.148-0.094-0.094-0.156-0.023-0.070 0.062 0.031 0.148 0.094 0.094 0.156 0.023zM3.523 10.758q0.023-0.086-0.102-0.125-0.117-0.031-0.148 0.055t0.102 0.117q0.117 0.047 0.148-0.047zM4.016 10.797q0-0.102-0.133-0.086-0.125 0-0.125 0.086 0 0.102 0.133 0.086 0.125 0 0.125-0.086zM4.469 10.719q-0.016-0.086-0.141-0.070-0.125 0.023-0.109 0.117t0.141 0.062 0.109-0.109z"></path></symbol><symbol id="icon-medium" viewBox="0 0 1000 1000"><path d="M336.5,240.2v641.5c0,9.1-2.3,16.9-6.8,23.2s-11.2,9.6-20,9.6c-6.2,0-12.2-1.5-18-4.4L37.3,782.7c-7.7-3.6-14.1-9.8-19.4-18.3S10,747.4,10,739V115.5c0-7.3,1.8-13.5,5.5-18.6c3.6-5.1,8.9-7.7,15.9-7.7c5.1,0,13.1,2.7,24.1,8.2l279.5,140C335.9,238.6,336.5,239.5,336.5,240.2L336.5,240.2z M371.5,295.5l292,473.6l-292-145.5V295.5z M990,305.3v576.4c0,9.1-2.6,16.5-7.7,22.1c-5.1,5.7-12,8.5-20.8,8.5s-17.3-2.4-25.7-7.1L694.7,784.9L990,305.3z M988.4,239.7c0,1.1-46.8,77.6-140.3,229.4C754.6,621,699.8,709.8,683.8,735.7L470.5,389l177.2-288.2c6.2-10.2,15.7-15.3,28.4-15.3c5.1,0,9.8,1.1,14.2,3.3l295.9,147.7C987.6,237.1,988.4,238.2,988.4,239.7L988.4,239.7z"/></symbol><symbol id="icon-instagram" viewBox="0 0 489.84 489.84"><path d="M249.62,50.46c65.4,0,73.14.25,99,1.43C372.47,53,385.44,57,394.07,60.32a75.88,75.88,0,0,1,28.16,18.32,75.88,75.88,0,0,1,18.32,28.16c3.35,8.63,7.34,21.6,8.43,45.48,1.18,25.83,1.43,33.57,1.43,99s-0.25,73.14-1.43,99c-1.09,23.88-5.08,36.85-8.43,45.48a81.11,81.11,0,0,1-46.48,46.48c-8.63,3.35-21.6,7.34-45.48,8.43-25.82,1.18-33.57,1.43-99,1.43s-73.15-.25-99-1.43c-23.88-1.09-36.85-5.08-45.48-8.43A75.88,75.88,0,0,1,77,423.86,75.88,75.88,0,0,1,58.69,395.7c-3.35-8.63-7.34-21.6-8.43-45.48-1.18-25.83-1.43-33.57-1.43-99s0.25-73.14,1.43-99c1.09-23.88,5.08-36.85,8.43-45.48A75.88,75.88,0,0,1,77,78.64a75.88,75.88,0,0,1,28.16-18.32c8.63-3.35,21.6-7.34,45.48-8.43,25.83-1.18,33.57-1.43,99-1.43m0-44.13c-66.52,0-74.86.28-101,1.47s-43.87,5.33-59.45,11.38A120.06,120.06,0,0,0,45.81,47.44,120.06,120.06,0,0,0,17.56,90.82C11.5,106.4,7.36,124.2,6.17,150.27s-1.47,34.46-1.47,101,0.28,74.86,1.47,101,5.33,43.87,11.38,59.45a120.06,120.06,0,0,0,28.25,43.38,120.06,120.06,0,0,0,43.38,28.25c15.58,6.05,33.38,10.19,59.45,11.38s34.46,1.47,101,1.47,74.86-.28,101-1.47,43.87-5.33,59.45-11.38a125.24,125.24,0,0,0,71.63-71.63c6.05-15.58,10.19-33.38,11.38-59.45s1.47-34.46,1.47-101-0.28-74.86-1.47-101-5.33-43.87-11.38-59.45a120.06,120.06,0,0,0-28.25-43.38,120.06,120.06,0,0,0-43.38-28.25C394.47,13.13,376.67,9,350.6,7.8s-34.46-1.47-101-1.47h0Z" transform="translate(-4.7 -6.33)" /><path d="M249.62,125.48A125.77,125.77,0,1,0,375.39,251.25,125.77,125.77,0,0,0,249.62,125.48Zm0,207.41a81.64,81.64,0,1,1,81.64-81.64A81.64,81.64,0,0,1,249.62,332.89Z" transform="translate(-4.7 -6.33)"/><circle cx="375.66" cy="114.18" r="29.39" /></symbol><symbol id="icon-linkedin" viewBox="0 0 12 14"><path d="M2.727 4.883v7.742h-2.578v-7.742h2.578zM2.891 2.492q0.008 0.57-0.395 0.953t-1.059 0.383h-0.016q-0.641 0-1.031-0.383t-0.391-0.953q0-0.578 0.402-0.957t1.051-0.379 1.039 0.379 0.398 0.957zM12 8.187v4.437h-2.57v-4.141q0-0.82-0.316-1.285t-0.988-0.465q-0.492 0-0.824 0.27t-0.496 0.668q-0.086 0.234-0.086 0.633v4.32h-2.57q0.016-3.117 0.016-5.055t-0.008-2.313l-0.008-0.375h2.57v1.125h-0.016q0.156-0.25 0.32-0.438t0.441-0.406 0.68-0.34 0.895-0.121q1.336 0 2.148 0.887t0.813 2.598z"></path></symbol><symbol id="icon-heart" viewBox="0 0 34 30"><path d="M17,29.7 L16.4,29.2 C3.5,18.7 0,15 0,9 C0,4 4,0 9,0 C13.1,0 15.4,2.3 17,4.1 C18.6,2.3 20.9,0 25,0 C30,0 34,4 34,9 C34,15 30.5,18.7 17.6,29.2 L17,29.7 Z M9,2 C5.1,2 2,5.1 2,9 C2,14.1 5.2,17.5 17,27.1 C28.8,17.5 32,14.1 32,9 C32,5.1 28.9,2 25,2 C21.5,2 19.6,4.1 18.1,5.8 L17,7.1 L15.9,5.8 C14.4,4.1 12.5,2 9,2 Z" id="Shape"></path></symbol><symbol id="icon-arrow-right" viewBox="0 0 25.452 25.452"><path d="M4.471,24.929v-2.004l12.409-9.788c0.122-0.101,0.195-0.251,0.195-0.411c0-0.156-0.073-0.31-0.195-0.409L4.471,2.526V0.522c0-0.2,0.115-0.384,0.293-0.469c0.18-0.087,0.396-0.066,0.552,0.061l15.47,12.202c0.123,0.1,0.195,0.253,0.195,0.409c0,0.16-0.072,0.311-0.195,0.411L5.316,25.34c-0.155,0.125-0.372,0.147-0.552,0.061C4.586,25.315,4.471,25.13,4.471,24.929z"/></symbol><symbol id="icon-star" viewBox="0 0 48 48"><path fill="currentColor" d="M44,24c0,11.045-8.955,20-20,20S4,35.045,4,24S12.955,4,24,4S44,12.955,44,24z"/><path fill="#ffffff" d="M24,11l3.898,7.898l8.703,1.301l-6.301,6.102l1.5,8.699L24,30.898L16.199,35l1.5-8.699l-6.301-6.102  l8.703-1.301L24,11z"/></symbol><symbol id="icon-read" viewBox="0 0 32 32"><path fill="currentColor" d="M29,4H3C1.343,4,0,5.343,0,7v18c0,1.657,1.343,3,3,3h10c0,0.552,0.448,1,1,1h4c0.552,0,1-0.448,1-1h10  c1.657,0,3-1.343,3-3V7C32,5.343,30.657,4,29,4z M29,5v20H18.708c-0.618,0-1.236,0.146-1.789,0.422l-0.419,0.21V5H29z M15.5,5  v20.632l-0.419-0.21C14.528,25.146,13.91,25,13.292,25H3V5H15.5z M31,25c0,1.103-0.897,2-2,2H18v1h-4v-1H3c-1.103,0-2-0.897-2-2V7  c0-0.737,0.405-1.375,1-1.722V25c0,0.552,0.448,1,1,1h10.292c0.466,0,0.925,0.108,1.342,0.317l0.919,0.46  c0.141,0.07,0.294,0.106,0.447,0.106c0.153,0,0.306-0.035,0.447-0.106l0.919-0.46C17.783,26.108,18.242,26,18.708,26H29  c0.552,0,1-0.448,1-1V5.278C30.595,5.625,31,6.263,31,7V25z M6,12.5C6,12.224,6.224,12,6.5,12h5c0.276,0,0.5,0.224,0.5,0.5  S11.776,13,11.5,13h-5C6.224,13,6,12.776,6,12.5z M6,14.5C6,14.224,6.224,14,6.5,14h5c0.276,0,0.5,0.224,0.5,0.5S11.776,15,11.5,15  h-5C6.224,15,6,14.776,6,14.5z M6,16.5C6,16.224,6.224,16,6.5,16h5c0.276,0,0.5,0.224,0.5,0.5S11.776,17,11.5,17h-5  C6.224,17,6,16.776,6,16.5z M20,12.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,13,25.5,13h-5  C20.224,13,20,12.776,20,12.5z M20,14.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,15,25.5,15h-5  C20.224,15,20,14.776,20,14.5z M20,16.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,17,25.5,17h-5  C20.224,17,20,16.776,20,16.5z"></path></symbol><symbol id="icon-tistory" viewBox="0 0 24 24"><path d="M4 4h16v3h-6v13h-4V7H4V4z"/></symbol></defs></svg>

        <header class="bar-header">
    <a id="menu" role="button">
        <svg id="open" class="icon-menu"><use xlink:href="#icon-menu"></use></svg>
    </a>
    <h1 class="logo">
        <a href="/">
            
                somaz <span class="version">v3.1.2</span>
            
        </a>
    </h1>
    <a id="search" class="dosearch" role="button">
        <svg class="icon-search"><use xlink:href="#icon-search"></use></svg>
    </a>
    
        <a href="https://github.com/thiagorossener/jekflix-template" class="get-theme" role="button">
            Get this theme!
        </a>
    
</header>

<div id="mask" class="overlay"></div>

<aside class="sidebar" id="sidebar">
    <nav id="navigation">
      <h2>Menu</h2>
      <ul>
  
    
      <li>
        <a href="https://somaz.blog/">Home</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/about">About</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/category">Category</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/contact">Contact</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/feed.xml">Feed</a>
      </li>
    
  
</ul>

    </nav>
</aside>

<div class="search-wrapper">
    <div class="search-form">
        <input type="text" class="search-field" placeholder="Search">
        <svg class="icon-remove-sign"><use xlink:href="#icon-close"></use></svg>
        <ul class="search-results search-list"></ul>
    </div>
</div>



        <section class="post two-columns">
            <article role="article" class="post-content">
                <p class="post-info">
                    
                        <svg class="icon-calendar" id="date"><use xlink:href="#icon-calendar"></use></svg>
                        <time class="date" datetime="2025-10-09T00:00:00+00:00">
                            


October 9, 2025

                        </time>
                    
                    <svg id="clock" class="icon-clock"><use xlink:href="#icon-clock"></use></svg>
                    <span>23 min to read</span>
                </p>
                <h1 class="post-title">Supervised vs Unsupervised Learning: Understanding ML Fundamentals with Fruit Classification</h1>
                <p class="post-subtitle">From fruit sorting to advanced algorithms - A complete guide to machine learning paradigms</p>

                
                    <img src="https://res.cloudinary.com/dkcm26aem/image/upload/v1750915895/supervised-vs-unsupervised_jktylx.png" alt="Featured image" class="post-cover">
                

                <!-- Pagination links -->



                <!-- Add your table of contents here -->


                <p><br /></p>

<h2 id="table-of-contents">Table of Contents</h2>

<ol>
  <li><a href="#overview">Overview</a></li>
  <li><a href="#supervised-vs-unsupervised-learning">Supervised vs Unsupervised Learning</a></li>
  <li><a href="#similarity-vs-compatibility">Similarity vs Compatibility</a></li>
  <li><a href="#hands-on-python-examples">Hands-on Python Examples</a></li>
  <li><a href="#advanced-case-studies">Advanced Case Studies</a></li>
  <li><a href="#why-both-approaches-matter">Why Both Approaches Matter</a></li>
  <li><a href="#uci-machine-learning-repository">UCI Machine Learning Repository</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
  <li><a href="#references">References</a></li>
</ol>

<hr />

<h2 id="overview">Overview</h2>

<p>When starting with machine learning, one of the most common questions is: “What’s the difference between supervised and unsupervised learning?” This comprehensive guide uses intuitive fruit classification examples and real Python implementations to explain the core concepts that form the foundation of modern AI systems.</p>

<blockquote>
  <p>Through practical examples involving fruit classification and the famous Iris dataset, we’ll explore:</p>
</blockquote>

<ul>
  <li><strong>Supervised Learning</strong>: Classification and prediction with labeled data</li>
  <li><strong>Unsupervised Learning</strong>: Pattern discovery without ground truth labels</li>
  <li><strong>Similarity</strong>: Measuring how alike two data points are</li>
  <li><strong>Compatibility</strong>: Evaluating how well items work together</li>
</ul>

<p>You’ll gain hands-on experience with algorithms like DecisionTree, SVM, KNN, LogisticRegression for classification, and KMeans clustering with similarity analysis using real Python code.</p>

<hr />

<h2 id="supervised-vs-unsupervised-learning">Supervised vs Unsupervised Learning</h2>

<p><br /></p>

<h3 id="supervised-learning---learning-with-answers">Supervised Learning - “Learning with Answers”</h3>

<h4 id="definition">Definition</h4>
<p>“This fruit is an apple” → Learning from data where the correct answers (labels) are provided</p>

<div class="table-container">
  <table class="table-beauty">
    <tr>
      <th style="width: 25%;">Characteristic</th>
      <th style="width: 75%;">Description</th>
    </tr>
    <tr>
      <td><strong>Input</strong></td>
      <td>Fruit features: color, size, sweetness, etc.</td>
    </tr>
    <tr>
      <td><strong>Output</strong></td>
      <td>Labels (e.g., apple, banana, grape)</td>
    </tr>
    <tr>
      <td><strong>Goal</strong></td>
      <td>Learn to predict correct labels for new input data</td>
    </tr>
    <tr>
      <td><strong>Example</strong></td>
      <td>Fruit image → Apple/Banana/Grape prediction</td>
    </tr>
  </table>
</div>

<h4 id="example">Example:</h4>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input: [color=red, size=small, sweetness=high]  
Output: Apple (label)
</code></pre></div></div>

<p><br /></p>

<h3 id="unsupervised-learning---finding-patterns-without-answers">Unsupervised Learning - “Finding Patterns Without Answers”</h3>

<h4 id="definition-1">Definition</h4>
<p>“These fruits look similar, they might belong to the same group!” → Discovering data structure without ground truth labels</p>

<div class="table-container">
  <table class="table-beauty">
    <tr>
      <th style="width: 25%;">Characteristic</th>
      <th style="width: 75%;">Description</th>
    </tr>
    <tr>
      <td><strong>Input</strong></td>
      <td>Fruit features: color, size, sweetness, etc.</td>
    </tr>
    <tr>
      <td><strong>Output</strong></td>
      <td>None (clusters/groups without predefined labels)</td>
    </tr>
    <tr>
      <td><strong>Goal</strong></td>
      <td>Group similar data points or extract meaningful features</td>
    </tr>
    <tr>
      <td><strong>Example</strong></td>
      <td>Automatically cluster fruits by color/size similarity</td>
    </tr>
  </table>
</div>

<h4 id="example-1">Example:</h4>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input: Various fruit feature data  
Output: Cluster 1 = Apple-like group, Cluster 2 = Banana-like group
</code></pre></div></div>

<p><br /></p>

<hr />

<h2 id="similarity-vs-compatibility">Similarity vs Compatibility</h2>

<p>While similarity and compatibility may seem related, they serve different purposes in machine learning applications.</p>

<p><br /></p>

<h3 id="similarity">Similarity</h3>

<h4 id="core-question">Core Question</h4>
<p>“How alike are these two objects?” → Measuring distance or resemblance between data points</p>

<div class="table-container">
  <table class="table-beauty">
    <tr>
      <th style="width: 25%;">Characteristic</th>
      <th style="width: 75%;">Description</th>
    </tr>
    <tr>
      <td><strong>Core Question</strong></td>
      <td>How similar are they?</td>
    </tr>
    <tr>
      <td><strong>Mathematical Expression</strong></td>
      <td>Cosine Similarity, Euclidean Distance, etc.</td>
    </tr>
    <tr>
      <td><strong>Use Cases</strong></td>
      <td>Recommendation systems, clustering, image search</td>
    </tr>
  </table>
</div>

<h4 id="example-2">Example:</h4>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Apple vs Pear color/sweetness/size difference → Distance calculation
Distance 0 = Nearly identical fruits
</code></pre></div></div>

<h3 id="compatibility">Compatibility</h3>

<h4 id="core-question-1">Core Question</h4>
<p>“How well do these items work together?” → Evaluating the quality of combinations</p>

<div class="table-container">
  <table class="table-beauty">
    <tr>
      <th style="width: 25%;">Characteristic</th>
      <th style="width: 75%;">Description</th>
    </tr>
    <tr>
      <td><strong>Core Question</strong></td>
      <td>How well do they work together?</td>
    </tr>
    <tr>
      <td><strong>Mathematical Expression</strong></td>
      <td>Score-based (interaction models, co-occurrence)</td>
    </tr>
    <tr>
      <td><strong>Use Cases</strong></td>
      <td>Matching systems, product recommendations, recipe pairing</td>
    </tr>
  </table>
</div>

<h4 id="example-3">Example:</h4>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Apple + Honey combination score = 9.1
Apple + Soy sauce combination score = 2.3
</code></pre></div></div>

<p><br /></p>

<h3 id="summary-ml-concepts-with-fruit-examples">Summary: ML Concepts with Fruit Examples</h3>

<div class="table-container">
  <table class="table-beauty">
    <tr>
      <th style="width: 20%;">Concept</th>
      <th style="width: 40%;">Description</th>
      <th style="width: 40%;">Example</th>
    </tr>
    <tr>
      <td><strong>Supervised Learning</strong></td>
      <td>Learning from labeled examples</td>
      <td>Fruit photo → Apple prediction</td>
    </tr>
    <tr>
      <td><strong>Unsupervised Learning</strong></td>
      <td>Finding groups without labels</td>
      <td>Grouping similar fruits together</td>
    </tr>
    <tr>
      <td><strong>Similarity</strong></td>
      <td>How alike are they?</td>
      <td>Apple vs Pear comparison</td>
    </tr>
    <tr>
      <td><strong>Compatibility</strong></td>
      <td>How well do they work together?</td>
      <td>Apple + Honey pairing</td>
    </tr>
  </table>
</div>

<hr />

<h2 id="hands-on-python-examples">Hands-on Python Examples</h2>

<p>Now let’s implement supervised and unsupervised learning with actual Python code. Follow along with the practical examples below.</p>

<blockquote>
  <h3 id="-complete-code-repository">🚀 <strong>Complete Code Repository</strong></h3>

  <p><strong><a href="https://github.com/somaz94/ml-basics">� ML Basics - Supervised vs Unsupervised Learning</a></strong></p>

  <p><em>Complete guide from machine learning fundamentals to hands-on practice</em></p>

  <p><strong>What’s included:</strong></p>
  <ul>
    <li>📓 Interactive Jupyter Notebooks</li>
    <li>📊 Real-world Sample Datasets</li>
    <li>🐍 Well-documented Python Examples</li>
    <li>📚 Step-by-step Implementation Guide</li>
    <li>🔬 Comparison Analysis &amp; Visualizations</li>
  </ul>
</blockquote>

<p><br /></p>

<h3 id="-prerequisites">� Prerequisites</h3>

<p>Before diving into the examples, make sure you have the following setup ready:</p>

<p><br /></p>

<h3 id="setup-virtual-environment-and-dependencies">Setup: Virtual Environment and Dependencies</h3>

<h4 id="recommended-setup">Recommended Setup</h4>
<p>Create a virtual environment to avoid package conflicts and ensure reproducible results.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Create and activate virtual environment</span>
python3 <span class="nt">-m</span> venv ml_env
<span class="nb">source </span>ml_env/bin/activate  <span class="c"># Windows: ml_env\Scripts\activate</span>

<span class="c"># Install required packages</span>
pip3 <span class="nb">install </span>scikit-learn numpy matplotlib pandas
</code></pre></div></div>

<h3 id="example-1-fruit-classification-with-scikit-learn">Example 1: Fruit Classification with Scikit-Learn</h3>

<p>This example demonstrates both supervised and unsupervised learning approaches using synthetic fruit data with features like color, size, and sweetness.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># supervised_vs_unsupervised.py
</span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Configure font for better visualization
</span><span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'font.family'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'DejaVu Sans'</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'axes.unicode_minus'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>

<span class="c1"># -----------------------
# Supervised Learning: Fruit Classification
# -----------------------
</span><span class="k">print</span><span class="p">(</span><span class="s">"📘 Supervised Learning - Decision Tree Fruit Prediction"</span><span class="p">)</span>

<span class="c1"># Fruit features: [color, size, sweetness]
</span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>  <span class="c1"># 0:apple, 1:banana, 2:grape
</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Predict new fruit
</span><span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Prediction result (label):"</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Feature importance:"</span><span class="p">,</span> <span class="n">clf</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">)</span>

<span class="c1"># -----------------------
# Unsupervised Learning: Fruit Clustering
# -----------------------
</span><span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">📘 Unsupervised Learning - KMeans Clustering"</span><span class="p">)</span>

<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Cluster results:"</span><span class="p">,</span> <span class="n">clusters</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Cluster centers:"</span><span class="p">,</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">cluster_centers_</span><span class="p">)</span>

<span class="c1"># Visualization
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">],</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'viridis'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Color"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Sweetness"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"True Labels"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">],</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">clusters</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'viridis'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Color"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Sweetness"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"KMeans Clusters"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># -----------------------
# Similarity Analysis (Cosine)
# -----------------------
</span><span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">📘 Similarity - Cosine Similarity Analysis"</span><span class="p">)</span>

<span class="n">apple</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="n">pear</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="n">banana</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>

<span class="n">sim_apple_pear</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">apple</span><span class="p">,</span> <span class="n">pear</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">sim_apple_banana</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">apple</span><span class="p">,</span> <span class="n">banana</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Apple-Pear similarity: </span><span class="si">{</span><span class="n">sim_apple_pear</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Apple-Banana similarity: </span><span class="si">{</span><span class="n">sim_apple_banana</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Calculate all pairwise similarities
</span><span class="n">fruits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="n">fruit_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Apple'</span><span class="p">,</span> <span class="s">'Pear'</span><span class="p">,</span> <span class="s">'Banana'</span><span class="p">]</span>
<span class="n">similarity_matrix</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">fruits</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Similarity Matrix:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name1</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fruit_names</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">name2</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">fruit_names</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">name1</span><span class="si">}</span><span class="s">-</span><span class="si">{</span><span class="n">name2</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">similarity_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Expected Output:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>📘 Supervised Learning - Decision Tree Fruit Prediction
Prediction result (label): [0]
Feature importance: [0.2 0.3 0.5]

📘 Unsupervised Learning - KMeans Clustering
Cluster results: [0 0 1 1 2]
Cluster centers: [[1.5 1.5 9.5]
                  [2.5 4.  3.5]
                  [4.  1.  8. ]]

📘 Similarity - Cosine Similarity Analysis
Apple-Pear similarity: 0.9942
Apple-Banana similarity: 0.6400
</code></pre></div></div>

<p><img src="https://res.cloudinary.com/dkcm26aem/image/upload/v1750916446/supervised-vs-unsupervised-1_nvjeit.png" alt="fruit" /></p>

<p><br /></p>

<h3 id="example-2-iris-dataset-classification-and-clustering">Example 2: Iris Dataset Classification and Clustering</h3>

<p>The Iris dataset is a classic benchmark in machine learning, perfect for comparing supervised and unsupervised approaches on real data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># iris_classification.py
</span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Load Iris dataset
</span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="p">.</span><span class="n">target</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">feature_names</span>
<span class="n">target_names</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">target_names</span>

<span class="k">print</span><span class="p">(</span><span class="s">"📊 Iris Dataset Overview"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Dataset shape: </span><span class="si">{</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Features: </span><span class="si">{</span><span class="n">feature_names</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Classes: </span><span class="si">{</span><span class="n">target_names</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Class distribution: </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Split data for supervised learning
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="c1"># -----------------------
# Supervised Learning: Multiple Algorithms
# -----------------------
</span><span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">📘 Supervised Learning - Multiple Classification Algorithms"</span><span class="p">)</span>

<span class="n">algorithms</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'SVM'</span><span class="p">:</span> <span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
    <span class="s">'KNN'</span><span class="p">:</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
    <span class="s">'LogisticRegression'</span><span class="p">:</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">algorithms</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">accuracy</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s"> accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># -----------------------
# Unsupervised Learning: KMeans Clustering
# -----------------------
</span><span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">📘 Unsupervised Learning - KMeans Clustering Analysis"</span><span class="p">)</span>

<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"KMeans cluster results:"</span><span class="p">,</span> <span class="n">cluster_labels</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"True species labels:"</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Compare clustering with true labels
</span><span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">cluster_labels</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Cluster-Truth confusion matrix:"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">)</span>

<span class="c1"># Calculate cluster purity
</span><span class="k">def</span> <span class="nf">calculate_purity</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="s">"""Calculate clustering purity score"""</span>
    <span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">amax</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">)</span>

<span class="n">purity</span> <span class="o">=</span> <span class="n">calculate_purity</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">cluster_labels</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Clustering purity: </span><span class="si">{</span><span class="n">purity</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Analyze cluster characteristics
</span><span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Cluster Analysis:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">cluster_mask</span> <span class="o">=</span> <span class="n">cluster_labels</span> <span class="o">==</span> <span class="n">i</span>
    <span class="n">cluster_data</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">cluster_mask</span><span class="p">]</span>
    <span class="n">true_labels</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">cluster_mask</span><span class="p">]</span>
    
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n</span><span class="s">Cluster </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">:"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Size: </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">cluster_mask</span><span class="p">)</span><span class="si">}</span><span class="s"> samples"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Dominant species: </span><span class="si">{</span><span class="n">target_names</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">true_labels</span><span class="p">).</span><span class="n">argmax</span><span class="p">()]</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"  Average features: </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cluster_data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># -----------------------
# Feature Analysis
# -----------------------
</span><span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">📊 Feature Importance Analysis"</span><span class="p">)</span>

<span class="c1"># Use trained LogisticRegression for feature importance
</span><span class="n">lr_model</span> <span class="o">=</span> <span class="n">algorithms</span><span class="p">[</span><span class="s">'LogisticRegression'</span><span class="p">]</span>
<span class="n">feature_importance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">lr_model</span><span class="p">.</span><span class="n">coef_</span><span class="p">).</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Feature importance ranking:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">importance</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">feature_importance</span><span class="p">)):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">. </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">importance</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Expected Output:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>📊 Iris Dataset Overview
Dataset shape: (150, 4)
Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']
Classes: ['setosa' 'versicolor' 'virginica']
Class distribution: [50 50 50]

📘 Supervised Learning - Multiple Classification Algorithms
SVM accuracy: 1.000
KNN accuracy: 1.000
LogisticRegression accuracy: 1.000

📘 Unsupervised Learning - KMeans Clustering Analysis
KMeans cluster results: [1 1 1 ... 0 2 0]
True species labels: [0 0 0 ... 2 2 2]
Cluster-Truth confusion matrix:
[[ 0 50  0]
 [ 3  0 47]
 [36  0 14]]
Clustering purity: 0.747
</code></pre></div></div>

<p><img src="https://res.cloudinary.com/dkcm26aem/image/upload/v1750916685/supervised-vs-unsupervised-2_vurhma.png" alt="iris-1" /></p>

<p><br /></p>

<p><img src="https://res.cloudinary.com/dkcm26aem/image/upload/v1750916686/supervised-vs-unsupervised-3_uhceiw.png" alt="iris-2" /></p>

<p><br /></p>

<h3 id="example-3-wine-quality-analysis">Example 3: Wine Quality Analysis</h3>

<p>This example demonstrates both classification and regression tasks using real-world wine quality data, showing how the same dataset can be approached differently.</p>

<p><br /></p>

<p><img src="https://res.cloudinary.com/dkcm26aem/image/upload/v1750917074/supervised-vs-unsupervised-4_t34yo1.png" alt="wine" /></p>

<p><br /></p>

<hr />

<h2 id="advanced-case-studies">Advanced Case Studies</h2>

<p><br /></p>

<h3 id="case-study-1-e-commerce-recommendation-system">Case Study 1: E-commerce Recommendation System</h3>

<p>Real-world application combining both supervised and unsupervised learning for product recommendations.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ecommerce_recommendation.py
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="k">class</span> <span class="nc">EcommerceRecommendationSystem</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">user_clusters</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">product_features</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">purchase_predictor</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">analyze_user_behavior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user_data</span><span class="p">):</span>
        <span class="s">"""Unsupervised: Cluster users by behavior patterns"""</span>
        <span class="c1"># user_data: [browsing_time, purchase_frequency, avg_order_value, ...]
</span>        
        <span class="n">scaled_data</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">user_data</span><span class="p">)</span>
        
        <span class="c1"># Find optimal number of clusters
</span>        <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">user_clusters</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">scaled_data</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">user_clusters</span> <span class="o">=</span> <span class="n">kmeans</span>
        <span class="k">return</span> <span class="n">user_clusters</span>
    
    <span class="k">def</span> <span class="nf">train_purchase_predictor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user_features</span><span class="p">,</span> <span class="n">purchase_history</span><span class="p">):</span>
        <span class="s">"""Supervised: Predict purchase likelihood"""</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">purchase_predictor</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span>
            <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">purchase_predictor</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">user_features</span><span class="p">,</span> <span class="n">purchase_history</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">purchase_predictor</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">user_features</span><span class="p">,</span> <span class="n">purchase_history</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">calculate_product_similarity</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">product_features</span><span class="p">):</span>
        <span class="s">"""Calculate product similarity matrix"""</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">product_features</span> <span class="o">=</span> <span class="n">product_features</span>
        <span class="n">similarity_matrix</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">product_features</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">similarity_matrix</span>
    
    <span class="k">def</span> <span class="nf">recommend_products</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">user_id</span><span class="p">,</span> <span class="n">user_features</span><span class="p">,</span> <span class="n">n_recommendations</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="s">"""Hybrid recommendation using both approaches"""</span>
        
        <span class="c1"># 1. Predict purchase probability (supervised)
</span>        <span class="n">purchase_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">purchase_predictor</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">([</span><span class="n">user_features</span><span class="p">])[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># 2. Find user cluster (unsupervised)
</span>        <span class="n">user_cluster</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">user_clusters</span><span class="p">.</span><span class="n">predict</span><span class="p">([</span><span class="n">user_features</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># 3. Use similarity for product recommendations
</span>        <span class="c1"># (In practice, this would use actual user-product interactions)
</span>        <span class="n">recommendations</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">'user_id'</span><span class="p">:</span> <span class="n">user_id</span><span class="p">,</span>
            <span class="s">'purchase_probability'</span><span class="p">:</span> <span class="n">purchase_prob</span><span class="p">,</span>
            <span class="s">'user_cluster'</span><span class="p">:</span> <span class="n">user_cluster</span><span class="p">,</span>
            <span class="s">'recommended_products'</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_recommendations</span><span class="p">))</span>  <span class="c1"># Simplified
</span>        <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">recommendations</span>

<span class="c1"># Example usage
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Generate synthetic user data
</span><span class="n">n_users</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">user_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_users</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># 5 behavioral features
</span><span class="n">purchase_history</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">n_users</span><span class="p">)</span>  <span class="c1"># 30% purchase rate
</span>
<span class="c1"># Initialize and train system
</span><span class="n">rec_system</span> <span class="o">=</span> <span class="n">EcommerceRecommendationSystem</span><span class="p">()</span>

<span class="c1"># Unsupervised analysis
</span><span class="n">user_clusters</span> <span class="o">=</span> <span class="n">rec_system</span><span class="p">.</span><span class="n">analyze_user_behavior</span><span class="p">(</span><span class="n">user_data</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Identified </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">user_clusters</span><span class="p">))</span><span class="si">}</span><span class="s"> user clusters"</span><span class="p">)</span>

<span class="c1"># Supervised training
</span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">rec_system</span><span class="p">.</span><span class="n">train_purchase_predictor</span><span class="p">(</span><span class="n">user_data</span><span class="p">,</span> <span class="n">purchase_history</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Purchase prediction accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Generate recommendations for a new user
</span><span class="n">new_user_features</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]</span>
<span class="n">recommendations</span> <span class="o">=</span> <span class="n">rec_system</span><span class="p">.</span><span class="n">recommend_products</span><span class="p">(</span>
    <span class="n">user_id</span><span class="o">=</span><span class="mi">1001</span><span class="p">,</span> 
    <span class="n">user_features</span><span class="o">=</span><span class="n">new_user_features</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Recommendation Results:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">recommendations</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="why-both-approaches-matter">Why Both Approaches Matter</h2>

<p><br /></p>

<h3 id="when-supervised-learning-is-essential">When Supervised Learning is Essential</h3>

<h4 id="high-stakes-prediction-tasks">High-Stakes Prediction Tasks</h4>
<p>When accurate prediction is critical and labeled data is available.</p>

<ol>
  <li><strong>Medical Diagnosis</strong>
    <ul>
      <li>Input: Patient symptoms, test results</li>
      <li>Ground Truth: Actual diagnosis (cancer/normal)</li>
      <li>Goal: Accurately predict new patient diagnoses</li>
      <li><em>Unsupervised limitation</em>: Can group similar symptoms but can’t determine actual disease</li>
    </ul>
  </li>
  <li><strong>Fraud Detection</strong>
    <ul>
      <li>Input: Transaction patterns, amounts, timing</li>
      <li>Ground Truth: Confirmed fraud cases</li>
      <li>Goal: Accurately identify fraudulent transactions</li>
      <li><em>Unsupervised limitation</em>: Can find unusual patterns but can’t confirm fraud</li>
    </ul>
  </li>
  <li><strong>Image Recognition</strong>
    <ul>
      <li>Input: Cat/dog photos</li>
      <li>Ground Truth: Actual animal labels</li>
      <li>Goal: Classify new images accurately</li>
    </ul>
  </li>
</ol>

<p><br /></p>

<h3 id="when-unsupervised-learning-is-crucial">When Unsupervised Learning is Crucial</h3>

<h4 id="exploratory-data-analysis">Exploratory Data Analysis</h4>
<p>When labels are unavailable or when discovering hidden patterns is the goal.</p>

<ol>
  <li><strong>Unlabeled Data Scenarios</strong>
    <ul>
      <li>Most real-world data lacks labels</li>
      <li>Examples: Web logs, social media posts, sensor data, customer behavior</li>
      <li><em>Supervised limitation</em>: Cannot learn without labels</li>
    </ul>
  </li>
  <li><strong>Pattern Discovery</strong>
    <ul>
      <li>Goal: Find unexpected relationships in research data</li>
      <li>Example: Discovering new customer segments</li>
      <li><em>Supervised limitation</em>: Can only predict known categories</li>
    </ul>
  </li>
  <li><strong>Data Exploration</strong>
    <ul>
      <li>Understanding data structure before building predictive models</li>
      <li>Identifying outliers and anomalies</li>
      <li>Feature engineering and dimensionality reduction</li>
    </ul>
  </li>
</ol>

<p><br /></p>

<h3 id="practical-project-workflow">Practical Project Workflow</h3>

<h4 id="best-practice-combine-both-approache">Best Practice: Combine Both Approache</h4>
<p>Use unsupervised learning for exploration, then supervised learning for prediction.</p>

<p><br /></p>

<p><strong>Stage 1: Unsupervised Exploration</strong></p>
<ul>
  <li>“What patterns exist in this data?”</li>
  <li>Identify customer segments, product categories, user behaviors</li>
</ul>

<p><strong>Stage 2: Supervised Prediction</strong></p>
<ul>
  <li>“What will happen next?”</li>
  <li>Predict purchases, classify images, forecast demand</li>
</ul>

<p><strong>Example: Online Shopping Platform</strong></p>

<p><em>Unsupervised Analysis:</em></p>
<ul>
  <li>“These customers have similar purchase patterns”</li>
  <li>“This group primarily shops on weekends”</li>
</ul>

<p><em>Supervised Prediction:</em></p>
<ul>
  <li>“This customer will likely buy X next”</li>
  <li>“This customer has high churn probability”</li>
</ul>

<p><br /></p>

<h3 id="comparison-summary">Comparison Summary</h3>

<div class="table-container">
  <table class="table-beauty">
    <tr>
      <th style="width: 20%;">Aspect</th>
      <th style="width: 40%;">Supervised Learning</th>
      <th style="width: 40%;">Unsupervised Learning</th>
    </tr>
    <tr>
      <td><strong>Advantages</strong></td>
      <td>High accuracy, clear objectives</td>
      <td>No labels required, discovers new patterns</td>
    </tr>
    <tr>
      <td><strong>Disadvantages</strong></td>
      <td>Requires labeled data, time-consuming</td>
      <td>No accuracy guarantee, subjective interpretation</td>
    </tr>
    <tr>
      <td><strong>Best For</strong></td>
      <td>Prediction-critical applications</td>
      <td>Data exploration and discovery</td>
    </tr>
    <tr>
      <td><strong>Examples</strong></td>
      <td>Medical diagnosis, fraud detection</td>
      <td>Customer segmentation, anomaly detection</td>
    </tr>
  </table>
</div>

<hr />

<h2 id="uci-machine-learning-repository">UCI Machine Learning Repository</h2>

<p>The UCI Machine Learning Repository is the gold standard for machine learning datasets, maintained by the University of California, Irvine. It’s an invaluable resource for learning and benchmarking ML algorithms.</p>

<p><br /></p>

<h3 id="what-is-uci-ml-repository">What is UCI ML Repository?</h3>

<ul>
  <li><strong>Official Site</strong>: <a href="https://archive.ics.uci.edu/ml">https://archive.ics.uci.edu/ml</a></li>
  <li><strong>Purpose</strong>: Public repository of machine learning datasets</li>
  <li><strong>Audience</strong>: Researchers, students, and practitioners in ML and data science</li>
  <li><strong>History</strong>: One of the oldest and most respected ML dataset collections</li>
</ul>

<p><br /></p>

<h3 id="key-features">Key Features</h3>

<div class="table-container">
  <table class="table-beauty">
    <tr>
      <th style="width: 30%;">Feature</th>
      <th style="width: 70%;">Description</th>
    </tr>
    <tr>
      <td><strong>Diverse Domains</strong></td>
      <td>Health, finance, biology, image recognition, text classification</td>
    </tr>
    <tr>
      <td><strong>Labeled Datasets</strong></td>
      <td>Primarily supervised learning datasets for classification and regression</td>
    </tr>
    <tr>
      <td><strong>Benchmark Standard</strong></td>
      <td>Used in papers, courses, and tutorials for algorithm comparison</td>
    </tr>
    <tr>
      <td><strong>Free Access</strong></td>
      <td>Open access for educational and research purposes</td>
    </tr>
  </table>
</div>

<p><br /></p>

<h3 id="popular-datasets">Popular Datasets</h3>

<ol>
  <li><strong>Iris</strong>: 150 samples, 4 features, 3 classes (flower species)</li>
  <li><strong>Wine</strong>: 178 samples, 13 features, 3 classes (wine cultivars)</li>
  <li><strong>Breast Cancer Wisconsin</strong>: 569 samples, 30 features, 2 classes (malignant/benign)</li>
  <li><strong>Adult (Census Income)</strong>: 48,842 samples for income prediction</li>
  <li><strong>Mushroom</strong>: 8,124 samples for edibility classification</li>
</ol>

<p><br /></p>

<p>These datasets are ideal for:</p>
<ul>
  <li>Learning different ML algorithms</li>
  <li>Comparing model performance</li>
  <li>Understanding data preprocessing techniques</li>
  <li>Practicing feature engineering</li>
</ul>

<hr />

<h2 id="conclusion">Conclusion</h2>

<div class="info-box info-box-success-not-check">
  <strong>Key Takeaways</strong>
  <ul>
    <li><strong>Supervised Learning</strong>: Use when you have labeled data and need accurate predictions</li>
    <li><strong>Unsupervised Learning</strong>: Use for pattern discovery and data exploration without labels</li>
    <li><strong>Similarity</strong>: Measures how alike two data points are (distance-based)</li>
    <li><strong>Compatibility</strong>: Evaluates how well items work together (interaction-based)</li>
    <li><strong>Best Practice</strong>: Combine both approaches for comprehensive data understanding</li>
  </ul>
</div>

<p><br /></p>

<p>Machine learning fundamentally revolves around whether ground truth labels are available. Through our fruit classification examples and real-world implementations, we’ve seen that:</p>

<ul>
  <li><strong>Supervised learning</strong> achieves high accuracy with labeled data but requires extensive preparation</li>
  <li><strong>Unsupervised learning</strong> reveals hidden patterns but may not perfectly align with human expectations</li>
  <li><strong>Similarity measures</strong> quantify data relationships mathematically</li>
  <li><strong>Compatibility assessment</strong> evaluates interaction quality between entities</li>
</ul>

<p>The practical implementations demonstrate that understanding these concepts through code and experimentation provides deeper insights than theoretical definitions alone. The limitations and interpretations become clear when working with actual data.</p>

<p>Whether you’re building recommendation systems, analyzing customer behavior, or developing predictive models, mastering both supervised and unsupervised approaches will make you a more effective machine learning practitioner.</p>

<p><br /></p>

<p><strong>To put it simply:</strong></p>
<ul>
  <li><strong>Supervised learning</strong> is like having a teacher with answer sheets - you can learn to predict accurately</li>
  <li><strong>Unsupervised learning</strong> is like exploring patterns without answers - you discover new insights but can’t guarantee correctness</li>
  <li><strong>Both are powerful</strong> when used together for comprehensive data understanding</li>
</ul>

<p>Start with the provided examples, experiment with different algorithms, and gradually work with larger, more complex datasets to build your intuition and expertise.</p>

<hr />

<h2 id="references">References</h2>

<ul>
  <li><a href="https://scikit-learn.org/stable/">Scikit-learn Official Documentation</a></li>
  <li><a href="https://scikit-learn.org/stable/supervised_learning.html">Scikit-learn: Supervised vs Unsupervised Learning</a></li>
  <li><a href="https://archive.ics.uci.edu/ml/datasets/iris">Iris Dataset Documentation</a></li>
  <li><a href="https://towardsdatascience.com/supervised-vs-unsupervised-learning-14f68e32ea8d">Towards Data Science - Supervised vs Unsupervised Learning</a></li>
  <li><a href="https://developers.google.com/machine-learning/recommendation">Google Developers - Recommendation Systems</a></li>
  <li><a href="https://www.machinelearningplus.com/nlp/cosine-similarity/">Cosine Similarity Explained</a></li>
  <li><a href="https://scikit-learn.org/stable/modules/clustering.html#k-means">KMeans Clustering Official Examples</a></li>
  <li><a href="https://archive.ics.uci.edu/ml/index.php">UCI Machine Learning Repository</a></li>
</ul>


                <!-- Pagination links -->


            </article>

            
                <aside class="see-also">
                    <h2>See also</h2>
                    <ul>
                        
                        
                        
                            <li>
                                <a href="/category/troubleshooting/k8s-pod-restart-error-resolution/">
                                    
                                        <img src="https://res.cloudinary.com/dkcm26aem/image/upload/c_scale,w_380/v1754458793/pod-restart_r7jm5f.png">
                                    
                                    <h3>Resolving Kubernetes Pod Restart Errors</h3>
                                </a>
                            </li>
                        
                            <li>
                                <a href="/category/iac/terraform-starter/">
                                    
                                        <img src="https://res.cloudinary.com/dkcm26aem/image/upload/c_scale,w_380/v1755140221/terraform-starter-1_k25yxv.png">
                                    
                                    <h3>Terraform Fundamentals: Complete Guide to Infrastructure as Code</h3>
                                </a>
                            </li>
                        
                            <li>
                                <a href="/category/network/bridge-network/">
                                    
                                        <img src="https://res.cloudinary.com/dkcm26aem/image/upload/c_scale,w_380/v1754445656/bridge-network_dtjij0.png">
                                    
                                    <h3>Virtual Bridge Mode Networking: Transparent Layer 2 Connectivity in Virtualized Environments</h3>
                                </a>
                            </li>
                        
                    </ul>
                </aside>
            

        </section>

        <!-- Add time bar only for pages without pagination -->
        
            <div class="time-bar" data-minutes="23">
    <span class="time-completed"></span>
    <span class="time-remaining"></span>
    <div class="bar">
        <span class="completed" style="width:0%;"></span>
        <span class="remaining" style="width:100%;"></span>
    </div>
</div>

            <button class="toggle-preview" onclick="togglePreview()">
    <span>Hide Preview ▼</span>
</button>

<div id="recommendationSection" class="recommendation">
    <div class="message">
        <strong>Why don't you read something next?</strong>
        <div>
            <button>
                <svg><use xlink:href="#icon-arrow-right"></use></svg>
                <span>Go back to top</span>
            </button>
        </div>
    </div>
    <div id="previewSection" class="preview-section">
        
        <a href="/category/troubleshooting/cockpit-vm-network-communication-resolution/" class="post-preview">
            <div class="image">
                
                    <img src="https://res.cloudinary.com/dkcm26aem/image/upload/c_scale,w_380/v1755076873/cockpit-vm_o4uqsz.png">
                
            </div>
            <h3 class="title">Resolving VM-to-VM Network Communication Issues in Cockpit</h3>
        </a>
    </div>
</div>

<style>
.toggle-preview {
    position: fixed;
    bottom: 20px;
    right: 20px;
    background: #333;
    color: white;
    border: none;
    padding: 8px 15px;
    border-radius: 4px;
    cursor: pointer;
    z-index: 1000;
    opacity: 0;
    transition: opacity 0.3s ease;
}

.toggle-preview:hover {
    background: #444;
}

.toggle-preview.visible {
    opacity: 1;
}

.recommendation {
    margin-top: 1000px;
    display: block;
    transition: all 0.3s ease;
}

.recommendation.hidden {
    display: none;
}

.hide-preview {
    margin-left: 10px;
    background: none;
    border: 1px solid #666;
    color: #666;
    padding: 5px 10px;
    border-radius: 4px;
    cursor: pointer;
}

.hide-preview:hover {
    background: #f0f0f0;
}

.preview-section {
    max-height: 1000px;
    overflow: hidden;
    transition: max-height 0.3s ease-out;
}

.preview-section.hidden {
    max-height: 0;
}
</style>

<script>
function togglePreview() {
    const recommendation = document.getElementById('recommendationSection');
    const button = document.querySelector('.toggle-preview span');
    
    if (recommendation.classList.contains('hidden')) {
        recommendation.classList.remove('hidden');
        button.textContent = 'Hide Preview ▼';
    } else {
        recommendation.classList.add('hidden');
        button.textContent = 'Show Preview ▲';
    }
}

window.addEventListener('scroll', function() {
    const toggleButton = document.querySelector('.toggle-preview');
    const recommendation = document.getElementById('recommendationSection');
    const rect = recommendation.getBoundingClientRect();
    
    if (rect.top <= window.innerHeight) {
        toggleButton.classList.add('visible');
    } else {
        toggleButton.classList.remove('visible');
    }
});
</script>

        

        <!-- Show modal if the post is the last one -->
        

        <!-- Show modal before user leaves the page -->
        

        <!-- Add your newsletter subscription form here -->

        <section class="share">
    <h3>Share</h3>
    <a aria-label="Share on Twitter" href="https://twitter.com/intent/tweet?text=&quot;Master the core concepts of supervised and unsupervised learning through intuitive fruit classification examples, practical Python implementations, and real-world applications&quot;%20https://somaz.blog/category/ai/supervised-vs-unsupervised-learning-guide/%20via%20&#64;twitter_username&hashtags=machine-learning,supervised-learning,unsupervised-learning,classification,clustering,python,scikit-learn"
    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" title="Share on Twitter">
        <svg class="icon icon-twitter"><use xlink:href="#icon-twitter"></use></svg>
    </a>
    <a aria-label="Share on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://somaz.blog/category/ai/supervised-vs-unsupervised-learning-guide/"
    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;" title="Share on Facebook">
        <svg class="icon icon-facebook"><use xlink:href="#icon-facebook"></use></svg>
    </a>
</section>

        

  <section class="author">
    <div class="details">
      
        <img class="img-rounded" src="/assets/img/uploads/profile.png" alt="Somaz">
      
      <p class="def">Author</p>
      <h3 class="name">
        <a href="/authors/somaz/">Somaz</a>
      </h3>
      <p class="desc">DevOps engineer focused on cloud infrastructure and automation</p>
      <p>
        
          <a href="https://github.com/somaz94" title="Github">
            <svg><use xlink:href="#icon-github"></use></svg>
          </a>
        
        
        
        
        
        
          <a href="https://www.linkedin.com/in/somaz" title="LinkedIn">
            <svg><use xlink:href="#icon-linkedin"></use></svg>
          </a>
        
        
          <a href="https://somaz.tistory.com" title="Tistory">
            <svg><use xlink:href="#icon-tistory"></use></svg>
          </a>
        
      </p>
    </div>
  </section>

  
  
  
  
  
  
  
  

  <script type="application/ld+json">
  {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Somaz",
      
      "image": "/assets/img/uploads/profile.png",
      
      "jobTitle": "DevOps Engineer",
      "url": "https://somaz.blog/authors/somaz/",
      "sameAs": [
        "https://github.com/somaz94","https://www.linkedin.com/in/somaz","https://{{ author.tistory_username }}.tistory.com"
      ]
  }
  </script>


        

<section class="comments">
    <h3>Comments</h3>
    <div id="disqus_thread"></div>
</section>
<script type="text/javascript">
    var disqus_loaded = false;

    function load_disqus()
    {
        disqus_loaded = true;
        var disqus_shortname = 'https-somaz94-github-io';
        var disqus_title = '';
        var disqus_url = '/category/ai/supervised-vs-unsupervised-learning-guide/';
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        var ldr = document.getElementById('disqus_loader');
    };
    window.onscroll = function(e) {
        if ((window.innerHeight + window.scrollY) >= (document.body.offsetHeight - 800)) {
            //hit bottom of page
            if (disqus_loaded==false)
                load_disqus()
        }
    };
</script>



        <footer>
    <p>
      
        <a href="https://github.com/somaz94" title="Github">
          <svg><use xlink:href="#icon-github"></use></svg>
        </a>
      
      
        <a href="https://www.facebook.com/facebook_username" title="Facebook">
          <svg><use xlink:href="#icon-facebook"></use></svg>
        </a>
      
      
        <a href="https://twitter.com/twitter_username" title="Twitter">
          <svg><use xlink:href="#icon-twitter"></use></svg>
        </a>
      
      
        <a href="https://medium.com/@medium_username" title="Medium">
          <svg><use xlink:href="#icon-medium"></use></svg>
        </a>
      
      
        <a href="https://www.instagram.com/instagram_username" title="Instagram">
          <svg><use xlink:href="#icon-instagram"></use></svg>
        </a>
      
      
        <a href="https://www.linkedin.com/in/somaz" title="LinkedIn">
          <svg><use xlink:href="#icon-linkedin"></use></svg>
        </a>
      
      
        <a href="https://somaz.tistory.com" title="Tistory">
          <svg><use xlink:href="#icon-tistory"></use></svg>
        </a>
      
    </p>

    <ul>
  
    
      <li>
        <a href="https://somaz.blog/">Home</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/about">About</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/category">Category</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/contact">Contact</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/feed.xml">Feed</a>
      </li>
    
  
</ul>


    <p>
      <a href="https://somaz.blog/sitemap.xml" title="sitemap">Sitemap</a> |
      <a href="https://somaz.blog/privacy-policy" title="Privacy Policy">Privacy Policy</a>
    </p>

    <p>
      <span>Somaz Tech Blog</span> <svg class="love"><use xlink:href="#icon-heart"></use></svg>
    </p>
</footer>










<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "somaz",
  "description": "DevOps engineer's tech blog.",
  "url": "https://somaz.blog/",
  "logo": {
      "@type": "ImageObject",
      "url": "https://somaz.blog/assets/img/icons/mediumtile.png",
      "width": "600",
      "height": "315"
  },
  "sameAs": [
    "https://github.com/somaz94","https://www.facebook.com/facebook_username","https://twitter.com/twitter_username","https://medium.com/@medium_username","https://www.instagram.com/instagram_username","https://www.linkedin.com/in/somaz","https://{{ site.tistory_username }}.tistory.com"
  ]
}
</script>

<!-- Include the script that allows Netlify CMS login -->
<script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script>

<!-- Include the website scripts -->
<script src="/assets/js/scripts.min.js"></script>

<!-- Include Google Analytics script -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXX-X"></script>
<script>
  var host = window.location.hostname;
  if (host != 'localhost') {
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-XXXXXXXX-X');
  }
</script>
  


<!-- Include extra scripts -->



        

        
        
        
        
        
        
        
        
        <script type="application/ld+json">
        {
            "@context": "http://schema.org",
            "@type": "BlogPosting",
            "name": "Supervised vs Unsupervised Learning: Understanding ML Fundamentals with Fruit Classification",
            "headline": "From fruit sorting to advanced algorithms - A complete guide to machine learning paradigms",
            "description": "Master the core concepts of supervised and unsupervised learning through intuitive fruit classification examples, practical Python implementations, and real-world applications",
            "image": "https://res.cloudinary.com/dkcm26aem/image/upload/v1750915895/supervised-vs-unsupervised_jktylx.png",
            "url": "https://somaz.blog/category/ai/supervised-vs-unsupervised-learning-guide/",
            "articleBody": "

Table of Contents


  Overview
  Supervised vs Unsupervised Learning
  Similarity vs Compatibility
  Hands-on Python Examples
  Advanced Case Studies
  Why Both Approaches Matter
  UCI Machine Learning Repository
  Conclusion
  References




Overview

When starting with machine learning, one of the most common questions is: “What’s the difference between supervised and unsupervised learning?” This comprehensive guide uses intuitive fruit classification examples and real Python implementations to explain the core concepts that form the foundation of modern AI systems.


  Through practical examples involving fruit classification and the famous Iris dataset, we’ll explore:



  Supervised Learning: Classification and prediction with labeled data
  Unsupervised Learning: Pattern discovery without ground truth labels
  Similarity: Measuring how alike two data points are
  Compatibility: Evaluating how well items work together


You’ll gain hands-on experience with algorithms like DecisionTree, SVM, KNN, LogisticRegression for classification, and KMeans clustering with similarity analysis using real Python code.



Supervised vs Unsupervised Learning



Supervised Learning - “Learning with Answers”

Definition
“This fruit is an apple” → Learning from data where the correct answers (labels) are provided


  
    
      Characteristic
      Description
    
    
      Input
      Fruit features: color, size, sweetness, etc.
    
    
      Output
      Labels (e.g., apple, banana, grape)
    
    
      Goal
      Learn to predict correct labels for new input data
    
    
      Example
      Fruit image → Apple/Banana/Grape prediction
    
  


Example:
Input: [color=red, size=small, sweetness=high]  
Output: Apple (label)




Unsupervised Learning - “Finding Patterns Without Answers”

Definition
“These fruits look similar, they might belong to the same group!” → Discovering data structure without ground truth labels


  
    
      Characteristic
      Description
    
    
      Input
      Fruit features: color, size, sweetness, etc.
    
    
      Output
      None (clusters/groups without predefined labels)
    
    
      Goal
      Group similar data points or extract meaningful features
    
    
      Example
      Automatically cluster fruits by color/size similarity
    
  


Example:
Input: Various fruit feature data  
Output: Cluster 1 = Apple-like group, Cluster 2 = Banana-like group






Similarity vs Compatibility

While similarity and compatibility may seem related, they serve different purposes in machine learning applications.



Similarity

Core Question
“How alike are these two objects?” → Measuring distance or resemblance between data points


  
    
      Characteristic
      Description
    
    
      Core Question
      How similar are they?
    
    
      Mathematical Expression
      Cosine Similarity, Euclidean Distance, etc.
    
    
      Use Cases
      Recommendation systems, clustering, image search
    
  


Example:
Apple vs Pear color/sweetness/size difference → Distance calculation
Distance 0 = Nearly identical fruits


Compatibility

Core Question
“How well do these items work together?” → Evaluating the quality of combinations


  
    
      Characteristic
      Description
    
    
      Core Question
      How well do they work together?
    
    
      Mathematical Expression
      Score-based (interaction models, co-occurrence)
    
    
      Use Cases
      Matching systems, product recommendations, recipe pairing
    
  


Example:
Apple + Honey combination score = 9.1
Apple + Soy sauce combination score = 2.3




Summary: ML Concepts with Fruit Examples


  
    
      Concept
      Description
      Example
    
    
      Supervised Learning
      Learning from labeled examples
      Fruit photo → Apple prediction
    
    
      Unsupervised Learning
      Finding groups without labels
      Grouping similar fruits together
    
    
      Similarity
      How alike are they?
      Apple vs Pear comparison
    
    
      Compatibility
      How well do they work together?
      Apple + Honey pairing
    
  




Hands-on Python Examples

Now let’s implement supervised and unsupervised learning with actual Python code. Follow along with the practical examples below.


  🚀 Complete Code Repository

  � ML Basics - Supervised vs Unsupervised Learning

  Complete guide from machine learning fundamentals to hands-on practice

  What’s included:
  
    📓 Interactive Jupyter Notebooks
    📊 Real-world Sample Datasets
    🐍 Well-documented Python Examples
    📚 Step-by-step Implementation Guide
    🔬 Comparison Analysis &amp;amp; Visualizations
  




� Prerequisites

Before diving into the examples, make sure you have the following setup ready:



Setup: Virtual Environment and Dependencies

Recommended Setup
Create a virtual environment to avoid package conflicts and ensure reproducible results.

# Create and activate virtual environment
python3 -m venv ml_env
source ml_env/bin/activate  # Windows: ml_env\Scripts\activate

# Install required packages
pip3 install scikit-learn numpy matplotlib pandas


Example 1: Fruit Classification with Scikit-Learn

This example demonstrates both supervised and unsupervised learning approaches using synthetic fruit data with features like color, size, and sweetness.

# supervised_vs_unsupervised.py
from sklearn.tree import DecisionTreeClassifier
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import matplotlib.pyplot as plt

# Configure font for better visualization
plt.rcParams[&apos;font.family&apos;] = &apos;DejaVu Sans&apos;
plt.rcParams[&apos;axes.unicode_minus&apos;] = False

# -----------------------
# Supervised Learning: Fruit Classification
# -----------------------
print(&quot;📘 Supervised Learning - Decision Tree Fruit Prediction&quot;)

# Fruit features: [color, size, sweetness]
X = [[1, 1, 9], [1, 2, 10], [3, 4, 3], [2, 4, 4], [4, 1, 8]]
y = [0, 0, 1, 1, 2]  # 0:apple, 1:banana, 2:grape

clf = DecisionTreeClassifier(random_state=42)
clf.fit(X, y)

# Predict new fruit
prediction = clf.predict([[1, 1, 10]])
print(&quot;Prediction result (label):&quot;, prediction)
print(&quot;Feature importance:&quot;, clf.feature_importances_)

# -----------------------
# Unsupervised Learning: Fruit Clustering
# -----------------------
print(&quot;\n📘 Unsupervised Learning - KMeans Clustering&quot;)

kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X)
print(&quot;Cluster results:&quot;, clusters)
print(&quot;Cluster centers:&quot;, kmeans.cluster_centers_)

# Visualization
plt.figure(figsize=(10, 6))
plt.subplot(1, 2, 1)
plt.scatter([x[0] for x in X], [x[2] for x in X], c=y, cmap=&apos;viridis&apos;)
plt.xlabel(&quot;Color&quot;)
plt.ylabel(&quot;Sweetness&quot;)
plt.title(&quot;True Labels&quot;)
plt.colorbar()

plt.subplot(1, 2, 2)
plt.scatter([x[0] for x in X], [x[2] for x in X], c=clusters, cmap=&apos;viridis&apos;)
plt.xlabel(&quot;Color&quot;)
plt.ylabel(&quot;Sweetness&quot;)
plt.title(&quot;KMeans Clusters&quot;)
plt.colorbar()
plt.tight_layout()
plt.show()

# -----------------------
# Similarity Analysis (Cosine)
# -----------------------
print(&quot;\n📘 Similarity - Cosine Similarity Analysis&quot;)

apple = np.array([[1, 1, 9]])
pear = np.array([[2, 1, 9]])
banana = np.array([[3, 4, 3]])

sim_apple_pear = cosine_similarity(apple, pear)[0][0]
sim_apple_banana = cosine_similarity(apple, banana)[0][0]

print(f&quot;Apple-Pear similarity: {sim_apple_pear:.4f}&quot;)
print(f&quot;Apple-Banana similarity: {sim_apple_banana:.4f}&quot;)

# Calculate all pairwise similarities
fruits = np.array([[1, 1, 9], [2, 1, 9], [3, 4, 3]])
fruit_names = [&apos;Apple&apos;, &apos;Pear&apos;, &apos;Banana&apos;]
similarity_matrix = cosine_similarity(fruits)

print(&quot;\nSimilarity Matrix:&quot;)
for i, name1 in enumerate(fruit_names):
    for j, name2 in enumerate(fruit_names):
        print(f&quot;{name1}-{name2}: {similarity_matrix[i][j]:.4f}&quot;)


Expected Output:
📘 Supervised Learning - Decision Tree Fruit Prediction
Prediction result (label): [0]
Feature importance: [0.2 0.3 0.5]

📘 Unsupervised Learning - KMeans Clustering
Cluster results: [0 0 1 1 2]
Cluster centers: [[1.5 1.5 9.5]
                  [2.5 4.  3.5]
                  [4.  1.  8. ]]

📘 Similarity - Cosine Similarity Analysis
Apple-Pear similarity: 0.9942
Apple-Banana similarity: 0.6400






Example 2: Iris Dataset Classification and Clustering

The Iris dataset is a classic benchmark in machine learning, perfect for comparing supervised and unsupervised approaches on real data.

# iris_classification.py
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, confusion_matrix
import pandas as pd
import numpy as np

# Load Iris dataset
iris = datasets.load_iris()
X, y = iris.data, iris.target
feature_names = iris.feature_names
target_names = iris.target_names

print(&quot;📊 Iris Dataset Overview&quot;)
print(f&quot;Dataset shape: {X.shape}&quot;)
print(f&quot;Features: {feature_names}&quot;)
print(f&quot;Classes: {target_names}&quot;)
print(f&quot;Class distribution: {np.bincount(y)}&quot;)

# Split data for supervised learning
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# -----------------------
# Supervised Learning: Multiple Algorithms
# -----------------------
print(&quot;\n📘 Supervised Learning - Multiple Classification Algorithms&quot;)

algorithms = {
    &apos;SVM&apos;: SVC(random_state=42),
    &apos;KNN&apos;: KNeighborsClassifier(n_neighbors=3),
    &apos;LogisticRegression&apos;: LogisticRegression(random_state=42, max_iter=200)
}

results = {}
for name, model in algorithms.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy
    print(f&quot;{name} accuracy: {accuracy:.3f}&quot;)

# -----------------------
# Unsupervised Learning: KMeans Clustering
# -----------------------
print(&quot;\n📘 Unsupervised Learning - KMeans Clustering Analysis&quot;)

kmeans = KMeans(n_clusters=3, random_state=42)
cluster_labels = kmeans.fit_predict(X)

print(&quot;KMeans cluster results:&quot;, cluster_labels)
print(&quot;True species labels:&quot;, y)

# Compare clustering with true labels
conf_matrix = confusion_matrix(y, cluster_labels)
print(&quot;Cluster-Truth confusion matrix:&quot;)
print(conf_matrix)

# Calculate cluster purity
def calculate_purity(y_true, y_pred):
    &quot;&quot;&quot;Calculate clustering purity score&quot;&quot;&quot;
    conf_matrix = confusion_matrix(y_true, y_pred)
    return np.sum(np.amax(conf_matrix, axis=0)) / np.sum(conf_matrix)

purity = calculate_purity(y, cluster_labels)
print(f&quot;Clustering purity: {purity:.3f}&quot;)

# Analyze cluster characteristics
print(&quot;\nCluster Analysis:&quot;)
for i in range(3):
    cluster_mask = cluster_labels == i
    cluster_data = X[cluster_mask]
    true_labels = y[cluster_mask]
    
    print(f&quot;\nCluster {i}:&quot;)
    print(f&quot;  Size: {np.sum(cluster_mask)} samples&quot;)
    print(f&quot;  Dominant species: {target_names[np.bincount(true_labels).argmax()]}&quot;)
    print(f&quot;  Average features: {np.mean(cluster_data, axis=0)}&quot;)

# -----------------------
# Feature Analysis
# -----------------------
print(&quot;\n📊 Feature Importance Analysis&quot;)

# Use trained LogisticRegression for feature importance
lr_model = algorithms[&apos;LogisticRegression&apos;]
feature_importance = np.abs(lr_model.coef_).mean(axis=0)

print(&quot;Feature importance ranking:&quot;)
for i, (feature, importance) in enumerate(zip(feature_names, feature_importance)):
    print(f&quot;{i+1}. {feature}: {importance:.3f}&quot;)


Expected Output:
📊 Iris Dataset Overview
Dataset shape: (150, 4)
Features: [&apos;sepal length (cm)&apos;, &apos;sepal width (cm)&apos;, &apos;petal length (cm)&apos;, &apos;petal width (cm)&apos;]
Classes: [&apos;setosa&apos; &apos;versicolor&apos; &apos;virginica&apos;]
Class distribution: [50 50 50]

📘 Supervised Learning - Multiple Classification Algorithms
SVM accuracy: 1.000
KNN accuracy: 1.000
LogisticRegression accuracy: 1.000

📘 Unsupervised Learning - KMeans Clustering Analysis
KMeans cluster results: [1 1 1 ... 0 2 0]
True species labels: [0 0 0 ... 2 2 2]
Cluster-Truth confusion matrix:
[[ 0 50  0]
 [ 3  0 47]
 [36  0 14]]
Clustering purity: 0.747










Example 3: Wine Quality Analysis

This example demonstrates both classification and regression tasks using real-world wine quality data, showing how the same dataset can be approached differently.









Advanced Case Studies



Case Study 1: E-commerce Recommendation System

Real-world application combining both supervised and unsupervised learning for product recommendations.

# ecommerce_recommendation.py
import numpy as np
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler

class EcommerceRecommendationSystem:
    def __init__(self):
        self.user_clusters = None
        self.product_features = None
        self.purchase_predictor = None
        self.scaler = StandardScaler()
        
    def analyze_user_behavior(self, user_data):
        &quot;&quot;&quot;Unsupervised: Cluster users by behavior patterns&quot;&quot;&quot;
        # user_data: [browsing_time, purchase_frequency, avg_order_value, ...]
        
        scaled_data = self.scaler.fit_transform(user_data)
        
        # Find optimal number of clusters
        kmeans = KMeans(n_clusters=5, random_state=42)
        user_clusters = kmeans.fit_predict(scaled_data)
        
        self.user_clusters = kmeans
        return user_clusters
    
    def train_purchase_predictor(self, user_features, purchase_history):
        &quot;&quot;&quot;Supervised: Predict purchase likelihood&quot;&quot;&quot;
        
        self.purchase_predictor = RandomForestClassifier(
            n_estimators=100, random_state=42
        )
        self.purchase_predictor.fit(user_features, purchase_history)
        
        return self.purchase_predictor.score(user_features, purchase_history)
    
    def calculate_product_similarity(self, product_features):
        &quot;&quot;&quot;Calculate product similarity matrix&quot;&quot;&quot;
        
        self.product_features = product_features
        similarity_matrix = cosine_similarity(product_features)
        
        return similarity_matrix
    
    def recommend_products(self, user_id, user_features, n_recommendations=5):
        &quot;&quot;&quot;Hybrid recommendation using both approaches&quot;&quot;&quot;
        
        # 1. Predict purchase probability (supervised)
        purchase_prob = self.purchase_predictor.predict_proba([user_features])[0][1]
        
        # 2. Find user cluster (unsupervised)
        user_cluster = self.user_clusters.predict([user_features])[0]
        
        # 3. Use similarity for product recommendations
        # (In practice, this would use actual user-product interactions)
        recommendations = {
            &apos;user_id&apos;: user_id,
            &apos;purchase_probability&apos;: purchase_prob,
            &apos;user_cluster&apos;: user_cluster,
            &apos;recommended_products&apos;: list(range(n_recommendations))  # Simplified
        }
        
        return recommendations

# Example usage
np.random.seed(42)

# Generate synthetic user data
n_users = 1000
user_data = np.random.rand(n_users, 5)  # 5 behavioral features
purchase_history = np.random.binomial(1, 0.3, n_users)  # 30% purchase rate

# Initialize and train system
rec_system = EcommerceRecommendationSystem()

# Unsupervised analysis
user_clusters = rec_system.analyze_user_behavior(user_data)
print(f&quot;Identified {len(np.unique(user_clusters))} user clusters&quot;)

# Supervised training
accuracy = rec_system.train_purchase_predictor(user_data, purchase_history)
print(f&quot;Purchase prediction accuracy: {accuracy:.3f}&quot;)

# Generate recommendations for a new user
new_user_features = [0.7, 0.5, 0.8, 0.3, 0.6]
recommendations = rec_system.recommend_products(
    user_id=1001, 
    user_features=new_user_features
)

print(&quot;\nRecommendation Results:&quot;)
for key, value in recommendations.items():
    print(f&quot;{key}: {value}&quot;)




Why Both Approaches Matter



When Supervised Learning is Essential

High-Stakes Prediction Tasks
When accurate prediction is critical and labeled data is available.


  Medical Diagnosis
    
      Input: Patient symptoms, test results
      Ground Truth: Actual diagnosis (cancer/normal)
      Goal: Accurately predict new patient diagnoses
      Unsupervised limitation: Can group similar symptoms but can’t determine actual disease
    
  
  Fraud Detection
    
      Input: Transaction patterns, amounts, timing
      Ground Truth: Confirmed fraud cases
      Goal: Accurately identify fraudulent transactions
      Unsupervised limitation: Can find unusual patterns but can’t confirm fraud
    
  
  Image Recognition
    
      Input: Cat/dog photos
      Ground Truth: Actual animal labels
      Goal: Classify new images accurately
    
  




When Unsupervised Learning is Crucial

Exploratory Data Analysis
When labels are unavailable or when discovering hidden patterns is the goal.


  Unlabeled Data Scenarios
    
      Most real-world data lacks labels
      Examples: Web logs, social media posts, sensor data, customer behavior
      Supervised limitation: Cannot learn without labels
    
  
  Pattern Discovery
    
      Goal: Find unexpected relationships in research data
      Example: Discovering new customer segments
      Supervised limitation: Can only predict known categories
    
  
  Data Exploration
    
      Understanding data structure before building predictive models
      Identifying outliers and anomalies
      Feature engineering and dimensionality reduction
    
  




Practical Project Workflow

Best Practice: Combine Both Approache
Use unsupervised learning for exploration, then supervised learning for prediction.



Stage 1: Unsupervised Exploration

  “What patterns exist in this data?”
  Identify customer segments, product categories, user behaviors


Stage 2: Supervised Prediction

  “What will happen next?”
  Predict purchases, classify images, forecast demand


Example: Online Shopping Platform

Unsupervised Analysis:

  “These customers have similar purchase patterns”
  “This group primarily shops on weekends”


Supervised Prediction:

  “This customer will likely buy X next”
  “This customer has high churn probability”




Comparison Summary


  
    
      Aspect
      Supervised Learning
      Unsupervised Learning
    
    
      Advantages
      High accuracy, clear objectives
      No labels required, discovers new patterns
    
    
      Disadvantages
      Requires labeled data, time-consuming
      No accuracy guarantee, subjective interpretation
    
    
      Best For
      Prediction-critical applications
      Data exploration and discovery
    
    
      Examples
      Medical diagnosis, fraud detection
      Customer segmentation, anomaly detection
    
  




UCI Machine Learning Repository

The UCI Machine Learning Repository is the gold standard for machine learning datasets, maintained by the University of California, Irvine. It’s an invaluable resource for learning and benchmarking ML algorithms.



What is UCI ML Repository?


  Official Site: https://archive.ics.uci.edu/ml
  Purpose: Public repository of machine learning datasets
  Audience: Researchers, students, and practitioners in ML and data science
  History: One of the oldest and most respected ML dataset collections




Key Features


  
    
      Feature
      Description
    
    
      Diverse Domains
      Health, finance, biology, image recognition, text classification
    
    
      Labeled Datasets
      Primarily supervised learning datasets for classification and regression
    
    
      Benchmark Standard
      Used in papers, courses, and tutorials for algorithm comparison
    
    
      Free Access
      Open access for educational and research purposes
    
  




Popular Datasets


  Iris: 150 samples, 4 features, 3 classes (flower species)
  Wine: 178 samples, 13 features, 3 classes (wine cultivars)
  Breast Cancer Wisconsin: 569 samples, 30 features, 2 classes (malignant/benign)
  Adult (Census Income): 48,842 samples for income prediction
  Mushroom: 8,124 samples for edibility classification




These datasets are ideal for:

  Learning different ML algorithms
  Comparing model performance
  Understanding data preprocessing techniques
  Practicing feature engineering




Conclusion


  Key Takeaways
  
    Supervised Learning: Use when you have labeled data and need accurate predictions
    Unsupervised Learning: Use for pattern discovery and data exploration without labels
    Similarity: Measures how alike two data points are (distance-based)
    Compatibility: Evaluates how well items work together (interaction-based)
    Best Practice: Combine both approaches for comprehensive data understanding
  




Machine learning fundamentally revolves around whether ground truth labels are available. Through our fruit classification examples and real-world implementations, we’ve seen that:


  Supervised learning achieves high accuracy with labeled data but requires extensive preparation
  Unsupervised learning reveals hidden patterns but may not perfectly align with human expectations
  Similarity measures quantify data relationships mathematically
  Compatibility assessment evaluates interaction quality between entities


The practical implementations demonstrate that understanding these concepts through code and experimentation provides deeper insights than theoretical definitions alone. The limitations and interpretations become clear when working with actual data.

Whether you’re building recommendation systems, analyzing customer behavior, or developing predictive models, mastering both supervised and unsupervised approaches will make you a more effective machine learning practitioner.



To put it simply:

  Supervised learning is like having a teacher with answer sheets - you can learn to predict accurately
  Unsupervised learning is like exploring patterns without answers - you discover new insights but can’t guarantee correctness
  Both are powerful when used together for comprehensive data understanding


Start with the provided examples, experiment with different algorithms, and gradually work with larger, more complex datasets to build your intuition and expertise.



References


  Scikit-learn Official Documentation
  Scikit-learn: Supervised vs Unsupervised Learning
  Iris Dataset Documentation
  Towards Data Science - Supervised vs Unsupervised Learning
  Google Developers - Recommendation Systems
  Cosine Similarity Explained
  KMeans Clustering Official Examples
  UCI Machine Learning Repository

",
            "wordcount": "4210",
            "inLanguage": "en",
            "dateCreated": "2025-10-09/",
            "datePublished": "2025-10-09/",
            "dateModified": "2025-10-09/",
            "author": {
                "@type": "Person",
                "name": "Somaz",
                
                "image": "/assets/img/uploads/profile.png",
                
                "jobTitle": "DevOps Engineer",
                "url": "https://somaz.blog/authors/somaz/",
                "sameAs": [
                    "https://github.com/somaz94","https://www.linkedin.com/in/somaz"
                ]
            },
            "publisher": {
                "@type": "Organization",
                "name": "somaz",
                "url": "https://somaz.blog/",
                "logo": {
                    "@type": "ImageObject",
                    "url": "https://somaz.blog/assets/img/blog-image.png",
                    "width": "600",
                    "height": "315"
                }
            },
            "mainEntityOfPage": "True",
            "genre": "AI",
            "articleSection": "AI",
            "keywords": ["machine-learning","supervised-learning","unsupervised-learning","classification","clustering","python","scikit-learn"]
        }
        </script>
    </body>
</html>
