<!DOCTYPE html>
<html lang="en" class="no-js">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    

    
    

    
    

    
    

    <!-- ✅ Google Tag Manager 추가 -->
    <script>
        (function(w,d,s,l,i){
            w[l]=w[l]||[];
            w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});
            var f=d.getElementsByTagName(s)[0],
            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';
            j.async=true;
            j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;
            f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer','GTM-MBP83N4Q');
    </script>
      <!-- ✅ End Google Tag Manager -->

    <!-- Mermaid.js 직접 로드 -->
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true });
    </script>

    <title>OS Cache and Disk I/O - MySQL and Redis Performance Analysis | somaz</title>
    <meta name="description" content="An in-depth exploration of OS cache mechanisms and their effects on MySQL and Redis performance">
    
        <meta name="keywords" content="performance, mysql, redis, cache, disk-io">
    

    <!-- Social: Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="OS Cache and Disk I/O - MySQL and Redis Performance Analysis | somaz">
    <meta name="twitter:description" content="An in-depth exploration of OS cache mechanisms and their effects on MySQL and Redis performance">

    
        <meta property="twitter:image" content="https://res.cloudinary.com/dkcm26aem/image/upload/v1744340260/os-cache-disk_jwhgck.png">
    
    
    
        <meta name="twitter:site" content="@twitter_username">
    

    <!-- Social: Facebook / Open Graph -->
    <meta property="og:url" content="https://somaz.blog/category/cs/os-cache-disk/">
    <meta property="og:title" content="OS Cache and Disk I/O - MySQL and Redis Performance Analysis | somaz">
    <meta property="og:image" content="https://res.cloudinary.com/dkcm26aem/image/upload/v1744340260/os-cache-disk_jwhgck.png">
    <meta property="og:description" content="An in-depth exploration of OS cache mechanisms and their effects on MySQL and Redis performance">
    <meta property="og:site_name" content="Somaz Tech Blog">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/assets/img/icons/apple-touch-icon.png" />
    <link rel="apple-touch-icon" sizes="57x57" href="/assets/img/icons/apple-touch-icon-57x57.png" />
    <link rel="apple-touch-icon" sizes="72x72" href="/assets/img/icons/apple-touch-icon-72x72.png" />
    <link rel="apple-touch-icon" sizes="114x114" href="/assets/img/icons/apple-touch-icon-114x114.png" />
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/img/icons/apple-touch-icon-144x144.png" />
    <link rel="apple-touch-icon" sizes="60x60" href="/assets/img/icons/apple-touch-icon-60x60.png" />
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/img/icons/apple-touch-icon-120x120.png" />
    <link rel="apple-touch-icon" sizes="76x76" href="/assets/img/icons/apple-touch-icon-76x76.png" />
    <link rel="apple-touch-icon" sizes="152x152" href="/assets/img/icons/apple-touch-icon-152x152.png" />

    <!-- Windows 8 Tile Icons -->
    <meta name="application-name" content="somaz">
    <meta name="msapplication-TileColor" content="#141414">
    <meta name="msapplication-square70x70logo" content="smalltile.png" />
    <meta name="msapplication-square150x150logo" content="mediumtile.png" />
    <meta name="msapplication-wide310x150logo" content="widetile.png" />
    <meta name="msapplication-square310x310logo" content="largetile.png" />
    
    <!-- Android Lolipop Theme Color -->
    <meta name="theme-color" content="#141414">

    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Titillium+Web:300,400,700" rel="stylesheet">

    <link rel="stylesheet" href="/assets/css/styles.css">
    <link rel="canonical" href="https://somaz.blog/category/cs/os-cache-disk/">
    <link rel="alternate" type="application/rss+xml" title="Somaz Tech Blog" href="https://somaz.blog/feed.xml" />

    <!-- Include extra styles -->
    

    <!-- JavaScript enabled/disabled -->
    <script>
        document.querySelector('html').classList.remove('no-js');
    </script>

    <!-- Google Adsense -->
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8725590811736154"
        crossorigin="anonymous"></script>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <!-- <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet"> -->
    <!-- <link href="https://cdn.jsdelivr.net/gh/sunn-us/SUIT/fonts/variable/woff2/SUIT-Variable.css" rel="stylesheet"> -->
    <link href="https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@400;500;700&display=swap" rel="stylesheet">
    <!-- <link href="https://fonts.googleapis.com/css2?family=Albert+Sans:wght@400;500;700&display=swap" rel="stylesheet"> -->

    <link rel="sitemap" type="application/xml" title="Sitemap" href="/sitemap.xml" />

</head>
<!-- ✅ Google Tag Manager (noscript) -->
<noscript>
    <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MBP83N4Q"
            height="0" width="0" style="display:none;visibility:hidden">
    </iframe>
</noscript>
<!-- ✅ End Google Tag Manager (noscript) -->
    <body class="has-push-menu">
        





        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" display="none" version="1.1"><defs><symbol id="icon-menu" viewBox="0 0 1024 1024"><path class="path1" d="M128 213.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 725.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 469.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5z"/></symbol><symbol id="icon-search" viewBox="0 0 951 1024"><path class="path1" d="M658.286 475.429q0-105.714-75.143-180.857t-180.857-75.143-180.857 75.143-75.143 180.857 75.143 180.857 180.857 75.143 180.857-75.143 75.143-180.857zM950.857 950.857q0 29.714-21.714 51.429t-51.429 21.714q-30.857 0-51.429-21.714l-196-195.429q-102.286 70.857-228 70.857-81.714 0-156.286-31.714t-128.571-85.714-85.714-128.571-31.714-156.286 31.714-156.286 85.714-128.571 128.571-85.714 156.286-31.714 156.286 31.714 128.571 85.714 85.714 128.571 31.714 156.286q0 125.714-70.857 228l196 196q21.143 21.143 21.143 51.429z"/></symbol><symbol id="icon-close" viewBox="0 0 1000 1000"><path d="M969.8,870.3c27,27.7,27,71.8,0,99.1C955.7,983,937.9,990,920,990c-17.9,0-35.7-7-49.7-20.7L500,599L129.6,969.4C115.6,983,97.8,990,79.9,990s-35.7-7-49.7-20.7c-27-27.3-27-71.4,0-99.1L400.9,500L30.3,129.3c-27-27.3-27-71.4,0-99.1c27.3-27,71.8-27,99.4,0L500,400.9L870.4,30.2c27.7-27,71.8-27,99.4,0c27,27.7,27,71.8,0,99.1L599.1,500L969.8,870.3z"/></symbol><symbol id="icon-twitter" viewBox="0 0 951 1024"><path class="path1" d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"/></symbol><symbol id="icon-facebook" viewBox="0 0 585 1024"><path class="path1" d="M548 6.857v150.857h-89.714q-49.143 0-66.286 20.571t-17.143 61.714v108h167.429l-22.286 169.143h-145.143v433.714h-174.857v-433.714h-145.714v-169.143h145.714v-124.571q0-106.286 59.429-164.857t158.286-58.571q84 0 130.286 6.857z"/></symbol><symbol id="icon-clock" viewBox="0 0 1000 1000"><path d="M500,10C229.8,10,10,229.8,10,500c0,270.2,219.8,490,490,490c270.2,0,490-219.8,490-490C990,229.8,770.2,10,500,10z M500,910.2c-226.2,0-410.2-184-410.2-410.2c0-226.2,184-410.2,410.2-410.2c226.2,0,410.2,184,410.2,410.2C910.2,726.1,726.2,910.2,500,910.2z M753.1,374c8.2,11.9,5.2,28.1-6.6,36.3L509.9,573.7c-4.4,3.1-9.6,4.6-14.8,4.6c-4.1,0-8.3-1-12.1-3c-8.6-4.5-14-13.4-14-23.1V202.5c0-14.4,11.7-26.1,26.1-26.1c14.4,0,26.1,11.7,26.1,26.1v300l195.6-135.1C728.7,359.2,744.9,362.1,753.1,374z"/></symbol><symbol id="icon-calendar" viewBox="0 0 1000 1000"><path d="M920,500v420H80V500H920 M990,430H10v490c0,38.7,31.3,70,70,70h840c38.7,0,70-31.3,70-70V430L990,430z"/><path d="M850,80v105c0,57.9-47.2,105-105,105c-58,0-105-47.1-105-105V80H360v105c0,57.9-47.2,105-105,105c-58,0-105-47.1-105-105V80C72.8,80,10,142.7,10,220v140h980V220C990,142.7,927.2,80,850,80z"/><path d="M255,10c-19.3,0-35,15.8-35,35v140c0,19.2,15.7,35,35,35c19.3,0,35-15.8,35-35V45C290,25.8,274.3,10,255,10z"/><path d="M745,10c-19.3,0-35,15.8-35,35v140c0,19.2,15.7,35,35,35c19.3,0,35-15.8,35-35V45C780,25.8,764.3,10,745,10z"/></symbol><symbol id="icon-github" viewBox="0 0 12 14"><path d="M6 1q1.633 0 3.012 0.805t2.184 2.184 0.805 3.012q0 1.961-1.145 3.527t-2.957 2.168q-0.211 0.039-0.312-0.055t-0.102-0.234q0-0.023 0.004-0.598t0.004-1.051q0-0.758-0.406-1.109 0.445-0.047 0.801-0.141t0.734-0.305 0.633-0.52 0.414-0.82 0.16-1.176q0-0.93-0.617-1.609 0.289-0.711-0.062-1.594-0.219-0.070-0.633 0.086t-0.719 0.344l-0.297 0.187q-0.727-0.203-1.5-0.203t-1.5 0.203q-0.125-0.086-0.332-0.211t-0.652-0.301-0.664-0.105q-0.352 0.883-0.062 1.594-0.617 0.68-0.617 1.609 0 0.664 0.16 1.172t0.41 0.82 0.629 0.523 0.734 0.305 0.801 0.141q-0.305 0.281-0.383 0.805-0.164 0.078-0.352 0.117t-0.445 0.039-0.512-0.168-0.434-0.488q-0.148-0.25-0.379-0.406t-0.387-0.187l-0.156-0.023q-0.164 0-0.227 0.035t-0.039 0.090 0.070 0.109 0.102 0.094l0.055 0.039q0.172 0.078 0.34 0.297t0.246 0.398l0.078 0.18q0.102 0.297 0.344 0.48t0.523 0.234 0.543 0.055 0.434-0.027l0.18-0.031q0 0.297 0.004 0.691t0.004 0.426q0 0.141-0.102 0.234t-0.312 0.055q-1.812-0.602-2.957-2.168t-1.145-3.527q0-1.633 0.805-3.012t2.184-2.184 3.012-0.805zM2.273 9.617q0.023-0.055-0.055-0.094-0.078-0.023-0.102 0.016-0.023 0.055 0.055 0.094 0.070 0.047 0.102-0.016zM2.516 9.883q0.055-0.039-0.016-0.125-0.078-0.070-0.125-0.023-0.055 0.039 0.016 0.125 0.078 0.078 0.125 0.023zM2.75 10.234q0.070-0.055 0-0.148-0.062-0.102-0.133-0.047-0.070 0.039 0 0.141t0.133 0.055zM3.078 10.562q0.062-0.062-0.031-0.148-0.094-0.094-0.156-0.023-0.070 0.062 0.031 0.148 0.094 0.094 0.156 0.023zM3.523 10.758q0.023-0.086-0.102-0.125-0.117-0.031-0.148 0.055t0.102 0.117q0.117 0.047 0.148-0.047zM4.016 10.797q0-0.102-0.133-0.086-0.125 0-0.125 0.086 0 0.102 0.133 0.086 0.125 0 0.125-0.086zM4.469 10.719q-0.016-0.086-0.141-0.070-0.125 0.023-0.109 0.117t0.141 0.062 0.109-0.109z"></path></symbol><symbol id="icon-medium" viewBox="0 0 1000 1000"><path d="M336.5,240.2v641.5c0,9.1-2.3,16.9-6.8,23.2s-11.2,9.6-20,9.6c-6.2,0-12.2-1.5-18-4.4L37.3,782.7c-7.7-3.6-14.1-9.8-19.4-18.3S10,747.4,10,739V115.5c0-7.3,1.8-13.5,5.5-18.6c3.6-5.1,8.9-7.7,15.9-7.7c5.1,0,13.1,2.7,24.1,8.2l279.5,140C335.9,238.6,336.5,239.5,336.5,240.2L336.5,240.2z M371.5,295.5l292,473.6l-292-145.5V295.5z M990,305.3v576.4c0,9.1-2.6,16.5-7.7,22.1c-5.1,5.7-12,8.5-20.8,8.5s-17.3-2.4-25.7-7.1L694.7,784.9L990,305.3z M988.4,239.7c0,1.1-46.8,77.6-140.3,229.4C754.6,621,699.8,709.8,683.8,735.7L470.5,389l177.2-288.2c6.2-10.2,15.7-15.3,28.4-15.3c5.1,0,9.8,1.1,14.2,3.3l295.9,147.7C987.6,237.1,988.4,238.2,988.4,239.7L988.4,239.7z"/></symbol><symbol id="icon-instagram" viewBox="0 0 489.84 489.84"><path d="M249.62,50.46c65.4,0,73.14.25,99,1.43C372.47,53,385.44,57,394.07,60.32a75.88,75.88,0,0,1,28.16,18.32,75.88,75.88,0,0,1,18.32,28.16c3.35,8.63,7.34,21.6,8.43,45.48,1.18,25.83,1.43,33.57,1.43,99s-0.25,73.14-1.43,99c-1.09,23.88-5.08,36.85-8.43,45.48a81.11,81.11,0,0,1-46.48,46.48c-8.63,3.35-21.6,7.34-45.48,8.43-25.82,1.18-33.57,1.43-99,1.43s-73.15-.25-99-1.43c-23.88-1.09-36.85-5.08-45.48-8.43A75.88,75.88,0,0,1,77,423.86,75.88,75.88,0,0,1,58.69,395.7c-3.35-8.63-7.34-21.6-8.43-45.48-1.18-25.83-1.43-33.57-1.43-99s0.25-73.14,1.43-99c1.09-23.88,5.08-36.85,8.43-45.48A75.88,75.88,0,0,1,77,78.64a75.88,75.88,0,0,1,28.16-18.32c8.63-3.35,21.6-7.34,45.48-8.43,25.83-1.18,33.57-1.43,99-1.43m0-44.13c-66.52,0-74.86.28-101,1.47s-43.87,5.33-59.45,11.38A120.06,120.06,0,0,0,45.81,47.44,120.06,120.06,0,0,0,17.56,90.82C11.5,106.4,7.36,124.2,6.17,150.27s-1.47,34.46-1.47,101,0.28,74.86,1.47,101,5.33,43.87,11.38,59.45a120.06,120.06,0,0,0,28.25,43.38,120.06,120.06,0,0,0,43.38,28.25c15.58,6.05,33.38,10.19,59.45,11.38s34.46,1.47,101,1.47,74.86-.28,101-1.47,43.87-5.33,59.45-11.38a125.24,125.24,0,0,0,71.63-71.63c6.05-15.58,10.19-33.38,11.38-59.45s1.47-34.46,1.47-101-0.28-74.86-1.47-101-5.33-43.87-11.38-59.45a120.06,120.06,0,0,0-28.25-43.38,120.06,120.06,0,0,0-43.38-28.25C394.47,13.13,376.67,9,350.6,7.8s-34.46-1.47-101-1.47h0Z" transform="translate(-4.7 -6.33)" /><path d="M249.62,125.48A125.77,125.77,0,1,0,375.39,251.25,125.77,125.77,0,0,0,249.62,125.48Zm0,207.41a81.64,81.64,0,1,1,81.64-81.64A81.64,81.64,0,0,1,249.62,332.89Z" transform="translate(-4.7 -6.33)"/><circle cx="375.66" cy="114.18" r="29.39" /></symbol><symbol id="icon-linkedin" viewBox="0 0 12 14"><path d="M2.727 4.883v7.742h-2.578v-7.742h2.578zM2.891 2.492q0.008 0.57-0.395 0.953t-1.059 0.383h-0.016q-0.641 0-1.031-0.383t-0.391-0.953q0-0.578 0.402-0.957t1.051-0.379 1.039 0.379 0.398 0.957zM12 8.187v4.437h-2.57v-4.141q0-0.82-0.316-1.285t-0.988-0.465q-0.492 0-0.824 0.27t-0.496 0.668q-0.086 0.234-0.086 0.633v4.32h-2.57q0.016-3.117 0.016-5.055t-0.008-2.313l-0.008-0.375h2.57v1.125h-0.016q0.156-0.25 0.32-0.438t0.441-0.406 0.68-0.34 0.895-0.121q1.336 0 2.148 0.887t0.813 2.598z"></path></symbol><symbol id="icon-heart" viewBox="0 0 34 30"><path d="M17,29.7 L16.4,29.2 C3.5,18.7 0,15 0,9 C0,4 4,0 9,0 C13.1,0 15.4,2.3 17,4.1 C18.6,2.3 20.9,0 25,0 C30,0 34,4 34,9 C34,15 30.5,18.7 17.6,29.2 L17,29.7 Z M9,2 C5.1,2 2,5.1 2,9 C2,14.1 5.2,17.5 17,27.1 C28.8,17.5 32,14.1 32,9 C32,5.1 28.9,2 25,2 C21.5,2 19.6,4.1 18.1,5.8 L17,7.1 L15.9,5.8 C14.4,4.1 12.5,2 9,2 Z" id="Shape"></path></symbol><symbol id="icon-arrow-right" viewBox="0 0 25.452 25.452"><path d="M4.471,24.929v-2.004l12.409-9.788c0.122-0.101,0.195-0.251,0.195-0.411c0-0.156-0.073-0.31-0.195-0.409L4.471,2.526V0.522c0-0.2,0.115-0.384,0.293-0.469c0.18-0.087,0.396-0.066,0.552,0.061l15.47,12.202c0.123,0.1,0.195,0.253,0.195,0.409c0,0.16-0.072,0.311-0.195,0.411L5.316,25.34c-0.155,0.125-0.372,0.147-0.552,0.061C4.586,25.315,4.471,25.13,4.471,24.929z"/></symbol><symbol id="icon-star" viewBox="0 0 48 48"><path fill="currentColor" d="M44,24c0,11.045-8.955,20-20,20S4,35.045,4,24S12.955,4,24,4S44,12.955,44,24z"/><path fill="#ffffff" d="M24,11l3.898,7.898l8.703,1.301l-6.301,6.102l1.5,8.699L24,30.898L16.199,35l1.5-8.699l-6.301-6.102  l8.703-1.301L24,11z"/></symbol><symbol id="icon-read" viewBox="0 0 32 32"><path fill="currentColor" d="M29,4H3C1.343,4,0,5.343,0,7v18c0,1.657,1.343,3,3,3h10c0,0.552,0.448,1,1,1h4c0.552,0,1-0.448,1-1h10  c1.657,0,3-1.343,3-3V7C32,5.343,30.657,4,29,4z M29,5v20H18.708c-0.618,0-1.236,0.146-1.789,0.422l-0.419,0.21V5H29z M15.5,5  v20.632l-0.419-0.21C14.528,25.146,13.91,25,13.292,25H3V5H15.5z M31,25c0,1.103-0.897,2-2,2H18v1h-4v-1H3c-1.103,0-2-0.897-2-2V7  c0-0.737,0.405-1.375,1-1.722V25c0,0.552,0.448,1,1,1h10.292c0.466,0,0.925,0.108,1.342,0.317l0.919,0.46  c0.141,0.07,0.294,0.106,0.447,0.106c0.153,0,0.306-0.035,0.447-0.106l0.919-0.46C17.783,26.108,18.242,26,18.708,26H29  c0.552,0,1-0.448,1-1V5.278C30.595,5.625,31,6.263,31,7V25z M6,12.5C6,12.224,6.224,12,6.5,12h5c0.276,0,0.5,0.224,0.5,0.5  S11.776,13,11.5,13h-5C6.224,13,6,12.776,6,12.5z M6,14.5C6,14.224,6.224,14,6.5,14h5c0.276,0,0.5,0.224,0.5,0.5S11.776,15,11.5,15  h-5C6.224,15,6,14.776,6,14.5z M6,16.5C6,16.224,6.224,16,6.5,16h5c0.276,0,0.5,0.224,0.5,0.5S11.776,17,11.5,17h-5  C6.224,17,6,16.776,6,16.5z M20,12.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,13,25.5,13h-5  C20.224,13,20,12.776,20,12.5z M20,14.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,15,25.5,15h-5  C20.224,15,20,14.776,20,14.5z M20,16.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,17,25.5,17h-5  C20.224,17,20,16.776,20,16.5z"></path></symbol><symbol id="icon-tistory" viewBox="0 0 24 24"><path d="M4 4h16v3h-6v13h-4V7H4V4z"/></symbol></defs></svg>

        <header class="bar-header">
    <a id="menu" role="button">
        <svg id="open" class="icon-menu"><use xlink:href="#icon-menu"></use></svg>
    </a>
    <h1 class="logo">
        <a href="/">
            
                somaz <span class="version">v3.1.2</span>
            
        </a>
    </h1>
    <a id="search" class="dosearch" role="button">
        <svg class="icon-search"><use xlink:href="#icon-search"></use></svg>
    </a>
    
        <a href="https://github.com/thiagorossener/jekflix-template" class="get-theme" role="button">
            Get this theme!
        </a>
    
</header>

<div id="mask" class="overlay"></div>

<aside class="sidebar" id="sidebar">
    <nav id="navigation">
      <h2>Menu</h2>
      <ul>
  
    
      <li>
        <a href="https://somaz.blog/">Home</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/about">About</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/category">Category</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/contact">Contact</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/feed.xml">Feed</a>
      </li>
    
  
</ul>

    </nav>
</aside>

<div class="search-wrapper">
    <div class="search-form">
        <input type="text" class="search-field" placeholder="Search">
        <svg class="icon-remove-sign"><use xlink:href="#icon-close"></use></svg>
        <ul class="search-results search-list"></ul>
    </div>
</div>



        <section class="post two-columns">
            <article role="article" class="post-content">
                <p class="post-info">
                    
                        <svg class="icon-calendar" id="date"><use xlink:href="#icon-calendar"></use></svg>
                        <time class="date" datetime="2025-04-24T00:00:00+00:00">
                            


April 24, 2025

                        </time>
                    
                    <svg id="clock" class="icon-clock"><use xlink:href="#icon-clock"></use></svg>
                    <span>26 min to read</span>
                </p>
                <h1 class="post-title">OS Cache and Disk I/O - MySQL and Redis Performance Analysis</h1>
                <p class="post-subtitle">Understanding the impact of operating system caches on database performance</p>

                
                    <img src="https://res.cloudinary.com/dkcm26aem/image/upload/v1744340260/os-cache-disk_jwhgck.png" alt="Featured image" class="post-cover">
                

                <!-- Pagination links -->



                <!-- Add your table of contents here -->


                <p><br /></p>

<hr />

<h2 id="overview">Overview</h2>

<p>Operating system caching mechanisms sit at the critical intersection between application performance and hardware capabilities. While database administrators often focus on optimizing database settings and upgrading hardware, the operating system’s caching layer often has the most significant impact on real-world performance.</p>

<p>The OS cache serves as a transparent intermediary that minimizes expensive disk operations by storing recently accessed data in memory. This automatic optimization dramatically improves read and write speeds, particularly for database systems like MySQL and Redis that perform intensive I/O operations.</p>

<p><br /></p>

<div class="info-box info-box-default-not-check">
  <strong>Historical Context</strong>
  <p>Operating system caching has evolved significantly since the early days of computing. The concept of using faster memory to cache slower storage dates back to the 1960s, but modern page caching as we know it today was refined in the 1980s with the development of Unix's "unified buffer cache."</p>
  <p>Linux's page cache implementation, introduced in the early 1990s, combined with the virtual memory system to create an adaptive caching mechanism that automatically uses available memory for file system operations. This approach allowed for dramatic performance improvements without requiring application-level changes, making it one of the most important operating system optimizations for database performance.</p>
  <p>Over time, these caching mechanisms have been refined to handle evolving storage technologies, from traditional hard drives to modern SSDs and NVMe storage, with each advancement requiring adjustments to caching strategies for optimal performance.</p>
</div>

<p><br /></p>

<hr />

<h2 id="what-is-os-cache">What is OS Cache?</h2>

<p>The operating system cache is a memory management mechanism that improves I/O performance by storing recently accessed data in RAM, providing faster access than reading from or writing to physical storage devices.</p>

<div style="width: 100%; margin: auto; margin-top: 20px;">
  <div class="mermaid">
    graph LR
      A[Application] --&gt; B[System Call Interface]
      B --&gt; C{Cache Hit?}
      C --&gt;|Yes| D[Read from Page Cache]
      C --&gt;|No| E[Read from Disk]
      E --&gt; F[Store in Page Cache]
      F --&gt; D
      D --&gt; A
      
      style A fill:#f9f9f9,stroke:#333,stroke-width:1px
      style D fill:#d4f7d4,stroke:#333,stroke-width:1px
      style E fill:#f7d4d4,stroke:#333,stroke-width:1px
  </div>
</div>

<p><br /></p>

<h3 id="types-of-os-caches">Types of OS Caches</h3>

<table class="table-beauty">
  <tr>
    <th style="width: 20%;">Type</th>
    <th style="width: 40%;">Description</th>
    <th style="width: 40%;">How It Works</th>
  </tr>
  <tr>
    <td>Page Cache</td>
    <td>Memory area that stores file contents to minimize disk reads</td>
    <td>When a file is read, the OS copies pages into memory. Subsequent reads use cached data instead of accessing disk.</td>
  </tr>
  <tr>
    <td>Buffer Cache</td>
    <td>Memory area that temporarily holds data before writing to disk</td>
    <td>Write operations are stored in memory and flushed to disk asynchronously (delayed write), improving application performance.</td>
  </tr>
  <tr>
    <td>Dirty Pages</td>
    <td>Pages in memory that have been modified but not yet written to disk</td>
    <td>System tracks modified pages and periodically flushes them to disk based on time thresholds or when memory pressure increases.</td>
  </tr>
  <tr>
    <td>inode Cache</td>
    <td>Cache for file metadata structures</td>
    <td>Stores file attributes and locations to avoid filesystem metadata lookups.</td>
  </tr>
  <tr>
    <td>dentry Cache</td>
    <td>Cache for directory entry lookups</td>
    <td>Speeds up pathname resolution by storing recently used directory structures.</td>
  </tr>
</table>

<p><br /></p>

<h3 id="how-page-cache-works">How Page Cache Works</h3>

<p>When an application reads a file, the operating system follows these steps:</p>

<ol>
  <li>Check if the requested data exists in the page cache</li>
  <li>If found (cache hit), return data directly from memory</li>
  <li>If not found (cache miss), read the data from disk into the page cache</li>
  <li>Return the data from the cache to the application</li>
</ol>

<p>This process is transparent to applications, which simply make standard file I/O calls without needing to know about the cache.</p>

<p><br /></p>

<script src="https://gist.github.com/somaz94/2b7a89acaccb4361f631d6f478615e5f.js"></script>

<p><br /></p>

<h3 id="page-cache-management-in-linux">Page Cache Management in Linux</h3>

<p>Linux dynamically manages the page cache size based on memory pressure. It tries to use as much available memory as possible for caching, but will reclaim cache pages when applications need more memory.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># View current memory usage including cache</span>
free <span class="nt">-m</span>

<span class="c"># Example output:</span>
<span class="c">#               total        used        free      shared  buff/cache   available</span>
<span class="c"># Mem:          16384        4096        2048          64       10240        8192</span>
<span class="c"># Swap:          4096           0        4096</span>
</code></pre></div></div>

<p>In this output:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">buff/cache</code> shows memory used for the buffer cache and page cache</li>
  <li><code class="language-plaintext highlighter-rouge">available</code> shows memory that can be allocated to processes without swapping</li>
</ul>

<p><br /></p>

<h3 id="cache-flushing-mechanisms">Cache Flushing Mechanisms</h3>

<p>For data consistency and durability, Linux needs to write dirty pages back to disk. This happens through several mechanisms:</p>

<ol>
  <li><strong>Background Flush</strong>: The <code class="language-plaintext highlighter-rouge">pdflush</code> (older kernels) or <code class="language-plaintext highlighter-rouge">flusher</code> threads periodically write dirty pages to disk</li>
  <li><strong>Explicit Sync</strong>: Applications can call <code class="language-plaintext highlighter-rouge">fsync()</code>, <code class="language-plaintext highlighter-rouge">fdatasync()</code>, or <code class="language-plaintext highlighter-rouge">sync()</code> to force data to be written to disk</li>
  <li><strong>Memory Pressure</strong>: When memory is needed for other purposes, dirty pages may be written to disk</li>
  <li><strong>Age-Based Flush</strong>: Pages are written after being dirty for a certain time period</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># View current dirty page settings</span>
<span class="nb">cat</span> /proc/sys/vm/dirty_background_ratio
<span class="nb">cat</span> /proc/sys/vm/dirty_ratio
<span class="nb">cat</span> /proc/sys/vm/dirty_expire_centisecs
<span class="nb">cat</span> /proc/sys/vm/dirty_writeback_centisecs

<span class="c"># Example: Manually trigger sync to flush dirty pages</span>
<span class="nb">sync</span>
</code></pre></div></div>

<h3 id="direct-io-vs-cached-io">Direct I/O vs Cached I/O</h3>

<p>Some applications bypass the page cache for specific reasons:</p>

<p><br /></p>

<script src="https://gist.github.com/somaz94/be642caf5f1fe376e103c2fff99c8119.js"></script>

<p><br /></p>

<p>Bypassing the cache might be preferred when:</p>
<ul>
  <li>The application maintains its own cache (like MySQL’s InnoDB Buffer Pool)</li>
  <li>Predictable I/O latency is more important than throughput</li>
  <li>Very large sequential scans would push useful data out of cache</li>
</ul>

<p><br /></p>

<hr />

<h2 id="when-caching-doesnt-work-well">When Caching Doesn’t Work Well</h2>

<p>While the operating system’s caching mechanisms generally provide significant performance benefits, several scenarios can reduce or negate these advantages.</p>

<table class="table-beauty">
  <tr>
    <th style="width: 20%;">Situation</th>
    <th style="width: 40%;">Description</th>
    <th style="width: 40%;">Impact and Solutions</th>
  </tr>
  <tr>
    <td>Manual Cache Clearing</td>
    <td>Frequent execution of <code>drop_caches</code> or system reboots</td>
    <td>Causes "cold cache" performance, requiring disk reads for all data. <br /><strong>Solution:</strong> Avoid scheduled cache clearing; allow the OS to manage cache.</td>
  </tr>
  <tr>
    <td>Memory Pressure</td>
    <td>System memory is filled by applications, leaving little for cache</td>
    <td>OS reclaims cache pages for application use, reducing cache hit rate. <br /><strong>Solution:</strong> Add RAM or tune memory allocation between applications.</td>
  </tr>
  <tr>
    <td>Direct I/O Usage</td>
    <td>Applications bypassing kernel cache (O_DIRECT flag)</td>
    <td>Eliminates double-buffering but loses OS cache benefits. <br /><strong>Solution:</strong> Only use if application has custom caching.</td>
  </tr>
  <tr>
    <td>Random Access Pattern</td>
    <td>Non-sequential access to data across large datasets</td>
    <td>Lower spatial locality reduces prefetching effectiveness. <br /><strong>Solution:</strong> Improve data locality in application design.</td>
  </tr>
  <tr>
    <td>Working Set &gt; RAM</td>
    <td>Active dataset exceeds available memory</td>
    <td>Frequent cache evictions leading to high disk I/O. <br /><strong>Solution:</strong> Add RAM or partition workloads.</td>
  </tr>
  <tr>
    <td>Inappropriate Readahead</td>
    <td>Default readahead settings unsuitable for workload</td>
    <td>Cache filled with unused data or insufficient prefetching. <br /><strong>Solution:</strong> Tune <code>blockdev --setra</code> for workload.</td>
  </tr>
  <tr>
    <td>Cache Thrashing</td>
    <td>Working set slightly exceeds available memory</td>
    <td>Continuous cycle of cache fills and evictions. <br /><strong>Solution:</strong> Tune application or increase RAM.</td>
  </tr>
  <tr>
    <td>Inappropriate Cache Flush Settings</td>
    <td>Poorly configured dirty page write parameters</td>
    <td>Too-frequent or too-infrequent disk writes. <br /><strong>Solution:</strong> Tune VM dirty page parameters.</td>
  </tr>
</table>

<h3 id="case-study-cache-clearing-impact-on-database-performance">Case Study: Cache Clearing Impact on Database Performance</h3>

<p>The following graph demonstrates the performance impact of clearing the OS cache on a MySQL database server:</p>

<p><br /></p>

<script src="https://gist.github.com/somaz94/4614b18983d0e05baa141f75e547736e.js"></script>

<p><br /></p>

<p>When the cache is cleared, transaction performance drops dramatically until the working set is reloaded into memory.</p>

<p><br /></p>

<h3 id="testing-cache-impact-on-your-system">Testing Cache Impact on Your System</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="c"># Script to demonstrate cache impact on file read performance</span>

<span class="nv">FILE_PATH</span><span class="o">=</span><span class="s2">"/path/to/large/file"</span>  <span class="c"># Should be at least 1GB</span>
<span class="nv">ITERATIONS</span><span class="o">=</span>3

<span class="nb">echo</span> <span class="s2">"Testing read performance with OS cache:"</span>

<span class="c"># Drop caches first to start with clean state</span>
<span class="nb">echo</span> <span class="s2">"Dropping caches..."</span>
<span class="nb">sudo sync
sudo </span>bash <span class="nt">-c</span> <span class="s2">"echo 3 &gt; /proc/sys/vm/drop_caches"</span>

<span class="k">for </span>i <span class="k">in</span> <span class="si">$(</span><span class="nb">seq </span>1 <span class="nv">$ITERATIONS</span><span class="si">)</span><span class="p">;</span> <span class="k">do
    </span><span class="nb">echo</span> <span class="s2">"Read </span><span class="nv">$i</span><span class="s2">:"</span>
    <span class="nb">time cat</span> <span class="nv">$FILE_PATH</span> <span class="o">&gt;</span> /dev/null
<span class="k">done

</span><span class="nb">echo</span> <span class="s2">"Note the significant speed improvement after the first read"</span>
<span class="nb">echo</span> <span class="s2">"This demonstrates the OS cache effect"</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="common-cache-tuning-parameters">Common Cache Tuning Parameters</h3>

<p>For workloads where the default caching behavior isn’t optimal, Linux provides several tuning parameters:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Control how aggressive the kernel reclaims memory </span>
<span class="c"># (0-100, higher = favor cache retention)</span>
<span class="nb">echo </span>10 <span class="o">&gt;</span> /proc/sys/vm/swappiness

<span class="c"># Control dirty page thresholds (as % of total memory)</span>
<span class="nb">echo </span>10 <span class="o">&gt;</span> /proc/sys/vm/dirty_background_ratio  <span class="c"># Start background flushing</span>
<span class="nb">echo </span>20 <span class="o">&gt;</span> /proc/sys/vm/dirty_ratio             <span class="c"># Force synchronous flushes</span>

<span class="c"># Control how long dirty pages can stay in memory (in centiseconds)</span>
<span class="nb">echo </span>3000 <span class="o">&gt;</span> /proc/sys/vm/dirty_expire_centisecs  <span class="c"># 30 seconds</span>

<span class="c"># Readahead setting for specific device (in 512-byte sectors)</span>
blockdev <span class="nt">--setra</span> 256 /dev/sda  <span class="c"># 128KB readahead</span>
</code></pre></div></div>

<p><br /></p>

<h2 id="disk-io-vs-cache-access-speed-comparison">Disk I/O vs Cache Access Speed Comparison</h2>

<p>The performance gap between memory and storage devices is one of the largest disparities in computer architecture, making caching essential for system performance.</p>

<table class="table-beauty">
  <tr>
    <th style="width: 20%;">Storage Type</th>
    <th style="width: 15%;">Avg. Access Time</th>
    <th style="width: 15%;">Unit</th>
    <th style="width: 15%;">Relative Speed</th>
    <th style="width: 35%;">Practical Impact</th>
  </tr>
  <tr>
    <td>CPU L1 Cache</td>
    <td>0.5-1 ns</td>
    <td>nanoseconds</td>
    <td>1x</td>
    <td>Reference point (fastest)</td>
  </tr>
  <tr>
    <td>CPU L2 Cache</td>
    <td>3-7 ns</td>
    <td>nanoseconds</td>
    <td>~5x slower</td>
    <td>Still extremely fast, small capacity (KB to MB)</td>
  </tr>
  <tr>
    <td>CPU L3 Cache</td>
    <td>10-20 ns</td>
    <td>nanoseconds</td>
    <td>~15x slower</td>
    <td>Shared among CPU cores, larger capacity</td>
  </tr>
  <tr>
    <td>Main Memory (RAM)</td>
    <td>50-100 ns</td>
    <td>nanoseconds</td>
    <td>~100x slower</td>
    <td>OS cache uses RAM, 100-1000x faster than best SSDs</td>
  </tr>
  <tr>
    <td>NVMe SSD</td>
    <td>10-20 μs</td>
    <td>microseconds</td>
    <td>~10,000x slower</td>
    <td>Fastest storage, but still orders of magnitude slower than RAM</td>
  </tr>
  <tr>
    <td>SATA SSD</td>
    <td>50-150 μs</td>
    <td>microseconds</td>
    <td>~100,000x slower</td>
    <td>Common SSD type, latency constrained by SATA interface</td>
  </tr>
  <tr>
    <td>HDD (7200 RPM)</td>
    <td>5-10 ms</td>
    <td>milliseconds</td>
    <td>~10,000,000x slower</td>
    <td>Mechanical seek time dominates, 50-100x slower than SSDs</td>
  </tr>
  <tr>
    <td>Network Storage</td>
    <td>5-50+ ms</td>
    <td>milliseconds</td>
    <td>~10,000,000x+ slower</td>
    <td>Network latency adds significant overhead</td>
  </tr>
</table>

<p><br /></p>

<h3 id="visualizing-the-speed-difference">Visualizing the Speed Difference</h3>

<p>To put these differences in perspective, if we were to scale these times to human-relatable units, where RAM access is represented as 1 second:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CPU L1 Cache: 10 milliseconds <span class="o">(</span>quick eye blink<span class="o">)</span>
RAM: 1 second <span class="o">(</span>heartbeat<span class="o">)</span>
NVMe SSD: 2-5 minutes <span class="o">(</span>short <span class="nb">break</span><span class="o">)</span>
SATA SSD: 10-25 minutes <span class="o">(</span>coffee <span class="nb">break</span><span class="o">)</span>
HDD: 14-28 hours <span class="o">(</span>more than a day<span class="o">)</span>
</code></pre></div></div>

<p>This enormous performance gap makes caching critical for system performance.</p>

<p><br /></p>

<h3 id="measuring-io-vs-cache-performance">Measuring I/O vs Cache Performance</h3>

<p>You can measure and compare disk I/O versus cache performance on your system using tools like:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Install necessary tools</span>
apt-get <span class="nb">install </span>fio sysstat

<span class="c"># Create test file and bypass cache for accurate disk timing</span>
<span class="nb">dd </span><span class="k">if</span><span class="o">=</span>/dev/zero <span class="nv">of</span><span class="o">=</span>test_file <span class="nv">bs</span><span class="o">=</span>1M <span class="nv">count</span><span class="o">=</span>1024 <span class="nv">oflag</span><span class="o">=</span>direct

<span class="c"># Run disk read test (bypassing cache)</span>
fio <span class="nt">--name</span><span class="o">=</span>disk_read <span class="nt">--filename</span><span class="o">=</span>test_file <span class="nt">--direct</span><span class="o">=</span>1 <span class="nt">--rw</span><span class="o">=</span><span class="nb">read</span> <span class="nt">--bs</span><span class="o">=</span>4k <span class="nt">--size</span><span class="o">=</span>1G <span class="nt">--numjobs</span><span class="o">=</span>1 <span class="nt">--time_based</span> <span class="nt">--runtime</span><span class="o">=</span>60 <span class="nt">--group_reporting</span>

<span class="c"># Run cached read test (after file is cached)</span>
<span class="c"># First read it to ensure it's in cache</span>
<span class="nb">cat </span>test_file <span class="o">&gt;</span> /dev/null
<span class="c"># Then measure cached performance</span>
fio <span class="nt">--name</span><span class="o">=</span>cached_read <span class="nt">--filename</span><span class="o">=</span>test_file <span class="nt">--direct</span><span class="o">=</span>0 <span class="nt">--rw</span><span class="o">=</span><span class="nb">read</span> <span class="nt">--bs</span><span class="o">=</span>4k <span class="nt">--size</span><span class="o">=</span>1G <span class="nt">--numjobs</span><span class="o">=</span>1 <span class="nt">--time_based</span> <span class="nt">--runtime</span><span class="o">=</span>60 <span class="nt">--group_reporting</span>
</code></pre></div></div>

<p>The results will typically show:</p>
<ul>
  <li>Disk read: 50-500 MB/s depending on storage type</li>
  <li>Cached read: 5,000-50,000+ MB/s depending on RAM speed and CPU</li>
</ul>

<p><br /></p>

<h3 id="database-performance-impact">Database Performance Impact</h3>

<p>For database systems like MySQL and Redis, this speed difference translates directly to performance metrics:</p>

<ul>
  <li><strong>Cold cache</strong>: TPS (transactions per second) can be 10-100x lower</li>
  <li><strong>Warm cache</strong>: Operations are primarily memory-bound, not I/O-bound</li>
  <li><strong>Cache hits</strong>: Can support thousands more concurrent users with the same hardware</li>
</ul>

<p>The database performance curve is typically non-linear with cache hit rate - a small decrease in cache hit rate from 99% to 95% might halve overall performance, while a drop from 95% to 80% might cause a 10x performance degradation.</p>

<p><br /></p>

<hr />

<h2 id="mysql-buffer-pool-vs-os-cache">MySQL: Buffer Pool vs OS Cache</h2>

<p>MySQL’s InnoDB storage engine implements a buffer pool that caches frequently accessed data and index pages in memory. However, this is just one layer in a multi-tiered caching system that ultimately includes the OS cache.</p>

<p><br /></p>

<div style="width: 100%; margin: auto; margin-top: 20px;">
  <div class="mermaid">
    graph LR
      A[SQL Query] --&gt; B[MySQL Query Cache]
      B --&gt;|Cache Miss| C[InnoDB Buffer Pool]
      C --&gt;|Cache Miss| D[OS Page Cache]
      D --&gt;|Cache Miss| E[Storage Device]
      
      style B fill:#d4e6f7,stroke:#333,stroke-width:1px
      style C fill:#d4e6f7,stroke:#333,stroke-width:1px
      style D fill:#d4e6f7,stroke:#333,stroke-width:1px
      style E fill:#f7d4d4,stroke:#333,stroke-width:1px
  </div>
</div>

<p><br /></p>

<h3 id="buffer-pool-architecture">Buffer Pool Architecture</h3>

<p>The InnoDB buffer pool is MySQL’s memory area for caching table and index data. It operates as follows:</p>

<ol>
  <li>Requested data pages are first looked up in the buffer pool</li>
  <li>If not found, they’re read from disk and placed in the buffer pool</li>
  <li>When the buffer pool is full, least recently used (LRU) pages are evicted</li>
</ol>

<p><br /></p>

<script src="https://gist.github.com/somaz94/845e147af2842189bde8932be0b829fb.js"></script>

<p><br /></p>

<h3 id="os-cache-role-in-mysql-performance">OS Cache Role in MySQL Performance</h3>

<p>Even with a well-sized buffer pool, MySQL still relies on the OS cache for several reasons:</p>

<ol>
  <li><strong>Data accessed through non-InnoDB storage engines</strong> (e.g., MyISAM)</li>
  <li><strong>Binary logs, redo logs, and other system files</strong></li>
  <li><strong>Data not in the buffer pool</strong> (cold data or after buffer pool eviction)</li>
  <li><strong>Temporary tables and sort files</strong></li>
</ol>

<p><br /></p>

<h3 id="disk-read-metrics-analysis">Disk Read Metrics Analysis</h3>

<p>Monitoring disk read operations helps understand how your MySQL instance is utilizing caches:</p>

<p><br /></p>

<script src="https://gist.github.com/somaz94/834f82b22efc5235d5892cae6b26fc5b.js"></script>

<p><br /></p>

<p>A high hit ratio (&gt;99%) suggests effective buffer pool usage, but doesn’t give the full picture of OS cache usage.</p>

<p><br /></p>

<h3 id="o_direct-flag-and-its-impact">O_DIRECT Flag and Its Impact</h3>

<p>MySQL can be configured to use direct I/O, bypassing the OS cache:</p>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># MySQL configuration for direct I/O
</span><span class="nn">[mysqld]</span>
<span class="py">innodb_flush_method</span><span class="p">=</span><span class="s">O_DIRECT</span>
</code></pre></div></div>

<p>This configuration has important trade-offs:</p>

<table class="table-beauty">
  <tr>
    <th>Aspect</th>
    <th>With OS Cache</th>
    <th>With O_DIRECT</th>
  </tr>
  <tr>
    <td>Memory Usage</td>
    <td>Data potentially cached twice (buffer pool and OS cache)</td>
    <td>More efficient memory usage (no double-buffering)</td>
  </tr>
  <tr>
    <td>Read Performance</td>
    <td>Cold data may be in OS cache even if not in buffer pool</td>
    <td>All cache misses go directly to disk</td>
  </tr>
  <tr>
    <td>Write Control</td>
    <td>OS controls write flushing (potentially unpredictable)</td>
    <td>MySQL controls write timing (more predictable)</td>
  </tr>
  <tr>
    <td>Best For</td>
    <td>Systems where MySQL is the primary application</td>
    <td>Systems with multiple applications competing for memory</td>
  </tr>
</table>

<p><br /></p>

<h3 id="optimizing-mysql-with-proper-buffer-pool-and-os-cache-configuration">Optimizing MySQL with Proper Buffer Pool and OS Cache Configuration</h3>

<p>The key to optimal MySQL performance is balancing buffer pool size and allowing sufficient memory for the OS cache:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Example optimal memory allocation for a database server with 64GB RAM</span>
<span class="c"># MySQL Buffer Pool: 48GB (75%)</span>
<span class="c"># OS and other processes: 4GB</span>
<span class="c"># OS Cache available: 12GB</span>

<span class="c"># MySQL configuration</span>
innodb_buffer_pool_size <span class="o">=</span> 48G
innodb_buffer_pool_instances <span class="o">=</span> 8  <span class="c"># One per CPU core up to 8</span>

<span class="c"># Monitor actual memory usage</span>
free <span class="nt">-m</span>
vmstat 1
</code></pre></div></div>

<p><br /></p>

<h3 id="practical-case-studies-and-solutions">Practical Case Studies and Solutions</h3>

<h4 id="case-study-1-mysql-performance-degradation-after-midnight">Case Study 1: MySQL Performance Degradation After Midnight</h4>

<p><br /></p>

<p><strong>Problem:</strong>
A production MySQL database experienced significant performance degradation every night at midnight, with query latency increasing by 10x and disk I/O spikes.</p>

<p><strong>Investigation:</strong></p>
<ul>
  <li>Monitoring showed an increase in both buffer pool misses and disk reads</li>
  <li>OS monitoring revealed a scheduled script executed <code class="language-plaintext highlighter-rouge">echo 3 &gt; /proc/sys/vm/drop_caches</code> as part of cleanup automation</li>
  <li>This cleared both the OS cache and caused cold reads for data not in the buffer pool</li>
</ul>

<p><strong>Solution:</strong></p>
<h4 id="1-removed-the-drop_caches-command-from-the-cleanup-script">1. Removed the <code class="language-plaintext highlighter-rouge">drop_caches</code> command from the cleanup script</h4>
<h4 id="2-implemented-proper-buffer-pool-dumping-and-loading">2. Implemented proper buffer pool dumping and loading:</h4>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Added to MySQL configuration
</span><span class="py">innodb_buffer_pool_dump_at_shutdown</span> <span class="p">=</span> <span class="s">1</span>
<span class="py">innodb_buffer_pool_load_at_startup</span> <span class="p">=</span> <span class="s">1</span>
</code></pre></div></div>

<h4 id="3-added-monitoring-for-buffer-pool-and-os-cache-hit-rates">3. Added monitoring for buffer pool and OS cache hit rates</h4>

<p><strong>Result:</strong></p>
<ul>
  <li>Overnight performance stabilized with no noticeable latency spikes</li>
  <li>Cold starts after planned maintenance were also improved</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Script to warm up MySQL cache after planned maintenance</span>
mysql <span class="nt">-e</span> <span class="s2">"SELECT COUNT(*) FROM important_table WHERE last_accessed &gt; DATE_SUB(NOW(), INTERVAL 1 DAY)"</span>
</code></pre></div></div>

<p><br /></p>

<h4 id="case-study-2-optimizing-for-limited-memory">Case Study 2: Optimizing for Limited Memory</h4>

<p><strong>Problem:</strong>
A server with 16GB RAM running both MySQL and application services experienced high I/O wait times.</p>

<p><strong>Investigation:</strong></p>
<ul>
  <li>MySQL was configured with 12GB buffer pool</li>
  <li>Application servers required 2-3GB, leaving only 1-2GB for OS cache</li>
  <li>High I/O wait showed insufficient OS caching</li>
</ul>

<p><strong>Solution:</strong></p>
<h4 id="1-rebalanced-memory-allocation">1. Rebalanced memory allocation:</h4>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Reduced buffer pool size
</span><span class="py">innodb_buffer_pool_size</span> <span class="p">=</span> <span class="s">8G</span>
</code></pre></div></div>

<h4 id="2-optimized-mysql-query-patterns-to-work-better-with-smaller-buffer-pool">2. Optimized MySQL query patterns to work better with smaller buffer pool</h4>
<h4 id="3-added-monitoring-for-os-cache-usage">3. Added monitoring for OS cache usage</h4>

<p><strong>Result:</strong></p>
<ul>
  <li>OS Cache grew to 5-6GB</li>
  <li>Overall performance improved by 30%</li>
  <li>I/O wait decreased by 60%</li>
</ul>

<p><br /><br /></p>

<h2 id="redis-all-in-memory-but-why-cache">Redis: All In-Memory, But Why Cache?</h2>

<p>While Redis is primarily an in-memory database, it still interacts with disk for persistence features and can benefit significantly from OS cache management.</p>

<p><br /></p>

<h3 id="redis-persistence-mechanisms">Redis Persistence Mechanisms</h3>

<p>Redis offers two persistence options that interact with the OS cache:</p>

<ol>
  <li><strong>RDB (Redis Database)</strong>: Point-in-time snapshots saved to disk</li>
  <li><strong>AOF (Append-Only File)</strong>: Log of all write operations</li>
</ol>

<table class="table-beauty">
  <tr>
    <th>Feature</th>
    <th>RDB</th>
    <th>AOF</th>
  </tr>
  <tr>
    <td>Persistence Model</td>
    <td>Periodic snapshots</td>
    <td>Write-ahead log</td>
  </tr>
  <tr>
    <td>OS Cache Impact</td>
    <td>Large writes during save, benefits from write-back cache</td>
    <td>Continuous small writes, OS cache crucial for performance</td>
  </tr>
  <tr>
    <td>Fsync Frequency</td>
    <td>Only at end of save operation</td>
    <td>Configurable: never, every second, or every write</td>
  </tr>
  <tr>
    <td>Recovery Performance</td>
    <td>Faster load (binary format)</td>
    <td>Slower (must replay operations)</td>
  </tr>
</table>

<p><br /></p>

<h3 id="aof-and-os-cache-interaction">AOF and OS Cache Interaction</h3>

<p>With AOF enabled, Redis writes operations to a file, but the actual disk flush depends on the <code class="language-plaintext highlighter-rouge">appendfsync</code> setting:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Redis configuration options
appendonly yes
appendfsync everysec  # Options: no, everysec, always
</code></pre></div></div>

<p>The OS cache’s role in each setting:</p>

<ol>
  <li><strong>appendfsync no</strong>: Redis never calls fsync, relying entirely on OS cache to flush dirty pages</li>
  <li><strong>appendfsync everysec</strong>: Redis calls fsync every second, but writes first go to OS cache</li>
  <li><strong>appendfsync always</strong>: Redis calls fsync after every write, minimizing OS cache role but dramatically reducing performance</li>
</ol>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Performance: no &gt; everysec &gt; always
Durability: always &gt; everysec &gt; no
</code></pre></div></div>

<p><br /></p>

<h3 id="case-study-redis-aof-write-delay">Case Study: Redis AOF Write Delay</h3>

<h4 id="problem">Problem:</h4>
<p>A Redis server with AOF enabled experienced periodic “freeze” moments where all operations would block for several seconds.</p>

<h4 id="investigation">Investigation:</h4>
<ul>
  <li>AOF file had grown to several GB</li>
  <li><code class="language-plaintext highlighter-rouge">vm.dirty_ratio</code> was set to default 20%</li>
  <li>During peak write periods, dirty pages accumulated until hitting the threshold</li>
  <li>When threshold was reached, the kernel forced synchronous flushes, blocking Redis</li>
</ul>

<h4 id="solution">Solution:</h4>

<h4 id="1-adjusted-linux-kernel-parameters">1. Adjusted Linux kernel parameters:</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Lower threshold for background flushing</span>
<span class="nb">echo </span>5 <span class="o">&gt;</span> /proc/sys/vm/dirty_background_ratio

<span class="c"># Set longer expiration for dirty pages</span>
<span class="nb">echo </span>10000 <span class="o">&gt;</span> /proc/sys/vm/dirty_expire_centisecs
</code></pre></div></div>

<h4 id="2-implemented-scheduled-aof-rewrites-and-monitoring">2. Implemented scheduled AOF rewrites and monitoring:</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Add to crontab</span>
0 3 <span class="k">*</span> <span class="k">*</span> <span class="k">*</span> redis-cli BGREWRITEAOF

<span class="c"># Monitor AOF size</span>
redis-cli info persistence | <span class="nb">grep </span>aof_current_size
</code></pre></div></div>

<h4 id="3-added-higher-performance-storage-for-the-aof-file">3. Added higher-performance storage for the AOF file</h4>

<p><strong>Result:</strong></p>
<ul>
  <li>Background flushing prevented accumulation of excessive dirty pages</li>
  <li>Redis operations remained responsive even during high write periods</li>
  <li>Scheduled rewrites kept AOF size manageable</li>
</ul>

<p><br /></p>

<h3 id="redis-and-memory-pressure">Redis and Memory Pressure</h3>

<p>Even though Redis is an in-memory database, system memory pressure can still affect performance:</p>

<ol>
  <li>When memory is scarce, the OS may prioritize application memory over cache</li>
  <li>Background saves (BGSAVE) require additional memory, potentially causing swapping</li>
  <li>AOF rewrites also need memory to create the new file</li>
</ol>

<h4 id="monitoring-redis-memory-and-os-cache-interaction">Monitoring Redis Memory and OS Cache Interaction:</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Check Redis memory usage</span>
redis-cli info memory

<span class="c"># Check system memory including cache</span>
free <span class="nt">-m</span>

<span class="c"># Watch for Redis swapping</span>
redis-cli info stats | <span class="nb">grep </span>total_swap
</code></pre></div></div>

<p><br /></p>

<div class="info-box info-box-default">
  <strong>📊 Key Performance Metrics to Monitor</strong>
  <ul>
    <li>
      <strong>MySQL</strong><br />
      - Buffer pool hit rate (&gt;99% is excellent)<br />
      - InnoDB buffer pool reads vs read requests<br />
      - Disk I/O wait percentage<br />
      - Table and index size vs buffer pool size
    </li>
    <li>
      <strong>Redis</strong><br />
      - AOF rewrite duration and frequency<br />
      - OS dirty page ratio during writes<br />
      - fsync duration (available in Redis logs when spikes occur)<br />
      - Memory fragmentation ratio
    </li>
    <li>
      <strong>OS Cache</strong><br />
      - Available memory vs cache size<br />
      - Dirty page ratio and flush patterns<br />
      - I/O wait percentage<br />
      - Read vs write IOPS
    </li>
  </ul>
</div>

<p><br /></p>

<div class="info-box info-box-default-not-check">
  <strong>Cache Warming Strategies</strong>
  <p>After system reboots or cache clearing events, databases will experience "cold cache" performance until the working set is loaded into memory. Cache warming can significantly reduce the performance impact:</p>
  <ul>
    <li><strong>MySQL</strong>: Use buffer pool dump/load for InnoDB, or run queries that select commonly accessed data</li>
    <li><strong>Redis</strong>: Load data through scripts that access frequently used keys</li>
    <li><strong>OS Cache</strong>: Read important database files sequentially before accepting application traffic</li>
  </ul>
  <p>Example MySQL cache warming script:</p>
  <pre>
  #!/bin/bash
  # MySQL cache warming script
  mysql -e "SELECT * FROM (SELECT id FROM popular_table ORDER BY last_accessed DESC LIMIT 10000) t"
  mysql -e "SELECT * FROM (SELECT id FROM common_reference_table) t"
  </pre>
</div>

<p><br /></p>

<h3 id="practical-example-monitoring-cache-hit-rate">Practical Example: Monitoring Cache Hit Rate</h3>

<p>Monitoring tools play a crucial role in understanding cache behavior:</p>

<h4 id="os-cache-status">OS Cache Status:</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># View memory usage including cache</span>
free <span class="nt">-h</span>

<span class="c"># More detailed cache information</span>
<span class="nb">cat</span> /proc/meminfo | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'Cached|Buffers|Dirty|Writeback'</span>

<span class="c"># Monitor I/O wait percentage - indicator of cache efficiency</span>
top
<span class="c"># or</span>
vmstat 1
</code></pre></div></div>

<h4 id="mysql-cache-monitoring">MySQL Cache Monitoring:</h4>

<p><br /></p>

<script src="https://gist.github.com/somaz94/1ed422de9d3f44106dae182f5cf90648.js"></script>

<p><br /></p>

<h4 id="redis-cache-monitoring">Redis Cache Monitoring:</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Monitor Redis memory usage</span>
redis-cli info memory | <span class="nb">grep </span>used_memory

<span class="c"># Monitor AOF status</span>
redis-cli info persistence | <span class="nb">grep </span>aof

<span class="c"># Check background save status</span>
redis-cli info persistence | <span class="nb">grep </span>rdb
</code></pre></div></div>

<p><br /></p>

<hr />

<h2 id="advanced-cache-optimization-techniques">Advanced Cache Optimization Techniques</h2>

<p>Beyond the basic understanding of OS cache and its interaction with databases, several advanced techniques can further optimize system performance.</p>

<p><br /></p>

<h3 id="cache-prefetching">Cache Prefetching</h3>

<p>Cache prefetching involves reading data into memory before it’s actually requested, improving performance for sequential operations:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Enable and configure readahead for a specific block device</span>
<span class="nb">sudo </span>blockdev <span class="nt">--setra</span> 4096 /dev/sda  <span class="c"># 2MB readahead (4096 * 512 bytes)</span>

<span class="c"># Check current readahead settings</span>
<span class="nb">sudo </span>blockdev <span class="nt">--getra</span> /dev/sda
</code></pre></div></div>

<h4 id="application-level-prefetching">Application-level prefetching:</h4>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- MySQL query that prefetches data for upcoming operations</span>
<span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">users</span> <span class="k">WHERE</span> <span class="n">last_active</span> <span class="o">&gt;</span> <span class="n">DATE_SUB</span><span class="p">(</span><span class="n">NOW</span><span class="p">(),</span> <span class="n">INTERVAL</span> <span class="mi">1</span> <span class="k">DAY</span><span class="p">)</span> <span class="k">LIMIT</span> <span class="mi">10000</span><span class="p">;</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="filesystem-selection-for-caching-behavior">Filesystem Selection for Caching Behavior</h3>

<p>Different filesystems have different caching characteristics:</p>

<table class="table-beauty">
  <tr>
    <th>Filesystem</th>
    <th>Cache Behavior</th>
    <th>Best For</th>
  </tr>
  <tr>
    <td>ext4</td>
    <td>Good balance of metadata and data caching</td>
    <td>General-purpose database servers</td>
  </tr>
  <tr>
    <td>XFS</td>
    <td>Excellent for large files, metadata performance</td>
    <td>Large database files, high concurrency</td>
  </tr>
  <tr>
    <td>ZFS</td>
    <td>Adaptive Read Cache (ARC) with its own caching layer</td>
    <td>Systems with large RAM and varied workloads</td>
  </tr>
  <tr>
    <td>Btrfs</td>
    <td>Good metadata caching, COW can impact caching performance</td>
    <td>Systems where data integrity is top priority</td>
  </tr>
</table>

<p><br /></p>

<h3 id="numa-cache-considerations">Numa Cache Considerations</h3>

<p>On multi-socket servers, Non-Uniform Memory Access (NUMA) can significantly impact cache performance:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># View NUMA topology</span>
numactl <span class="nt">--hardware</span>

<span class="c"># Run MySQL with NUMA awareness</span>
numactl <span class="nt">--interleave</span><span class="o">=</span>all mysqld

<span class="c"># MySQL NUMA configuration</span>
<span class="o">[</span>mysqld]
<span class="nv">innodb_numa_interleave</span><span class="o">=</span>1
</code></pre></div></div>

<p><br /></p>

<h3 id="cache-partitioning">Cache Partitioning</h3>

<p>For systems with multiple applications, cache partitioning can prevent one application from dominating the cache:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Create separate mount points for different applications</span>
mount <span class="nt">-o</span> <span class="nv">size</span><span class="o">=</span>4G <span class="nt">-t</span> tmpfs tmpfs /mnt/mysql_tmpfs
mount <span class="nt">-o</span> <span class="nv">size</span><span class="o">=</span>2G <span class="nt">-t</span> tmpfs tmpfs /mnt/redis_tmpfs

<span class="c"># Move specific files to the partitioned cache</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /mnt/mysql_tmpfs/tmp
<span class="nb">ln</span> <span class="nt">-s</span> /mnt/mysql_tmpfs/tmp /var/lib/mysql/tmp
</code></pre></div></div>

<p><br /></p>

<div class="info-box info-box-default-not-check">
  <strong>Common OS Cache Misconceptions</strong>
  <ul>
    <li>
      <strong>Myth: "Free memory is wasted memory"</strong><br />
      Reality: The OS automatically uses free memory for caching, but having some free memory is important for new allocations without forcing cache evictions
    </li>
    <li>
      <strong>Myth: "Disabling OS cache with O_DIRECT always improves database performance"</strong><br />
      Reality: O_DIRECT can reduce double-buffering, but eliminates beneficial effects of OS cache for cold data, system files, and other I/O
    </li>
    <li>
      <strong>Myth: "Adding RAM always improves performance"</strong><br />
      Reality: Once your working set fits in memory (buffer pool + OS cache), additional RAM provides diminishing returns
    </li>
    <li>
      <strong>Myth: "SSDs eliminate the need for caching"</strong><br />
      Reality: Even NVMe SSDs are orders of magnitude slower than RAM; caching remains essential
    </li>
  </ul>
</div>

<p><br /></p>

<h2 id="conclusion">Conclusion</h2>

<p>The operating system’s cache mechanism plays a pivotal role in database performance, serving as a critical layer between applications and storage devices. Our exploration has revealed how both MySQL and Redis leverage the OS cache in different ways, each with its own unique optimization considerations.</p>

<p><br /></p>

<h3 id="key-insights">Key Insights</h3>

<ol>
  <li><strong>Layered Caching Architecture</strong>: Database systems implement multiple caching layers that work together:
    <ul>
      <li>Application-level caches (e.g., Redis itself)</li>
      <li>Database engine caches (MySQL’s Buffer Pool)</li>
      <li>OS cache</li>
      <li>Storage controller caches</li>
    </ul>
  </li>
  <li>
    <p><strong>Performance Implications</strong>: The difference between memory and disk access speeds (nano vs. milliseconds) makes caching essential for performance. Even a small decrease in cache hit rates can cause dramatic performance degradation.</p>
  </li>
  <li>
    <p><strong>Cache Cooperation</strong>: For optimal performance, database settings should be configured with OS cache in mind. A well-tuned system balances memory allocation between application caches and OS cache.</p>
  </li>
  <li><strong>Monitoring Importance</strong>: Regularly monitoring cache hit rates, dirty page ratios, and I/O patterns allows for early detection of caching issues before they impact users.</li>
</ol>

<p><br /></p>

<h3 id="practical-recommendations">Practical Recommendations</h3>

<p>As we’ve seen through case studies and examples, several practical steps can ensure optimal cache performance:</p>

<ul>
  <li><strong>Balance memory allocation</strong> between database buffer pools and OS cache</li>
  <li><strong>Monitor cache metrics</strong> to identify potential issues</li>
  <li><strong>Avoid unnecessary cache clearing</strong> through automated scripts</li>
  <li><strong>Tune OS cache parameters</strong> (<code class="language-plaintext highlighter-rouge">vm.dirty_ratio</code>, <code class="language-plaintext highlighter-rouge">vm.swappiness</code>) based on workload</li>
  <li><strong>Consider filesystem and storage options</strong> that complement your caching strategy</li>
  <li><strong>Implement cache warming strategies</strong> for planned maintenance and restarts</li>
</ul>

<p><br /></p>

<h3 id="broader-implications">Broader Implications</h3>

<p>The principles of caching extend beyond databases to all computing systems. The fundamental tradeoff between speed and capacity drives the design of modern storage hierarchies from CPU registers to cloud storage.</p>

<p>Understanding how the OS cache interfaces with applications provides deeper insight into system behavior and performance optimization opportunities. For database administrators and system engineers, this knowledge is not just theoretical—it has direct, practical applications in designing high-performance, reliable systems.</p>

<p>As database technologies continue to evolve, the role of OS caching remains crucial. Even with in-memory databases, the OS cache continues to play an important role in persistence, recovery, and overall system performance.</p>

<p>Remember: “A well-used cache is often more important than fast storage.” By leveraging the OS cache effectively, you can achieve significant performance improvements without additional hardware investments.</p>

<p><br /></p>

<hr />

<h2 id="references">References</h2>

<ul>
  <li><a href="https://www.redhat.com/sysadmin/linux-page-cache">RedHat: Linux Page Cache</a></li>
  <li><a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-buffer-pool.html">MySQL Documentation: InnoDB Buffer Pool</a></li>
  <li><a href="https://redis.io/docs/management/persistence/">Redis Documentation: Persistence</a></li>
  <li><a href="https://www.kernel.org/doc/Documentation/sysctl/vm.txt">Kernel Documentation: VM Sysctl</a></li>
  <li><a href="https://blog.percona.com/understanding-innodb-buffer-pool/">Percona: Understanding InnoDB Buffer Pool</a></li>
  <li><a href="https://www.brendangregg.com/linuxperf.html">Brendan Gregg: Linux Performance</a></li>
  <li><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/vm-subsystems-monitoring">RedHat: VM Subsystems Monitoring</a></li>
  <li><a href="https://netflixtechblog.com/using-ebpf-to-understand-cache-behavior-c74f62cfc84a">Netflix: Using eBPF to Understand Cache Behavior</a></li>
  <li><a href="https://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server">PostgreSQL Wiki: Tuning Your Server</a></li>
  <li><a href="https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html">Oracle: MySQL Server System Variables</a></li>
  <li><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems">RHEL Documentation: Filesystems</a></li>
  <li><a href="https://www.kernel.org/doc/html/latest/admin-guide/mm/concepts.html">Linux Kernel Documentation: Page Cache</a></li>
  <li><a href="https://aws.amazon.com/blogs/database/best-practices-for-configuring-parameters-for-amazon-rds-for-mysql-part-1-parameters-related-to-performance/">Amazon AWS: Optimizing MySQL Performance</a></li>
</ul>


                <!-- Pagination links -->


            </article>

            
                <aside class="see-also">
                    <h2>See also</h2>
                    <ul>
                        
                        
                        
                            <li>
                                <a href="/category/troubleshooting/db-connection-econnreset-resolution/">
                                    
                                        <img src="https://blog.kakaocdn.net/dna/s4D8a/btsOxNLMqM4/AAAAAAAAAAAAAAAAAAAAAORE6t2MVeHlg6zCJA1t5NVNNR4Wh10RQLa4nfpWBDNv/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1756652399&allow_ip=&allow_referer=&signature=BU3QjfHpdR4%2FWl2hapEWOzOIy2I%3D">
                                    
                                    <h3>Resolving DB Connection Error (ECONNRESET) Issues</h3>
                                </a>
                            </li>
                        
                            <li>
                                <a href="/category/openstack/openstack-trove/">
                                    
                                        <img src="https://res.cloudinary.com/dkcm26aem/image/upload/c_scale,w_380/v1756185482/openstack-trove-1_ggheju.png">
                                    
                                    <h3>Deep Dive into OpenStack Trove</h3>
                                </a>
                            </li>
                        
                            <li>
                                <a href="/category/database/database-normalization/">
                                    
                                        <img src="https://blog.kakaocdn.net/dn/GY9Lf/btsMP5uevn7/JNMOge6dsyn4R6Lx0CbQF1/img.png">
                                    
                                    <h3>Database Normalization and Denormalization: A Complete Guide</h3>
                                </a>
                            </li>
                        
                    </ul>
                </aside>
            

        </section>

        <!-- Add time bar only for pages without pagination -->
        
            <div class="time-bar" data-minutes="26">
    <span class="time-completed"></span>
    <span class="time-remaining"></span>
    <div class="bar">
        <span class="completed" style="width:0%;"></span>
        <span class="remaining" style="width:100%;"></span>
    </div>
</div>

            <button class="toggle-preview" onclick="togglePreview()">
    <span>Hide Preview ▼</span>
</button>

<div id="recommendationSection" class="recommendation">
    <div class="message">
        <strong>Why don't you read something next?</strong>
        <div>
            <button>
                <svg><use xlink:href="#icon-arrow-right"></use></svg>
                <span>Go back to top</span>
            </button>
        </div>
    </div>
    <div id="previewSection" class="preview-section">
        
        <a href="/category/cicd/gitlab-gitlabrunner/" class="post-preview">
            <div class="image">
                
                    <img src="https://res.cloudinary.com/dkcm26aem/image/upload/c_scale,w_380/v1737524828/gitlab_1_zviqqo.png">
                
            </div>
            <h3 class="title">What is GitLab, GitLab Runner?</h3>
        </a>
    </div>
</div>

<style>
.toggle-preview {
    position: fixed;
    bottom: 20px;
    right: 20px;
    background: #333;
    color: white;
    border: none;
    padding: 8px 15px;
    border-radius: 4px;
    cursor: pointer;
    z-index: 1000;
    opacity: 0;
    transition: opacity 0.3s ease;
}

.toggle-preview:hover {
    background: #444;
}

.toggle-preview.visible {
    opacity: 1;
}

.recommendation {
    margin-top: 1000px;
    display: block;
    transition: all 0.3s ease;
}

.recommendation.hidden {
    display: none;
}

.hide-preview {
    margin-left: 10px;
    background: none;
    border: 1px solid #666;
    color: #666;
    padding: 5px 10px;
    border-radius: 4px;
    cursor: pointer;
}

.hide-preview:hover {
    background: #f0f0f0;
}

.preview-section {
    max-height: 1000px;
    overflow: hidden;
    transition: max-height 0.3s ease-out;
}

.preview-section.hidden {
    max-height: 0;
}
</style>

<script>
function togglePreview() {
    const recommendation = document.getElementById('recommendationSection');
    const button = document.querySelector('.toggle-preview span');
    
    if (recommendation.classList.contains('hidden')) {
        recommendation.classList.remove('hidden');
        button.textContent = 'Hide Preview ▼';
    } else {
        recommendation.classList.add('hidden');
        button.textContent = 'Show Preview ▲';
    }
}

window.addEventListener('scroll', function() {
    const toggleButton = document.querySelector('.toggle-preview');
    const recommendation = document.getElementById('recommendationSection');
    const rect = recommendation.getBoundingClientRect();
    
    if (rect.top <= window.innerHeight) {
        toggleButton.classList.add('visible');
    } else {
        toggleButton.classList.remove('visible');
    }
});
</script>

        

        <!-- Show modal if the post is the last one -->
        

        <!-- Show modal before user leaves the page -->
        

        <!-- Add your newsletter subscription form here -->

        <section class="share">
    <h3>Share</h3>
    <a aria-label="Share on Twitter" href="https://twitter.com/intent/tweet?text=&quot;An in-depth exploration of OS cache mechanisms and their effects on MySQL and Redis performance&quot;%20https://somaz.blog/category/cs/os-cache-disk/%20via%20&#64;twitter_username&hashtags=performance,mysql,redis,cache,disk-io"
    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" title="Share on Twitter">
        <svg class="icon icon-twitter"><use xlink:href="#icon-twitter"></use></svg>
    </a>
    <a aria-label="Share on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://somaz.blog/category/cs/os-cache-disk/"
    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;" title="Share on Facebook">
        <svg class="icon icon-facebook"><use xlink:href="#icon-facebook"></use></svg>
    </a>
</section>

        

  <section class="author">
    <div class="details">
      
        <img class="img-rounded" src="/assets/img/uploads/profile.png" alt="Somaz">
      
      <p class="def">Author</p>
      <h3 class="name">
        <a href="/authors/somaz/">Somaz</a>
      </h3>
      <p class="desc">DevOps engineer focused on cloud infrastructure and automation</p>
      <p>
        
          <a href="https://github.com/somaz94" title="Github">
            <svg><use xlink:href="#icon-github"></use></svg>
          </a>
        
        
        
        
        
        
          <a href="https://www.linkedin.com/in/somaz" title="LinkedIn">
            <svg><use xlink:href="#icon-linkedin"></use></svg>
          </a>
        
        
          <a href="https://somaz.tistory.com" title="Tistory">
            <svg><use xlink:href="#icon-tistory"></use></svg>
          </a>
        
      </p>
    </div>
  </section>

  
  
  
  
  
  
  
  

  <script type="application/ld+json">
  {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "Somaz",
      
      "image": "/assets/img/uploads/profile.png",
      
      "jobTitle": "DevOps Engineer",
      "url": "https://somaz.blog/authors/somaz/",
      "sameAs": [
        "https://github.com/somaz94","https://www.linkedin.com/in/somaz","https://{{ author.tistory_username }}.tistory.com"
      ]
  }
  </script>


        

<section class="comments">
    <h3>Comments</h3>
    <div id="disqus_thread"></div>
</section>
<script type="text/javascript">
    var disqus_loaded = false;

    function load_disqus()
    {
        disqus_loaded = true;
        var disqus_shortname = 'https-somaz94-github-io';
        var disqus_title = '';
        var disqus_url = '/category/cs/os-cache-disk/';
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        var ldr = document.getElementById('disqus_loader');
    };
    window.onscroll = function(e) {
        if ((window.innerHeight + window.scrollY) >= (document.body.offsetHeight - 800)) {
            //hit bottom of page
            if (disqus_loaded==false)
                load_disqus()
        }
    };
</script>



        <footer>
    <p>
      
        <a href="https://github.com/somaz94" title="Github">
          <svg><use xlink:href="#icon-github"></use></svg>
        </a>
      
      
        <a href="https://www.facebook.com/facebook_username" title="Facebook">
          <svg><use xlink:href="#icon-facebook"></use></svg>
        </a>
      
      
        <a href="https://twitter.com/twitter_username" title="Twitter">
          <svg><use xlink:href="#icon-twitter"></use></svg>
        </a>
      
      
        <a href="https://medium.com/@medium_username" title="Medium">
          <svg><use xlink:href="#icon-medium"></use></svg>
        </a>
      
      
        <a href="https://www.instagram.com/instagram_username" title="Instagram">
          <svg><use xlink:href="#icon-instagram"></use></svg>
        </a>
      
      
        <a href="https://www.linkedin.com/in/somaz" title="LinkedIn">
          <svg><use xlink:href="#icon-linkedin"></use></svg>
        </a>
      
      
        <a href="https://somaz.tistory.com" title="Tistory">
          <svg><use xlink:href="#icon-tistory"></use></svg>
        </a>
      
    </p>

    <ul>
  
    
      <li>
        <a href="https://somaz.blog/">Home</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/about">About</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/category">Category</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/contact">Contact</a>
      </li>
    
  
    
      <li>
        <a href="https://somaz.blog/feed.xml">Feed</a>
      </li>
    
  
</ul>


    <p>
      <a href="https://somaz.blog/sitemap.xml" title="sitemap">Sitemap</a> |
      <a href="https://somaz.blog/privacy-policy" title="Privacy Policy">Privacy Policy</a>
    </p>

    <p>
      <span>Somaz Tech Blog</span> <svg class="love"><use xlink:href="#icon-heart"></use></svg>
    </p>
</footer>










<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "somaz",
  "description": "DevOps engineer's tech blog.",
  "url": "https://somaz.blog/",
  "logo": {
      "@type": "ImageObject",
      "url": "https://somaz.blog/assets/img/icons/mediumtile.png",
      "width": "600",
      "height": "315"
  },
  "sameAs": [
    "https://github.com/somaz94","https://www.facebook.com/facebook_username","https://twitter.com/twitter_username","https://medium.com/@medium_username","https://www.instagram.com/instagram_username","https://www.linkedin.com/in/somaz","https://{{ site.tistory_username }}.tistory.com"
  ]
}
</script>

<!-- Include the script that allows Netlify CMS login -->
<script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script>

<!-- Include the website scripts -->
<script src="/assets/js/scripts.min.js"></script>

<!-- Include Google Analytics script -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXX-X"></script>
<script>
  var host = window.location.hostname;
  if (host != 'localhost') {
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-XXXXXXXX-X');
  }
</script>
  


<!-- Include extra scripts -->



        

        
        
        
        
        
        
        
        
        <script type="application/ld+json">
        {
            "@context": "http://schema.org",
            "@type": "BlogPosting",
            "name": "OS Cache and Disk I/O - MySQL and Redis Performance Analysis",
            "headline": "Understanding the impact of operating system caches on database performance",
            "description": "An in-depth exploration of OS cache mechanisms and their effects on MySQL and Redis performance",
            "image": "https://res.cloudinary.com/dkcm26aem/image/upload/v1744340260/os-cache-disk_jwhgck.png",
            "url": "https://somaz.blog/category/cs/os-cache-disk/",
            "articleBody": "



Overview

Operating system caching mechanisms sit at the critical intersection between application performance and hardware capabilities. While database administrators often focus on optimizing database settings and upgrading hardware, the operating system’s caching layer often has the most significant impact on real-world performance.

The OS cache serves as a transparent intermediary that minimizes expensive disk operations by storing recently accessed data in memory. This automatic optimization dramatically improves read and write speeds, particularly for database systems like MySQL and Redis that perform intensive I/O operations.




  Historical Context
  Operating system caching has evolved significantly since the early days of computing. The concept of using faster memory to cache slower storage dates back to the 1960s, but modern page caching as we know it today was refined in the 1980s with the development of Unix&apos;s &quot;unified buffer cache.&quot;
  Linux&apos;s page cache implementation, introduced in the early 1990s, combined with the virtual memory system to create an adaptive caching mechanism that automatically uses available memory for file system operations. This approach allowed for dramatic performance improvements without requiring application-level changes, making it one of the most important operating system optimizations for database performance.
  Over time, these caching mechanisms have been refined to handle evolving storage technologies, from traditional hard drives to modern SSDs and NVMe storage, with each advancement requiring adjustments to caching strategies for optimal performance.






What is OS Cache?

The operating system cache is a memory management mechanism that improves I/O performance by storing recently accessed data in RAM, providing faster access than reading from or writing to physical storage devices.


  
    graph LR
      A[Application] --&amp;gt; B[System Call Interface]
      B --&amp;gt; C{Cache Hit?}
      C --&amp;gt;|Yes| D[Read from Page Cache]
      C --&amp;gt;|No| E[Read from Disk]
      E --&amp;gt; F[Store in Page Cache]
      F --&amp;gt; D
      D --&amp;gt; A
      
      style A fill:#f9f9f9,stroke:#333,stroke-width:1px
      style D fill:#d4f7d4,stroke:#333,stroke-width:1px
      style E fill:#f7d4d4,stroke:#333,stroke-width:1px
  




Types of OS Caches


  
    Type
    Description
    How It Works
  
  
    Page Cache
    Memory area that stores file contents to minimize disk reads
    When a file is read, the OS copies pages into memory. Subsequent reads use cached data instead of accessing disk.
  
  
    Buffer Cache
    Memory area that temporarily holds data before writing to disk
    Write operations are stored in memory and flushed to disk asynchronously (delayed write), improving application performance.
  
  
    Dirty Pages
    Pages in memory that have been modified but not yet written to disk
    System tracks modified pages and periodically flushes them to disk based on time thresholds or when memory pressure increases.
  
  
    inode Cache
    Cache for file metadata structures
    Stores file attributes and locations to avoid filesystem metadata lookups.
  
  
    dentry Cache
    Cache for directory entry lookups
    Speeds up pathname resolution by storing recently used directory structures.
  




How Page Cache Works

When an application reads a file, the operating system follows these steps:


  Check if the requested data exists in the page cache
  If found (cache hit), return data directly from memory
  If not found (cache miss), read the data from disk into the page cache
  Return the data from the cache to the application


This process is transparent to applications, which simply make standard file I/O calls without needing to know about the cache.







Page Cache Management in Linux

Linux dynamically manages the page cache size based on memory pressure. It tries to use as much available memory as possible for caching, but will reclaim cache pages when applications need more memory.

# View current memory usage including cache
free -m

# Example output:
#               total        used        free      shared  buff/cache   available
# Mem:          16384        4096        2048          64       10240        8192
# Swap:          4096           0        4096


In this output:

  buff/cache shows memory used for the buffer cache and page cache
  available shows memory that can be allocated to processes without swapping




Cache Flushing Mechanisms

For data consistency and durability, Linux needs to write dirty pages back to disk. This happens through several mechanisms:


  Background Flush: The pdflush (older kernels) or flusher threads periodically write dirty pages to disk
  Explicit Sync: Applications can call fsync(), fdatasync(), or sync() to force data to be written to disk
  Memory Pressure: When memory is needed for other purposes, dirty pages may be written to disk
  Age-Based Flush: Pages are written after being dirty for a certain time period


# View current dirty page settings
cat /proc/sys/vm/dirty_background_ratio
cat /proc/sys/vm/dirty_ratio
cat /proc/sys/vm/dirty_expire_centisecs
cat /proc/sys/vm/dirty_writeback_centisecs

# Example: Manually trigger sync to flush dirty pages
sync


Direct I/O vs Cached I/O

Some applications bypass the page cache for specific reasons:







Bypassing the cache might be preferred when:

  The application maintains its own cache (like MySQL’s InnoDB Buffer Pool)
  Predictable I/O latency is more important than throughput
  Very large sequential scans would push useful data out of cache






When Caching Doesn’t Work Well

While the operating system’s caching mechanisms generally provide significant performance benefits, several scenarios can reduce or negate these advantages.


  
    Situation
    Description
    Impact and Solutions
  
  
    Manual Cache Clearing
    Frequent execution of drop_caches or system reboots
    Causes &quot;cold cache&quot; performance, requiring disk reads for all data. Solution: Avoid scheduled cache clearing; allow the OS to manage cache.
  
  
    Memory Pressure
    System memory is filled by applications, leaving little for cache
    OS reclaims cache pages for application use, reducing cache hit rate. Solution: Add RAM or tune memory allocation between applications.
  
  
    Direct I/O Usage
    Applications bypassing kernel cache (O_DIRECT flag)
    Eliminates double-buffering but loses OS cache benefits. Solution: Only use if application has custom caching.
  
  
    Random Access Pattern
    Non-sequential access to data across large datasets
    Lower spatial locality reduces prefetching effectiveness. Solution: Improve data locality in application design.
  
  
    Working Set &amp;gt; RAM
    Active dataset exceeds available memory
    Frequent cache evictions leading to high disk I/O. Solution: Add RAM or partition workloads.
  
  
    Inappropriate Readahead
    Default readahead settings unsuitable for workload
    Cache filled with unused data or insufficient prefetching. Solution: Tune blockdev --setra for workload.
  
  
    Cache Thrashing
    Working set slightly exceeds available memory
    Continuous cycle of cache fills and evictions. Solution: Tune application or increase RAM.
  
  
    Inappropriate Cache Flush Settings
    Poorly configured dirty page write parameters
    Too-frequent or too-infrequent disk writes. Solution: Tune VM dirty page parameters.
  


Case Study: Cache Clearing Impact on Database Performance

The following graph demonstrates the performance impact of clearing the OS cache on a MySQL database server:







When the cache is cleared, transaction performance drops dramatically until the working set is reloaded into memory.



Testing Cache Impact on Your System

#!/bin/bash
# Script to demonstrate cache impact on file read performance

FILE_PATH=&quot;/path/to/large/file&quot;  # Should be at least 1GB
ITERATIONS=3

echo &quot;Testing read performance with OS cache:&quot;

# Drop caches first to start with clean state
echo &quot;Dropping caches...&quot;
sudo sync
sudo bash -c &quot;echo 3 &amp;gt; /proc/sys/vm/drop_caches&quot;

for i in $(seq 1 $ITERATIONS); do
    echo &quot;Read $i:&quot;
    time cat $FILE_PATH &amp;gt; /dev/null
done

echo &quot;Note the significant speed improvement after the first read&quot;
echo &quot;This demonstrates the OS cache effect&quot;




Common Cache Tuning Parameters

For workloads where the default caching behavior isn’t optimal, Linux provides several tuning parameters:

# Control how aggressive the kernel reclaims memory 
# (0-100, higher = favor cache retention)
echo 10 &amp;gt; /proc/sys/vm/swappiness

# Control dirty page thresholds (as % of total memory)
echo 10 &amp;gt; /proc/sys/vm/dirty_background_ratio  # Start background flushing
echo 20 &amp;gt; /proc/sys/vm/dirty_ratio             # Force synchronous flushes

# Control how long dirty pages can stay in memory (in centiseconds)
echo 3000 &amp;gt; /proc/sys/vm/dirty_expire_centisecs  # 30 seconds

# Readahead setting for specific device (in 512-byte sectors)
blockdev --setra 256 /dev/sda  # 128KB readahead




Disk I/O vs Cache Access Speed Comparison

The performance gap between memory and storage devices is one of the largest disparities in computer architecture, making caching essential for system performance.


  
    Storage Type
    Avg. Access Time
    Unit
    Relative Speed
    Practical Impact
  
  
    CPU L1 Cache
    0.5-1 ns
    nanoseconds
    1x
    Reference point (fastest)
  
  
    CPU L2 Cache
    3-7 ns
    nanoseconds
    ~5x slower
    Still extremely fast, small capacity (KB to MB)
  
  
    CPU L3 Cache
    10-20 ns
    nanoseconds
    ~15x slower
    Shared among CPU cores, larger capacity
  
  
    Main Memory (RAM)
    50-100 ns
    nanoseconds
    ~100x slower
    OS cache uses RAM, 100-1000x faster than best SSDs
  
  
    NVMe SSD
    10-20 μs
    microseconds
    ~10,000x slower
    Fastest storage, but still orders of magnitude slower than RAM
  
  
    SATA SSD
    50-150 μs
    microseconds
    ~100,000x slower
    Common SSD type, latency constrained by SATA interface
  
  
    HDD (7200 RPM)
    5-10 ms
    milliseconds
    ~10,000,000x slower
    Mechanical seek time dominates, 50-100x slower than SSDs
  
  
    Network Storage
    5-50+ ms
    milliseconds
    ~10,000,000x+ slower
    Network latency adds significant overhead
  




Visualizing the Speed Difference

To put these differences in perspective, if we were to scale these times to human-relatable units, where RAM access is represented as 1 second:

CPU L1 Cache: 10 milliseconds (quick eye blink)
RAM: 1 second (heartbeat)
NVMe SSD: 2-5 minutes (short break)
SATA SSD: 10-25 minutes (coffee break)
HDD: 14-28 hours (more than a day)


This enormous performance gap makes caching critical for system performance.



Measuring I/O vs Cache Performance

You can measure and compare disk I/O versus cache performance on your system using tools like:

# Install necessary tools
apt-get install fio sysstat

# Create test file and bypass cache for accurate disk timing
dd if=/dev/zero of=test_file bs=1M count=1024 oflag=direct

# Run disk read test (bypassing cache)
fio --name=disk_read --filename=test_file --direct=1 --rw=read --bs=4k --size=1G --numjobs=1 --time_based --runtime=60 --group_reporting

# Run cached read test (after file is cached)
# First read it to ensure it&apos;s in cache
cat test_file &amp;gt; /dev/null
# Then measure cached performance
fio --name=cached_read --filename=test_file --direct=0 --rw=read --bs=4k --size=1G --numjobs=1 --time_based --runtime=60 --group_reporting


The results will typically show:

  Disk read: 50-500 MB/s depending on storage type
  Cached read: 5,000-50,000+ MB/s depending on RAM speed and CPU




Database Performance Impact

For database systems like MySQL and Redis, this speed difference translates directly to performance metrics:


  Cold cache: TPS (transactions per second) can be 10-100x lower
  Warm cache: Operations are primarily memory-bound, not I/O-bound
  Cache hits: Can support thousands more concurrent users with the same hardware


The database performance curve is typically non-linear with cache hit rate - a small decrease in cache hit rate from 99% to 95% might halve overall performance, while a drop from 95% to 80% might cause a 10x performance degradation.





MySQL: Buffer Pool vs OS Cache

MySQL’s InnoDB storage engine implements a buffer pool that caches frequently accessed data and index pages in memory. However, this is just one layer in a multi-tiered caching system that ultimately includes the OS cache.




  
    graph LR
      A[SQL Query] --&amp;gt; B[MySQL Query Cache]
      B --&amp;gt;|Cache Miss| C[InnoDB Buffer Pool]
      C --&amp;gt;|Cache Miss| D[OS Page Cache]
      D --&amp;gt;|Cache Miss| E[Storage Device]
      
      style B fill:#d4e6f7,stroke:#333,stroke-width:1px
      style C fill:#d4e6f7,stroke:#333,stroke-width:1px
      style D fill:#d4e6f7,stroke:#333,stroke-width:1px
      style E fill:#f7d4d4,stroke:#333,stroke-width:1px
  




Buffer Pool Architecture

The InnoDB buffer pool is MySQL’s memory area for caching table and index data. It operates as follows:


  Requested data pages are first looked up in the buffer pool
  If not found, they’re read from disk and placed in the buffer pool
  When the buffer pool is full, least recently used (LRU) pages are evicted








OS Cache Role in MySQL Performance

Even with a well-sized buffer pool, MySQL still relies on the OS cache for several reasons:


  Data accessed through non-InnoDB storage engines (e.g., MyISAM)
  Binary logs, redo logs, and other system files
  Data not in the buffer pool (cold data or after buffer pool eviction)
  Temporary tables and sort files




Disk Read Metrics Analysis

Monitoring disk read operations helps understand how your MySQL instance is utilizing caches:







A high hit ratio (&amp;gt;99%) suggests effective buffer pool usage, but doesn’t give the full picture of OS cache usage.



O_DIRECT Flag and Its Impact

MySQL can be configured to use direct I/O, bypassing the OS cache:

# MySQL configuration for direct I/O
[mysqld]
innodb_flush_method=O_DIRECT


This configuration has important trade-offs:


  
    Aspect
    With OS Cache
    With O_DIRECT
  
  
    Memory Usage
    Data potentially cached twice (buffer pool and OS cache)
    More efficient memory usage (no double-buffering)
  
  
    Read Performance
    Cold data may be in OS cache even if not in buffer pool
    All cache misses go directly to disk
  
  
    Write Control
    OS controls write flushing (potentially unpredictable)
    MySQL controls write timing (more predictable)
  
  
    Best For
    Systems where MySQL is the primary application
    Systems with multiple applications competing for memory
  




Optimizing MySQL with Proper Buffer Pool and OS Cache Configuration

The key to optimal MySQL performance is balancing buffer pool size and allowing sufficient memory for the OS cache:

# Example optimal memory allocation for a database server with 64GB RAM
# MySQL Buffer Pool: 48GB (75%)
# OS and other processes: 4GB
# OS Cache available: 12GB

# MySQL configuration
innodb_buffer_pool_size = 48G
innodb_buffer_pool_instances = 8  # One per CPU core up to 8

# Monitor actual memory usage
free -m
vmstat 1




Practical Case Studies and Solutions

Case Study 1: MySQL Performance Degradation After Midnight



Problem:
A production MySQL database experienced significant performance degradation every night at midnight, with query latency increasing by 10x and disk I/O spikes.

Investigation:

  Monitoring showed an increase in both buffer pool misses and disk reads
  OS monitoring revealed a scheduled script executed echo 3 &amp;gt; /proc/sys/vm/drop_caches as part of cleanup automation
  This cleared both the OS cache and caused cold reads for data not in the buffer pool


Solution:
1. Removed the drop_caches command from the cleanup script
2. Implemented proper buffer pool dumping and loading:

# Added to MySQL configuration
innodb_buffer_pool_dump_at_shutdown = 1
innodb_buffer_pool_load_at_startup = 1


3. Added monitoring for buffer pool and OS cache hit rates

Result:

  Overnight performance stabilized with no noticeable latency spikes
  Cold starts after planned maintenance were also improved


# Script to warm up MySQL cache after planned maintenance
mysql -e &quot;SELECT COUNT(*) FROM important_table WHERE last_accessed &amp;gt; DATE_SUB(NOW(), INTERVAL 1 DAY)&quot;




Case Study 2: Optimizing for Limited Memory

Problem:
A server with 16GB RAM running both MySQL and application services experienced high I/O wait times.

Investigation:

  MySQL was configured with 12GB buffer pool
  Application servers required 2-3GB, leaving only 1-2GB for OS cache
  High I/O wait showed insufficient OS caching


Solution:
1. Rebalanced memory allocation:

# Reduced buffer pool size
innodb_buffer_pool_size = 8G


2. Optimized MySQL query patterns to work better with smaller buffer pool
3. Added monitoring for OS cache usage

Result:

  OS Cache grew to 5-6GB
  Overall performance improved by 30%
  I/O wait decreased by 60%




Redis: All In-Memory, But Why Cache?

While Redis is primarily an in-memory database, it still interacts with disk for persistence features and can benefit significantly from OS cache management.



Redis Persistence Mechanisms

Redis offers two persistence options that interact with the OS cache:


  RDB (Redis Database): Point-in-time snapshots saved to disk
  AOF (Append-Only File): Log of all write operations



  
    Feature
    RDB
    AOF
  
  
    Persistence Model
    Periodic snapshots
    Write-ahead log
  
  
    OS Cache Impact
    Large writes during save, benefits from write-back cache
    Continuous small writes, OS cache crucial for performance
  
  
    Fsync Frequency
    Only at end of save operation
    Configurable: never, every second, or every write
  
  
    Recovery Performance
    Faster load (binary format)
    Slower (must replay operations)
  




AOF and OS Cache Interaction

With AOF enabled, Redis writes operations to a file, but the actual disk flush depends on the appendfsync setting:

# Redis configuration options
appendonly yes
appendfsync everysec  # Options: no, everysec, always


The OS cache’s role in each setting:


  appendfsync no: Redis never calls fsync, relying entirely on OS cache to flush dirty pages
  appendfsync everysec: Redis calls fsync every second, but writes first go to OS cache
  appendfsync always: Redis calls fsync after every write, minimizing OS cache role but dramatically reducing performance


Performance: no &amp;gt; everysec &amp;gt; always
Durability: always &amp;gt; everysec &amp;gt; no




Case Study: Redis AOF Write Delay

Problem:
A Redis server with AOF enabled experienced periodic “freeze” moments where all operations would block for several seconds.

Investigation:

  AOF file had grown to several GB
  vm.dirty_ratio was set to default 20%
  During peak write periods, dirty pages accumulated until hitting the threshold
  When threshold was reached, the kernel forced synchronous flushes, blocking Redis


Solution:

1. Adjusted Linux kernel parameters:

# Lower threshold for background flushing
echo 5 &amp;gt; /proc/sys/vm/dirty_background_ratio

# Set longer expiration for dirty pages
echo 10000 &amp;gt; /proc/sys/vm/dirty_expire_centisecs


2. Implemented scheduled AOF rewrites and monitoring:

# Add to crontab
0 3 * * * redis-cli BGREWRITEAOF

# Monitor AOF size
redis-cli info persistence | grep aof_current_size


3. Added higher-performance storage for the AOF file

Result:

  Background flushing prevented accumulation of excessive dirty pages
  Redis operations remained responsive even during high write periods
  Scheduled rewrites kept AOF size manageable




Redis and Memory Pressure

Even though Redis is an in-memory database, system memory pressure can still affect performance:


  When memory is scarce, the OS may prioritize application memory over cache
  Background saves (BGSAVE) require additional memory, potentially causing swapping
  AOF rewrites also need memory to create the new file


Monitoring Redis Memory and OS Cache Interaction:

# Check Redis memory usage
redis-cli info memory

# Check system memory including cache
free -m

# Watch for Redis swapping
redis-cli info stats | grep total_swap





  📊 Key Performance Metrics to Monitor
  
    
      MySQL
      - Buffer pool hit rate (&amp;gt;99% is excellent)
      - InnoDB buffer pool reads vs read requests
      - Disk I/O wait percentage
      - Table and index size vs buffer pool size
    
    
      Redis
      - AOF rewrite duration and frequency
      - OS dirty page ratio during writes
      - fsync duration (available in Redis logs when spikes occur)
      - Memory fragmentation ratio
    
    
      OS Cache
      - Available memory vs cache size
      - Dirty page ratio and flush patterns
      - I/O wait percentage
      - Read vs write IOPS
    
  





  Cache Warming Strategies
  After system reboots or cache clearing events, databases will experience &quot;cold cache&quot; performance until the working set is loaded into memory. Cache warming can significantly reduce the performance impact:
  
    MySQL: Use buffer pool dump/load for InnoDB, or run queries that select commonly accessed data
    Redis: Load data through scripts that access frequently used keys
    OS Cache: Read important database files sequentially before accepting application traffic
  
  Example MySQL cache warming script:
  
  #!/bin/bash
  # MySQL cache warming script
  mysql -e &quot;SELECT * FROM (SELECT id FROM popular_table ORDER BY last_accessed DESC LIMIT 10000) t&quot;
  mysql -e &quot;SELECT * FROM (SELECT id FROM common_reference_table) t&quot;
  




Practical Example: Monitoring Cache Hit Rate

Monitoring tools play a crucial role in understanding cache behavior:

OS Cache Status:

# View memory usage including cache
free -h

# More detailed cache information
cat /proc/meminfo | grep -E &apos;Cached|Buffers|Dirty|Writeback&apos;

# Monitor I/O wait percentage - indicator of cache efficiency
top
# or
vmstat 1


MySQL Cache Monitoring:







Redis Cache Monitoring:

# Monitor Redis memory usage
redis-cli info memory | grep used_memory

# Monitor AOF status
redis-cli info persistence | grep aof

# Check background save status
redis-cli info persistence | grep rdb






Advanced Cache Optimization Techniques

Beyond the basic understanding of OS cache and its interaction with databases, several advanced techniques can further optimize system performance.



Cache Prefetching

Cache prefetching involves reading data into memory before it’s actually requested, improving performance for sequential operations:

# Enable and configure readahead for a specific block device
sudo blockdev --setra 4096 /dev/sda  # 2MB readahead (4096 * 512 bytes)

# Check current readahead settings
sudo blockdev --getra /dev/sda


Application-level prefetching:

-- MySQL query that prefetches data for upcoming operations
SELECT * FROM users WHERE last_active &amp;gt; DATE_SUB(NOW(), INTERVAL 1 DAY) LIMIT 10000;




Filesystem Selection for Caching Behavior

Different filesystems have different caching characteristics:


  
    Filesystem
    Cache Behavior
    Best For
  
  
    ext4
    Good balance of metadata and data caching
    General-purpose database servers
  
  
    XFS
    Excellent for large files, metadata performance
    Large database files, high concurrency
  
  
    ZFS
    Adaptive Read Cache (ARC) with its own caching layer
    Systems with large RAM and varied workloads
  
  
    Btrfs
    Good metadata caching, COW can impact caching performance
    Systems where data integrity is top priority
  




Numa Cache Considerations

On multi-socket servers, Non-Uniform Memory Access (NUMA) can significantly impact cache performance:

# View NUMA topology
numactl --hardware

# Run MySQL with NUMA awareness
numactl --interleave=all mysqld

# MySQL NUMA configuration
[mysqld]
innodb_numa_interleave=1




Cache Partitioning

For systems with multiple applications, cache partitioning can prevent one application from dominating the cache:

# Create separate mount points for different applications
mount -o size=4G -t tmpfs tmpfs /mnt/mysql_tmpfs
mount -o size=2G -t tmpfs tmpfs /mnt/redis_tmpfs

# Move specific files to the partitioned cache
mkdir -p /mnt/mysql_tmpfs/tmp
ln -s /mnt/mysql_tmpfs/tmp /var/lib/mysql/tmp





  Common OS Cache Misconceptions
  
    
      Myth: &quot;Free memory is wasted memory&quot;
      Reality: The OS automatically uses free memory for caching, but having some free memory is important for new allocations without forcing cache evictions
    
    
      Myth: &quot;Disabling OS cache with O_DIRECT always improves database performance&quot;
      Reality: O_DIRECT can reduce double-buffering, but eliminates beneficial effects of OS cache for cold data, system files, and other I/O
    
    
      Myth: &quot;Adding RAM always improves performance&quot;
      Reality: Once your working set fits in memory (buffer pool + OS cache), additional RAM provides diminishing returns
    
    
      Myth: &quot;SSDs eliminate the need for caching&quot;
      Reality: Even NVMe SSDs are orders of magnitude slower than RAM; caching remains essential
    
  




Conclusion

The operating system’s cache mechanism plays a pivotal role in database performance, serving as a critical layer between applications and storage devices. Our exploration has revealed how both MySQL and Redis leverage the OS cache in different ways, each with its own unique optimization considerations.



Key Insights


  Layered Caching Architecture: Database systems implement multiple caching layers that work together:
    
      Application-level caches (e.g., Redis itself)
      Database engine caches (MySQL’s Buffer Pool)
      OS cache
      Storage controller caches
    
  
  
    Performance Implications: The difference between memory and disk access speeds (nano vs. milliseconds) makes caching essential for performance. Even a small decrease in cache hit rates can cause dramatic performance degradation.
  
  
    Cache Cooperation: For optimal performance, database settings should be configured with OS cache in mind. A well-tuned system balances memory allocation between application caches and OS cache.
  
  Monitoring Importance: Regularly monitoring cache hit rates, dirty page ratios, and I/O patterns allows for early detection of caching issues before they impact users.




Practical Recommendations

As we’ve seen through case studies and examples, several practical steps can ensure optimal cache performance:


  Balance memory allocation between database buffer pools and OS cache
  Monitor cache metrics to identify potential issues
  Avoid unnecessary cache clearing through automated scripts
  Tune OS cache parameters (vm.dirty_ratio, vm.swappiness) based on workload
  Consider filesystem and storage options that complement your caching strategy
  Implement cache warming strategies for planned maintenance and restarts




Broader Implications

The principles of caching extend beyond databases to all computing systems. The fundamental tradeoff between speed and capacity drives the design of modern storage hierarchies from CPU registers to cloud storage.

Understanding how the OS cache interfaces with applications provides deeper insight into system behavior and performance optimization opportunities. For database administrators and system engineers, this knowledge is not just theoretical—it has direct, practical applications in designing high-performance, reliable systems.

As database technologies continue to evolve, the role of OS caching remains crucial. Even with in-memory databases, the OS cache continues to play an important role in persistence, recovery, and overall system performance.

Remember: “A well-used cache is often more important than fast storage.” By leveraging the OS cache effectively, you can achieve significant performance improvements without additional hardware investments.





References


  RedHat: Linux Page Cache
  MySQL Documentation: InnoDB Buffer Pool
  Redis Documentation: Persistence
  Kernel Documentation: VM Sysctl
  Percona: Understanding InnoDB Buffer Pool
  Brendan Gregg: Linux Performance
  RedHat: VM Subsystems Monitoring
  Netflix: Using eBPF to Understand Cache Behavior
  PostgreSQL Wiki: Tuning Your Server
  Oracle: MySQL Server System Variables
  RHEL Documentation: Filesystems
  Linux Kernel Documentation: Page Cache
  Amazon AWS: Optimizing MySQL Performance

",
            "wordcount": "4688",
            "inLanguage": "en",
            "dateCreated": "2025-04-24/",
            "datePublished": "2025-04-24/",
            "dateModified": "2025-04-24/",
            "author": {
                "@type": "Person",
                "name": "Somaz",
                
                "image": "/assets/img/uploads/profile.png",
                
                "jobTitle": "DevOps Engineer",
                "url": "https://somaz.blog/authors/somaz/",
                "sameAs": [
                    "https://github.com/somaz94","https://www.linkedin.com/in/somaz"
                ]
            },
            "publisher": {
                "@type": "Organization",
                "name": "somaz",
                "url": "https://somaz.blog/",
                "logo": {
                    "@type": "ImageObject",
                    "url": "https://somaz.blog/assets/img/blog-image.png",
                    "width": "600",
                    "height": "315"
                }
            },
            "mainEntityOfPage": "True",
            "genre": "CS",
            "articleSection": "CS",
            "keywords": ["performance","mysql","redis","cache","disk-io"]
        }
        </script>
    </body>
</html>
